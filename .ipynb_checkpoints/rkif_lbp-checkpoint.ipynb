{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial for Classification Machine Learning and Statistical Analysis on Simulations of PTP1B. \n",
    "\n",
    "In this jupyter notebook we will use the model_building.py and stat_modelling.py modules to identify differences in the molecular interactions across PTP1B when the WPD-loop of PTP1B is in the Closed state, versus when the WPD-loop is in the Open state.\n",
    "\n",
    "This notebook will also cover all the pre- and post-processing steps requireds to prepare, analyse and visualise the results.\n",
    "\n",
    "The dataset used here is for WT PTP1B and is the same data as what was used in the manuscript. \n",
    "\n",
    "### Adapting this to use with LBP simulation data (conformational change)\n",
    "* Instead of PTP1B closed to open, we can look at the closed to open transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ihome/lchong/dty7/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/ihome/lchong/dty7/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from key_interactions_finder import data_preperation\n",
    "from key_interactions_finder import model_building\n",
    "from key_interactions_finder import stat_modelling\n",
    "from key_interactions_finder import post_proccessing\n",
    "from key_interactions_finder import pymol_projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we'll define the location of our downloaded input files and where we would like to save our output files to throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in current dir or alt\n",
    "save_dir = \"\"\n",
    "\n",
    "# Where all input data is stored. \n",
    "#in_dir = save_dir + r\"data/\"\n",
    "in_dir = save_dir\n",
    "\n",
    "# The target variable's per frame values are stored here. \n",
    "classifications_file = in_dir + r\"class_assignments_withneither_10i.txt\"\n",
    "\n",
    "# The pdb file will later be used to determine the distance of each residue to a site of interest.\n",
    "# Original crystall structure state (major conformation)\n",
    "pdb_file = in_dir + r\"1lst_dry.pdb\"\n",
    "\n",
    "# output folders for the stats and ml analysis. These will be created if they don't already exist.\n",
    "stats_out_dir = save_dir + r\"LBP_stat_analysis\"\n",
    "ml_out_dir = save_dir + r\"LBP_ml_analysis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation Step 1: Load the non-covalent interaction datasets\n",
    "\n",
    "The contact identification calculation was split into 4 blocks of different residues ranges. We will first need to load these blocks in and merge them. Luckly this is very easy with pandas. \n",
    "\n",
    "Note this data was generated using the script: \"identify_contacts.py\" which is provided with KIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3Pro 6Val Hydrophobic</th>\n",
       "      <th>2Leu 41Met Other</th>\n",
       "      <th>2Leu 43Val Hydrophobic</th>\n",
       "      <th>3Pro 43Val Hydrophobic</th>\n",
       "      <th>3Pro 65Asp Other</th>\n",
       "      <th>4Gln 42Gln Hbond</th>\n",
       "      <th>4Gln 43Val Other</th>\n",
       "      <th>4Gln 44Lys Hbond</th>\n",
       "      <th>5Thr 43Val Other</th>\n",
       "      <th>5Thr 44Lys Hbond</th>\n",
       "      <th>...</th>\n",
       "      <th>226Met 229Lys Hbond</th>\n",
       "      <th>226Met 230Tyr Other</th>\n",
       "      <th>227Ala 230Tyr Other</th>\n",
       "      <th>227Ala 231Phe Hydrophobic</th>\n",
       "      <th>227Ala 235Val Hydrophobic</th>\n",
       "      <th>228Lys 231Phe Hbond</th>\n",
       "      <th>228Lys 232Asp Saltbr</th>\n",
       "      <th>231Phe 235Val Hydrophobic</th>\n",
       "      <th>234Asn 237Gly Hbond</th>\n",
       "      <th>234Asn 238Asp Hbond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5329</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>1.7172</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>4.2693</td>\n",
       "      <td>10.8300</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>3.6985</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1654</td>\n",
       "      <td>2.5094</td>\n",
       "      <td>4.4450</td>\n",
       "      <td>8.2710</td>\n",
       "      <td>1.0146</td>\n",
       "      <td>4.8463</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>4.6154</td>\n",
       "      <td>1.3497</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>2.0700</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>3.4245</td>\n",
       "      <td>5.3518</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>4.8669</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1190</td>\n",
       "      <td>3.9452</td>\n",
       "      <td>3.3073</td>\n",
       "      <td>6.3502</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>4.9758</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>4.4195</td>\n",
       "      <td>1.2363</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>2.7918</td>\n",
       "      <td>4.0636</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>7.3735</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1370</td>\n",
       "      <td>3.2289</td>\n",
       "      <td>4.1669</td>\n",
       "      <td>5.8355</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>3.4915</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>2.4443</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   3Pro 6Val Hydrophobic  2Leu 41Met Other  2Leu 43Val Hydrophobic  \\\n",
       "0                 0.5329            0.3142                  0.2983   \n",
       "1                 0.5528            0.2583                  0.0727   \n",
       "2                 0.1342            0.0135                  0.0062   \n",
       "\n",
       "   3Pro 43Val Hydrophobic  3Pro 65Asp Other  4Gln 42Gln Hbond  \\\n",
       "0                  1.7172            0.0003            0.9915   \n",
       "1                  2.0700            0.0002            0.0172   \n",
       "2                  0.9421            0.0000            0.0011   \n",
       "\n",
       "   4Gln 43Val Other  4Gln 44Lys Hbond  5Thr 43Val Other  5Thr 44Lys Hbond  \\\n",
       "0            4.2693           10.8300            0.0026            3.6985   \n",
       "1            3.4245            5.3518            0.0174            4.8669   \n",
       "2            2.7918            4.0636            0.0243            7.3735   \n",
       "\n",
       "   ...  226Met 229Lys Hbond  226Met 230Tyr Other  227Ala 230Tyr Other  \\\n",
       "0  ...               2.1654               2.5094               4.4450   \n",
       "1  ...               4.1190               3.9452               3.3073   \n",
       "2  ...               5.1370               3.2289               4.1669   \n",
       "\n",
       "   227Ala 231Phe Hydrophobic  227Ala 235Val Hydrophobic  228Lys 231Phe Hbond  \\\n",
       "0                     8.2710                     1.0146               4.8463   \n",
       "1                     6.3502                     0.5429               4.9758   \n",
       "2                     5.8355                     0.8972               3.4915   \n",
       "\n",
       "   228Lys 232Asp Saltbr  231Phe 235Val Hydrophobic  234Asn 237Gly Hbond  \\\n",
       "0                0.0174                     4.6154               1.3497   \n",
       "1                0.2229                     4.4195               1.2363   \n",
       "2                0.0256                     2.4443               0.8852   \n",
       "\n",
       "   234Asn 238Asp Hbond  \n",
       "0               0.0001  \n",
       "1               0.0001  \n",
       "2               0.0000  \n",
       "\n",
       "[3 rows x 682 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_files = [\"PTP1B_block1.csv\", \"PTP1B_block2.csv\", \"PTP1B_block3.csv\", \"PTP1B_block4.csv\"]\n",
    "#input_files = [\"contacts_all_res.csv\"]\n",
    "#input_files = [\"contacts_all_10i.csv\"]\n",
    "input_files = [\"contacts_merged_10i.csv\"]\n",
    "dfs = []\n",
    "for file_name in input_files:\n",
    "    file_path = in_dir + file_name\n",
    "    df = pd.read_csv(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "all_contacts_df = pd.concat(dfs, join='outer', axis=1)\n",
    "all_contacts_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we now have a dataframe with all the contacts found (989) identified and of length 10000, with matches with the number of frames in the trajectory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 682)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_contacts_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation Step 2. Prepare the Dataset for calculations with the data_preperation.py module. \n",
    "\n",
    "In this step, we take our dataframe and merge our per frame classifications file to it.\n",
    "\n",
    "We can also optionally perform several forms of filtering on the non-covalent interactions identified to select what types of interactions we would like to study.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your PyContact features and target variable have been succesufully merged.\n",
      "You can access this dataset through the class attribute: '.df_processed'.\n"
     ]
    }
   ],
   "source": [
    "# First we generate an instance of the SupervisedFeatureData class (because we have per frame target labels).\n",
    "supervised_dataset = data_preperation.SupervisedFeatureData(\n",
    "    input_df=all_contacts_df,\n",
    "    target_file=classifications_file,\n",
    "    is_classification=True,\n",
    "    header_present=False # If your target_file has a header present, set to True.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>3Pro 6Val Hydrophobic</th>\n",
       "      <th>2Leu 41Met Other</th>\n",
       "      <th>2Leu 43Val Hydrophobic</th>\n",
       "      <th>3Pro 43Val Hydrophobic</th>\n",
       "      <th>3Pro 65Asp Other</th>\n",
       "      <th>4Gln 42Gln Hbond</th>\n",
       "      <th>4Gln 43Val Other</th>\n",
       "      <th>4Gln 44Lys Hbond</th>\n",
       "      <th>5Thr 43Val Other</th>\n",
       "      <th>...</th>\n",
       "      <th>226Met 229Lys Hbond</th>\n",
       "      <th>226Met 230Tyr Other</th>\n",
       "      <th>227Ala 230Tyr Other</th>\n",
       "      <th>227Ala 231Phe Hydrophobic</th>\n",
       "      <th>227Ala 235Val Hydrophobic</th>\n",
       "      <th>228Lys 231Phe Hbond</th>\n",
       "      <th>228Lys 232Asp Saltbr</th>\n",
       "      <th>231Phe 235Val Hydrophobic</th>\n",
       "      <th>234Asn 237Gly Hbond</th>\n",
       "      <th>234Asn 238Asp Hbond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>open</td>\n",
       "      <td>0.5329</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>1.7172</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>4.2693</td>\n",
       "      <td>10.8300</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1654</td>\n",
       "      <td>2.5094</td>\n",
       "      <td>4.4450</td>\n",
       "      <td>8.2710</td>\n",
       "      <td>1.0146</td>\n",
       "      <td>4.8463</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>4.6154</td>\n",
       "      <td>1.3497</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>open</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.0727</td>\n",
       "      <td>2.0700</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>3.4245</td>\n",
       "      <td>5.3518</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1190</td>\n",
       "      <td>3.9452</td>\n",
       "      <td>3.3073</td>\n",
       "      <td>6.3502</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>4.9758</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>4.4195</td>\n",
       "      <td>1.2363</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>open</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>2.7918</td>\n",
       "      <td>4.0636</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1370</td>\n",
       "      <td>3.2289</td>\n",
       "      <td>4.1669</td>\n",
       "      <td>5.8355</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>3.4915</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>2.4443</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open</td>\n",
       "      <td>1.3588</td>\n",
       "      <td>1.2146</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>2.8848</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>3.1210</td>\n",
       "      <td>6.1990</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6176</td>\n",
       "      <td>2.1097</td>\n",
       "      <td>4.2430</td>\n",
       "      <td>7.0550</td>\n",
       "      <td>0.3698</td>\n",
       "      <td>6.8199</td>\n",
       "      <td>2.8362</td>\n",
       "      <td>2.9558</td>\n",
       "      <td>1.7422</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open</td>\n",
       "      <td>5.9673</td>\n",
       "      <td>2.2893</td>\n",
       "      <td>1.5990</td>\n",
       "      <td>0.7918</td>\n",
       "      <td>0.8938</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>2.8498</td>\n",
       "      <td>9.1154</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9873</td>\n",
       "      <td>1.2366</td>\n",
       "      <td>4.1340</td>\n",
       "      <td>6.3315</td>\n",
       "      <td>0.4919</td>\n",
       "      <td>4.1251</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>3.1777</td>\n",
       "      <td>1.0016</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>0.2359</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>2.6393</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>1.0653</td>\n",
       "      <td>6.7574</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0054</td>\n",
       "      <td>3.9118</td>\n",
       "      <td>1.9167</td>\n",
       "      <td>6.4007</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>3.4088</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>1.5845</td>\n",
       "      <td>3.3009</td>\n",
       "      <td>1.5278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>closed</td>\n",
       "      <td>1.0091</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>1.1574</td>\n",
       "      <td>2.2330</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>1.7307</td>\n",
       "      <td>3.6708</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1211</td>\n",
       "      <td>2.4759</td>\n",
       "      <td>4.1000</td>\n",
       "      <td>6.4734</td>\n",
       "      <td>0.9019</td>\n",
       "      <td>3.4712</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>2.9561</td>\n",
       "      <td>5.6275</td>\n",
       "      <td>0.0710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.7409</td>\n",
       "      <td>1.1615</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3604</td>\n",
       "      <td>3.6894</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0278</td>\n",
       "      <td>4.9154</td>\n",
       "      <td>4.2875</td>\n",
       "      <td>5.8551</td>\n",
       "      <td>0.4131</td>\n",
       "      <td>6.5720</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>3.9111</td>\n",
       "      <td>9.7388</td>\n",
       "      <td>4.4154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.8547</td>\n",
       "      <td>1.0210</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>1.8511</td>\n",
       "      <td>3.1967</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0864</td>\n",
       "      <td>2.9089</td>\n",
       "      <td>2.1531</td>\n",
       "      <td>5.3433</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>3.3352</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>4.5739</td>\n",
       "      <td>5.8783</td>\n",
       "      <td>5.2084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.6078</td>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.6242</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>3.3451</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7285</td>\n",
       "      <td>2.9889</td>\n",
       "      <td>3.4993</td>\n",
       "      <td>8.5351</td>\n",
       "      <td>1.1471</td>\n",
       "      <td>3.9990</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>1.6116</td>\n",
       "      <td>10.0826</td>\n",
       "      <td>5.8489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 683 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target  3Pro 6Val Hydrophobic  2Leu 41Met Other  \\\n",
       "0        open                 0.5329            0.3142   \n",
       "1        open                 0.5528            0.2583   \n",
       "2        open                 0.1342            0.0135   \n",
       "3        open                 1.3588            1.2146   \n",
       "4        open                 5.9673            2.2893   \n",
       "...       ...                    ...               ...   \n",
       "19995  closed                 0.4880            0.2359   \n",
       "19996  closed                 1.0091            0.1129   \n",
       "19997  closed                 0.1184            0.1450   \n",
       "19998  closed                 0.0773            0.2530   \n",
       "19999  closed                 0.6078            0.7185   \n",
       "\n",
       "       2Leu 43Val Hydrophobic  3Pro 43Val Hydrophobic  3Pro 65Asp Other  \\\n",
       "0                      0.2983                  1.7172            0.0003   \n",
       "1                      0.0727                  2.0700            0.0002   \n",
       "2                      0.0062                  0.9421            0.0000   \n",
       "3                      0.9647                  2.8848            0.0107   \n",
       "4                      1.5990                  0.7918            0.8938   \n",
       "...                       ...                     ...               ...   \n",
       "19995                  0.1829                  2.6393            0.0007   \n",
       "19996                  1.1574                  2.2330            0.0330   \n",
       "19997                  0.7409                  1.1615            0.0001   \n",
       "19998                  0.8547                  1.0210            0.0000   \n",
       "19999                  0.6242                  0.1090            0.0001   \n",
       "\n",
       "       4Gln 42Gln Hbond  4Gln 43Val Other  4Gln 44Lys Hbond  5Thr 43Val Other  \\\n",
       "0                0.9915            4.2693           10.8300            0.0026   \n",
       "1                0.0172            3.4245            5.3518            0.0174   \n",
       "2                0.0011            2.7918            4.0636            0.0243   \n",
       "3                0.0415            3.1210            6.1990            0.0108   \n",
       "4                0.0028            2.8498            9.1154            0.0031   \n",
       "...                 ...               ...               ...               ...   \n",
       "19995            0.0012            1.0653            6.7574            0.0961   \n",
       "19996            0.0028            1.7307            3.6708            0.0255   \n",
       "19997            0.0001            0.3604            3.6894            0.0345   \n",
       "19998            0.0074            1.8511            3.1967            0.1885   \n",
       "19999            0.0000            0.0006            3.3451            0.0109   \n",
       "\n",
       "       ...  226Met 229Lys Hbond  226Met 230Tyr Other  227Ala 230Tyr Other  \\\n",
       "0      ...               2.1654               2.5094               4.4450   \n",
       "1      ...               4.1190               3.9452               3.3073   \n",
       "2      ...               5.1370               3.2289               4.1669   \n",
       "3      ...               2.6176               2.1097               4.2430   \n",
       "4      ...               4.9873               1.2366               4.1340   \n",
       "...    ...                  ...                  ...                  ...   \n",
       "19995  ...               6.0054               3.9118               1.9167   \n",
       "19996  ...               3.1211               2.4759               4.1000   \n",
       "19997  ...               4.0278               4.9154               4.2875   \n",
       "19998  ...               3.0864               2.9089               2.1531   \n",
       "19999  ...               5.7285               2.9889               3.4993   \n",
       "\n",
       "       227Ala 231Phe Hydrophobic  227Ala 235Val Hydrophobic  \\\n",
       "0                         8.2710                     1.0146   \n",
       "1                         6.3502                     0.5429   \n",
       "2                         5.8355                     0.8972   \n",
       "3                         7.0550                     0.3698   \n",
       "4                         6.3315                     0.4919   \n",
       "...                          ...                        ...   \n",
       "19995                     6.4007                     0.7681   \n",
       "19996                     6.4734                     0.9019   \n",
       "19997                     5.8551                     0.4131   \n",
       "19998                     5.3433                     0.6042   \n",
       "19999                     8.5351                     1.1471   \n",
       "\n",
       "       228Lys 231Phe Hbond  228Lys 232Asp Saltbr  231Phe 235Val Hydrophobic  \\\n",
       "0                   4.8463                0.0174                     4.6154   \n",
       "1                   4.9758                0.2229                     4.4195   \n",
       "2                   3.4915                0.0256                     2.4443   \n",
       "3                   6.8199                2.8362                     2.9558   \n",
       "4                   4.1251                0.0650                     3.1777   \n",
       "...                    ...                   ...                        ...   \n",
       "19995               3.4088                0.0019                     1.5845   \n",
       "19996               3.4712                0.0006                     2.9561   \n",
       "19997               6.5720                0.0188                     3.9111   \n",
       "19998               3.3352                0.0230                     4.5739   \n",
       "19999               3.9990                0.0011                     1.6116   \n",
       "\n",
       "       234Asn 237Gly Hbond  234Asn 238Asp Hbond  \n",
       "0                   1.3497               0.0001  \n",
       "1                   1.2363               0.0001  \n",
       "2                   0.8852               0.0000  \n",
       "3                   1.7422               0.0001  \n",
       "4                   1.0016               0.0000  \n",
       "...                    ...                  ...  \n",
       "19995               3.3009               1.5278  \n",
       "19996               5.6275               0.0710  \n",
       "19997               9.7388               4.4154  \n",
       "19998               5.8783               5.2084  \n",
       "19999              10.0826               5.8489  \n",
       "\n",
       "[20000 rows x 683 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As stated above to access the newly generated dataframe we can use the class attribute as follows\n",
    "supervised_dataset.df_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional Feature Filtering\n",
    "\n",
    "In the above dataframe we have n columns. We can take all of these forward for the statistical analysis or we can perform some filtering in advance (the choice is yours). \n",
    "There are five built in filtering methods available to you to perform filtering:\n",
    "\n",
    "1. **filter_by_occupancy(min_occupancy)** - Remove features that have an %occupancy less than the provided cut-off. %Occupancy is the % of frames with a non 0 value, i.e. the interaction is present in that frame.\n",
    "\n",
    "2. **filter_by_interaction_type(interaction_types_included)** - Inteactions are defined as one of four possible types: (\"Hbond\", \"Saltbr\", \"Hydrophobic\", \"Other\"). You select the interactions you want to include.\n",
    "\n",
    "3. **filter_by_avg_strength(average_strength_cut_off)** - Filter by the per frame contact score/strength for each interaction. You can filter features by the average score. Values below the cut-off are removed. \n",
    "\n",
    "4. **filter_by_occupancy_by_class(min_occupancy)** - Special alternative to the the standard filter features by occupancy method. %occupancy is determined for each class (as opposed to whole dataset), meaning only observations from 1 class have to meet the cut-off to keep the feature. Only avaible to datasets with a categorical target variable (classification). \n",
    "\n",
    "\n",
    "Finally if at any point in time you want to reset any filtering you've already performed, you can use the following method: \n",
    "\n",
    "5. **reset_filtering()** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before any filtering: 682\n",
      "Number of features after filtering by occupancy: 681\n",
      "Number of features after filtering by interaction type: 378\n",
      "Number of features after filtering by average interaction scores: 334\n"
     ]
    }
   ],
   "source": [
    "# An example of filtering the dataset using the available methods. \n",
    "supervised_dataset.reset_filtering() \n",
    "print(f\"Number of features before any filtering: {len(supervised_dataset.df_processed.columns) - 1}\")\n",
    "\n",
    "# Features with a %occupancy of less than 25% are removed. \n",
    "supervised_dataset.filter_by_occupancy_by_class(min_occupancy=25)\n",
    "print(f\"Number of features after filtering by occupancy: {len(supervised_dataset.df_filtered.columns) - 1}\")\n",
    "\n",
    "# Remove features with interaction type \"Other\". \n",
    "supervised_dataset.filter_by_interaction_type(\n",
    "    interaction_types_included=[\"Hbond\", \"Saltbr\", \"Hydrophobic\"]) \n",
    "print(f\"Number of features after filtering by interaction type: {len(supervised_dataset.df_filtered.columns) - 1}\")\n",
    "\n",
    "# Features with an average interaction strength less than 0.5 will be removed. \n",
    "supervised_dataset.filter_by_avg_strength(\n",
    "    average_strength_cut_off=0.5,  \n",
    ")\n",
    "print(f\"Number of features after filtering by average interaction scores: {len(supervised_dataset.df_filtered.columns) - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at the class attributes of our SupervisedFeatureData() instance (we called it: supervised_dataset) using the special \"\\_\\_dict__\" method we can see two dataframes we could use in the statistical analysis to follow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_df', 'is_classification', 'target_file', 'header_present', 'df_processed', 'df_filtered'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_dataset.__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are: \n",
    "- 'df_processed' - The unfiltered dataframe\n",
    "- 'df_filtered' - The filtered dataframe\n",
    "\n",
    "In the following sections we will use the filtered dataframe but either dataframe could be justified based on your goals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>98Lys 178Tyr Hbond</th>\n",
       "      <th>98Lys 177Glu Saltbr</th>\n",
       "      <th>98Lys 176Lys Hbond</th>\n",
       "      <th>97Ala 150Leu Hydrophobic</th>\n",
       "      <th>97Ala 100Ser Hbond</th>\n",
       "      <th>96Ala 181Ala Hydrophobic</th>\n",
       "      <th>96Ala 179Ala Hydrophobic</th>\n",
       "      <th>96Ala 102Ile Hydrophobic</th>\n",
       "      <th>95Ile 180Phe Hydrophobic</th>\n",
       "      <th>...</th>\n",
       "      <th>105Thr 108Ser Hbond</th>\n",
       "      <th>104Pro 183Pro Hydrophobic</th>\n",
       "      <th>104Pro 181Ala Hydrophobic</th>\n",
       "      <th>104Pro 130Trp Hbond</th>\n",
       "      <th>104Pro 109Leu Hydrophobic</th>\n",
       "      <th>103Gln 181Ala Hbond</th>\n",
       "      <th>103Gln 108Ser Hbond</th>\n",
       "      <th>102Ile 181Ala Hydrophobic</th>\n",
       "      <th>102Ile 109Leu Hydrophobic</th>\n",
       "      <th>100Ser 156Asp Hbond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>open</td>\n",
       "      <td>2.2196</td>\n",
       "      <td>6.6927</td>\n",
       "      <td>2.9951</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>5.3226</td>\n",
       "      <td>0.2566</td>\n",
       "      <td>5.8188</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>2.2829</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8184</td>\n",
       "      <td>1.0332</td>\n",
       "      <td>2.7846</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>5.4690</td>\n",
       "      <td>1.0816</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>open</td>\n",
       "      <td>3.4723</td>\n",
       "      <td>5.4602</td>\n",
       "      <td>1.6337</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>5.2617</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>7.7100</td>\n",
       "      <td>0.4893</td>\n",
       "      <td>1.2165</td>\n",
       "      <td>...</td>\n",
       "      <td>6.6230</td>\n",
       "      <td>1.4998</td>\n",
       "      <td>2.1896</td>\n",
       "      <td>1.7524</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>5.9963</td>\n",
       "      <td>1.8600</td>\n",
       "      <td>0.8436</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>open</td>\n",
       "      <td>5.5151</td>\n",
       "      <td>5.9816</td>\n",
       "      <td>3.4247</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>3.0168</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>7.2058</td>\n",
       "      <td>2.4520</td>\n",
       "      <td>2.4205</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2565</td>\n",
       "      <td>1.0581</td>\n",
       "      <td>4.1095</td>\n",
       "      <td>0.7932</td>\n",
       "      <td>1.9413</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>5.9519</td>\n",
       "      <td>1.2689</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open</td>\n",
       "      <td>4.0564</td>\n",
       "      <td>7.7428</td>\n",
       "      <td>1.3108</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>3.2617</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>7.4634</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>1.8717</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3120</td>\n",
       "      <td>0.8045</td>\n",
       "      <td>2.5094</td>\n",
       "      <td>3.0193</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>7.3297</td>\n",
       "      <td>1.0753</td>\n",
       "      <td>1.0128</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open</td>\n",
       "      <td>2.0435</td>\n",
       "      <td>7.8003</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>2.7963</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>6.8458</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>2.9681</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4638</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>1.7571</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>4.2944</td>\n",
       "      <td>1.2352</td>\n",
       "      <td>0.7117</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>3.1732</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.8152</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.5818</td>\n",
       "      <td>8.1799</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>2.0036</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8733</td>\n",
       "      <td>1.4102</td>\n",
       "      <td>3.2694</td>\n",
       "      <td>4.6895</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>1.8504</td>\n",
       "      <td>4.8606</td>\n",
       "      <td>3.7057</td>\n",
       "      <td>0.3970</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>7.6948</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3681</td>\n",
       "      <td>3.1753</td>\n",
       "      <td>0.4313</td>\n",
       "      <td>3.6710</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>2.1168</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7049</td>\n",
       "      <td>1.7590</td>\n",
       "      <td>3.5458</td>\n",
       "      <td>0.2265</td>\n",
       "      <td>0.5534</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>5.5715</td>\n",
       "      <td>1.0861</td>\n",
       "      <td>1.0581</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>9.2752</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4273</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>1.5541</td>\n",
       "      <td>5.1516</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>5.1020</td>\n",
       "      <td>...</td>\n",
       "      <td>5.9729</td>\n",
       "      <td>3.9002</td>\n",
       "      <td>2.2463</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>1.2901</td>\n",
       "      <td>5.4080</td>\n",
       "      <td>3.1844</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>5.7598</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6639</td>\n",
       "      <td>1.2664</td>\n",
       "      <td>1.8053</td>\n",
       "      <td>5.7275</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>2.8219</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2653</td>\n",
       "      <td>0.4635</td>\n",
       "      <td>1.1681</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>5.2517</td>\n",
       "      <td>4.0943</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>2.6079</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>6.0844</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1.0951</td>\n",
       "      <td>...</td>\n",
       "      <td>5.4346</td>\n",
       "      <td>1.1125</td>\n",
       "      <td>0.7624</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>2.5416</td>\n",
       "      <td>1.3415</td>\n",
       "      <td>7.1992</td>\n",
       "      <td>5.7498</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target  98Lys 178Tyr Hbond  98Lys 177Glu Saltbr  98Lys 176Lys Hbond  \\\n",
       "0        open              2.2196               6.6927              2.9951   \n",
       "1        open              3.4723               5.4602              1.6337   \n",
       "2        open              5.5151               5.9816              3.4247   \n",
       "3        open              4.0564               7.7428              1.3108   \n",
       "4        open              2.0435               7.8003              0.0065   \n",
       "...       ...                 ...                  ...                 ...   \n",
       "19995  closed              0.0023               3.1732              0.0000   \n",
       "19996  closed              0.0066               7.6948              0.0000   \n",
       "19997  closed              0.0183               9.2752              0.0000   \n",
       "19998  closed              0.0021               5.7598              0.0000   \n",
       "19999  closed              0.0056               2.6079              0.0000   \n",
       "\n",
       "       97Ala 150Leu Hydrophobic  97Ala 100Ser Hbond  96Ala 181Ala Hydrophobic  \\\n",
       "0                        0.0004              5.3226                    0.2566   \n",
       "1                        0.0009              5.2617                    0.8459   \n",
       "2                        0.0002              3.0168                    0.8234   \n",
       "3                        0.0006              3.2617                    0.2080   \n",
       "4                        0.0002              2.7963                    0.4199   \n",
       "...                         ...                 ...                       ...   \n",
       "19995                    1.8152              0.4719                    0.5818   \n",
       "19996                    0.3681              3.1753                    0.4313   \n",
       "19997                    0.4273              0.1219                    1.5541   \n",
       "19998                    0.6639              1.2664                    1.8053   \n",
       "19999                    0.2026              0.0344                    0.5460   \n",
       "\n",
       "       96Ala 179Ala Hydrophobic  96Ala 102Ile Hydrophobic  \\\n",
       "0                        5.8188                    0.6773   \n",
       "1                        7.7100                    0.4893   \n",
       "2                        7.2058                    2.4520   \n",
       "3                        7.4634                    0.0106   \n",
       "4                        6.8458                    0.0094   \n",
       "...                         ...                       ...   \n",
       "19995                    8.1799                    0.1490   \n",
       "19996                    3.6710                    0.0375   \n",
       "19997                    5.1516                    0.0410   \n",
       "19998                    5.7275                    0.3167   \n",
       "19999                    6.0844                    0.0008   \n",
       "\n",
       "       95Ile 180Phe Hydrophobic  ...  105Thr 108Ser Hbond  \\\n",
       "0                        2.2829  ...               4.8184   \n",
       "1                        1.2165  ...               6.6230   \n",
       "2                        2.4205  ...               5.2565   \n",
       "3                        1.8717  ...               5.3120   \n",
       "4                        2.9681  ...               3.4638   \n",
       "...                         ...  ...                  ...   \n",
       "19995                    2.0036  ...               4.8733   \n",
       "19996                    2.1168  ...               3.7049   \n",
       "19997                    5.1020  ...               5.9729   \n",
       "19998                    2.8219  ...               5.2653   \n",
       "19999                    1.0951  ...               5.4346   \n",
       "\n",
       "       104Pro 183Pro Hydrophobic  104Pro 181Ala Hydrophobic  \\\n",
       "0                         1.0332                     2.7846   \n",
       "1                         1.4998                     2.1896   \n",
       "2                         1.0581                     4.1095   \n",
       "3                         0.8045                     2.5094   \n",
       "4                         0.0048                     0.8998   \n",
       "...                          ...                        ...   \n",
       "19995                     1.4102                     3.2694   \n",
       "19996                     1.7590                     3.5458   \n",
       "19997                     3.9002                     2.2463   \n",
       "19998                     0.4635                     1.1681   \n",
       "19999                     1.1125                     0.7624   \n",
       "\n",
       "       104Pro 130Trp Hbond  104Pro 109Leu Hydrophobic  103Gln 181Ala Hbond  \\\n",
       "0                   0.0048                     0.1555               0.2941   \n",
       "1                   1.7524                     0.0323               0.0495   \n",
       "2                   0.7932                     1.9413               0.3060   \n",
       "3                   3.0193                     0.3131               0.3684   \n",
       "4                   1.7571                     0.0786               0.0083   \n",
       "...                    ...                        ...                  ...   \n",
       "19995               4.6895                     0.9302               1.8504   \n",
       "19996               0.2265                     0.5534               0.1001   \n",
       "19997               0.6757                     0.3026               1.2901   \n",
       "19998               0.1201                     0.3305               0.3161   \n",
       "19999               0.9992                     2.5416               1.3415   \n",
       "\n",
       "       103Gln 108Ser Hbond  102Ile 181Ala Hydrophobic  \\\n",
       "0                   5.4690                     1.0816   \n",
       "1                   5.9963                     1.8600   \n",
       "2                   5.9519                     1.2689   \n",
       "3                   7.3297                     1.0753   \n",
       "4                   4.2944                     1.2352   \n",
       "...                    ...                        ...   \n",
       "19995               4.8606                     3.7057   \n",
       "19996               5.5715                     1.0861   \n",
       "19997               5.4080                     3.1844   \n",
       "19998               5.2517                     4.0943   \n",
       "19999               7.1992                     5.7498   \n",
       "\n",
       "       102Ile 109Leu Hydrophobic  100Ser 156Asp Hbond  \n",
       "0                         0.2628               0.0002  \n",
       "1                         0.8436               0.0003  \n",
       "2                         0.0745               0.0001  \n",
       "3                         1.0128               0.0000  \n",
       "4                         0.7117               0.0002  \n",
       "...                          ...                  ...  \n",
       "19995                     0.3970               0.0018  \n",
       "19996                     1.0581               0.0019  \n",
       "19997                     0.2420               0.0274  \n",
       "19998                     0.0853               0.0031  \n",
       "19999                     0.0974               0.0020  \n",
       "\n",
       "[20000 rows x 335 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_dataset.df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_dataset.df_filtered.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 335)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_dataset.df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>98Lys 178Tyr Hbond</th>\n",
       "      <th>98Lys 177Glu Saltbr</th>\n",
       "      <th>98Lys 176Lys Hbond</th>\n",
       "      <th>97Ala 150Leu Hydrophobic</th>\n",
       "      <th>97Ala 100Ser Hbond</th>\n",
       "      <th>96Ala 181Ala Hydrophobic</th>\n",
       "      <th>96Ala 179Ala Hydrophobic</th>\n",
       "      <th>96Ala 102Ile Hydrophobic</th>\n",
       "      <th>95Ile 180Phe Hydrophobic</th>\n",
       "      <th>...</th>\n",
       "      <th>105Thr 108Ser Hbond</th>\n",
       "      <th>104Pro 183Pro Hydrophobic</th>\n",
       "      <th>104Pro 181Ala Hydrophobic</th>\n",
       "      <th>104Pro 130Trp Hbond</th>\n",
       "      <th>104Pro 109Leu Hydrophobic</th>\n",
       "      <th>103Gln 181Ala Hbond</th>\n",
       "      <th>103Gln 108Ser Hbond</th>\n",
       "      <th>102Ile 181Ala Hydrophobic</th>\n",
       "      <th>102Ile 109Leu Hydrophobic</th>\n",
       "      <th>100Ser 156Asp Hbond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>open</td>\n",
       "      <td>2.2196</td>\n",
       "      <td>6.6927</td>\n",
       "      <td>2.9951</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>5.3226</td>\n",
       "      <td>0.2566</td>\n",
       "      <td>5.8188</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>2.2829</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8184</td>\n",
       "      <td>1.0332</td>\n",
       "      <td>2.7846</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>5.4690</td>\n",
       "      <td>1.0816</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>open</td>\n",
       "      <td>3.4723</td>\n",
       "      <td>5.4602</td>\n",
       "      <td>1.6337</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>5.2617</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>7.7100</td>\n",
       "      <td>0.4893</td>\n",
       "      <td>1.2165</td>\n",
       "      <td>...</td>\n",
       "      <td>6.6230</td>\n",
       "      <td>1.4998</td>\n",
       "      <td>2.1896</td>\n",
       "      <td>1.7524</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>5.9963</td>\n",
       "      <td>1.8600</td>\n",
       "      <td>0.8436</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>open</td>\n",
       "      <td>5.5151</td>\n",
       "      <td>5.9816</td>\n",
       "      <td>3.4247</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>3.0168</td>\n",
       "      <td>0.8234</td>\n",
       "      <td>7.2058</td>\n",
       "      <td>2.4520</td>\n",
       "      <td>2.4205</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2565</td>\n",
       "      <td>1.0581</td>\n",
       "      <td>4.1095</td>\n",
       "      <td>0.7932</td>\n",
       "      <td>1.9413</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>5.9519</td>\n",
       "      <td>1.2689</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open</td>\n",
       "      <td>4.0564</td>\n",
       "      <td>7.7428</td>\n",
       "      <td>1.3108</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>3.2617</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>7.4634</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>1.8717</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3120</td>\n",
       "      <td>0.8045</td>\n",
       "      <td>2.5094</td>\n",
       "      <td>3.0193</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>7.3297</td>\n",
       "      <td>1.0753</td>\n",
       "      <td>1.0128</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>open</td>\n",
       "      <td>2.0435</td>\n",
       "      <td>7.8003</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>2.7963</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>6.8458</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>2.9681</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4638</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>1.7571</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>4.2944</td>\n",
       "      <td>1.2352</td>\n",
       "      <td>0.7117</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>3.1732</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.8152</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.5818</td>\n",
       "      <td>8.1799</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>2.0036</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8733</td>\n",
       "      <td>1.4102</td>\n",
       "      <td>3.2694</td>\n",
       "      <td>4.6895</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>1.8504</td>\n",
       "      <td>4.8606</td>\n",
       "      <td>3.7057</td>\n",
       "      <td>0.3970</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>7.6948</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3681</td>\n",
       "      <td>3.1753</td>\n",
       "      <td>0.4313</td>\n",
       "      <td>3.6710</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>2.1168</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7049</td>\n",
       "      <td>1.7590</td>\n",
       "      <td>3.5458</td>\n",
       "      <td>0.2265</td>\n",
       "      <td>0.5534</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>5.5715</td>\n",
       "      <td>1.0861</td>\n",
       "      <td>1.0581</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>9.2752</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4273</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>1.5541</td>\n",
       "      <td>5.1516</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>5.1020</td>\n",
       "      <td>...</td>\n",
       "      <td>5.9729</td>\n",
       "      <td>3.9002</td>\n",
       "      <td>2.2463</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>1.2901</td>\n",
       "      <td>5.4080</td>\n",
       "      <td>3.1844</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.0274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>5.7598</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6639</td>\n",
       "      <td>1.2664</td>\n",
       "      <td>1.8053</td>\n",
       "      <td>5.7275</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>2.8219</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2653</td>\n",
       "      <td>0.4635</td>\n",
       "      <td>1.1681</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>5.2517</td>\n",
       "      <td>4.0943</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>closed</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>2.6079</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>6.0844</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1.0951</td>\n",
       "      <td>...</td>\n",
       "      <td>5.4346</td>\n",
       "      <td>1.1125</td>\n",
       "      <td>0.7624</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>2.5416</td>\n",
       "      <td>1.3415</td>\n",
       "      <td>7.1992</td>\n",
       "      <td>5.7498</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target  98Lys 178Tyr Hbond  98Lys 177Glu Saltbr  98Lys 176Lys Hbond  \\\n",
       "0        open              2.2196               6.6927              2.9951   \n",
       "1        open              3.4723               5.4602              1.6337   \n",
       "2        open              5.5151               5.9816              3.4247   \n",
       "3        open              4.0564               7.7428              1.3108   \n",
       "4        open              2.0435               7.8003              0.0065   \n",
       "...       ...                 ...                  ...                 ...   \n",
       "19995  closed              0.0023               3.1732              0.0000   \n",
       "19996  closed              0.0066               7.6948              0.0000   \n",
       "19997  closed              0.0183               9.2752              0.0000   \n",
       "19998  closed              0.0021               5.7598              0.0000   \n",
       "19999  closed              0.0056               2.6079              0.0000   \n",
       "\n",
       "       97Ala 150Leu Hydrophobic  97Ala 100Ser Hbond  96Ala 181Ala Hydrophobic  \\\n",
       "0                        0.0004              5.3226                    0.2566   \n",
       "1                        0.0009              5.2617                    0.8459   \n",
       "2                        0.0002              3.0168                    0.8234   \n",
       "3                        0.0006              3.2617                    0.2080   \n",
       "4                        0.0002              2.7963                    0.4199   \n",
       "...                         ...                 ...                       ...   \n",
       "19995                    1.8152              0.4719                    0.5818   \n",
       "19996                    0.3681              3.1753                    0.4313   \n",
       "19997                    0.4273              0.1219                    1.5541   \n",
       "19998                    0.6639              1.2664                    1.8053   \n",
       "19999                    0.2026              0.0344                    0.5460   \n",
       "\n",
       "       96Ala 179Ala Hydrophobic  96Ala 102Ile Hydrophobic  \\\n",
       "0                        5.8188                    0.6773   \n",
       "1                        7.7100                    0.4893   \n",
       "2                        7.2058                    2.4520   \n",
       "3                        7.4634                    0.0106   \n",
       "4                        6.8458                    0.0094   \n",
       "...                         ...                       ...   \n",
       "19995                    8.1799                    0.1490   \n",
       "19996                    3.6710                    0.0375   \n",
       "19997                    5.1516                    0.0410   \n",
       "19998                    5.7275                    0.3167   \n",
       "19999                    6.0844                    0.0008   \n",
       "\n",
       "       95Ile 180Phe Hydrophobic  ...  105Thr 108Ser Hbond  \\\n",
       "0                        2.2829  ...               4.8184   \n",
       "1                        1.2165  ...               6.6230   \n",
       "2                        2.4205  ...               5.2565   \n",
       "3                        1.8717  ...               5.3120   \n",
       "4                        2.9681  ...               3.4638   \n",
       "...                         ...  ...                  ...   \n",
       "19995                    2.0036  ...               4.8733   \n",
       "19996                    2.1168  ...               3.7049   \n",
       "19997                    5.1020  ...               5.9729   \n",
       "19998                    2.8219  ...               5.2653   \n",
       "19999                    1.0951  ...               5.4346   \n",
       "\n",
       "       104Pro 183Pro Hydrophobic  104Pro 181Ala Hydrophobic  \\\n",
       "0                         1.0332                     2.7846   \n",
       "1                         1.4998                     2.1896   \n",
       "2                         1.0581                     4.1095   \n",
       "3                         0.8045                     2.5094   \n",
       "4                         0.0048                     0.8998   \n",
       "...                          ...                        ...   \n",
       "19995                     1.4102                     3.2694   \n",
       "19996                     1.7590                     3.5458   \n",
       "19997                     3.9002                     2.2463   \n",
       "19998                     0.4635                     1.1681   \n",
       "19999                     1.1125                     0.7624   \n",
       "\n",
       "       104Pro 130Trp Hbond  104Pro 109Leu Hydrophobic  103Gln 181Ala Hbond  \\\n",
       "0                   0.0048                     0.1555               0.2941   \n",
       "1                   1.7524                     0.0323               0.0495   \n",
       "2                   0.7932                     1.9413               0.3060   \n",
       "3                   3.0193                     0.3131               0.3684   \n",
       "4                   1.7571                     0.0786               0.0083   \n",
       "...                    ...                        ...                  ...   \n",
       "19995               4.6895                     0.9302               1.8504   \n",
       "19996               0.2265                     0.5534               0.1001   \n",
       "19997               0.6757                     0.3026               1.2901   \n",
       "19998               0.1201                     0.3305               0.3161   \n",
       "19999               0.9992                     2.5416               1.3415   \n",
       "\n",
       "       103Gln 108Ser Hbond  102Ile 181Ala Hydrophobic  \\\n",
       "0                   5.4690                     1.0816   \n",
       "1                   5.9963                     1.8600   \n",
       "2                   5.9519                     1.2689   \n",
       "3                   7.3297                     1.0753   \n",
       "4                   4.2944                     1.2352   \n",
       "...                    ...                        ...   \n",
       "19995               4.8606                     3.7057   \n",
       "19996               5.5715                     1.0861   \n",
       "19997               5.4080                     3.1844   \n",
       "19998               5.2517                     4.0943   \n",
       "19999               7.1992                     5.7498   \n",
       "\n",
       "       102Ile 109Leu Hydrophobic  100Ser 156Asp Hbond  \n",
       "0                         0.2628               0.0002  \n",
       "1                         0.8436               0.0003  \n",
       "2                         0.0745               0.0001  \n",
       "3                         1.0128               0.0000  \n",
       "4                         0.7117               0.0002  \n",
       "...                          ...                  ...  \n",
       "19995                     0.3970               0.0018  \n",
       "19996                     1.0581               0.0019  \n",
       "19997                     0.2420               0.0274  \n",
       "19998                     0.0853               0.0031  \n",
       "19999                     0.0974               0.0020  \n",
       "\n",
       "[20000 rows x 335 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_dataset.df_filtered.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had to drop ~39 features since these had NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_dataset.df_filtered = supervised_dataset.df_filtered.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 335)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_dataset.df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Time! \n",
    "\n",
    "Our dataset is now ready for either statistical analysis or ML or both! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1. Perform Statistical Analysis with the stat_modelling.py module. \n",
    "\n",
    "Now we will perform the actual statistical modelling to compare the differences for each feature between states.\n",
    "\n",
    "With this module, we can calculate two different metrics to evaluate how different/similar each feature is when the protein is in the different conformations: \n",
    "\n",
    "1. The [Jensen-Shannon distance](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.jensenshannon.html). For this method, Kernel density estimations (KDEs) are calculated for the normalised interaction stength of feature in each state before performing the calculation. We can also extract these KDEs as we did in the manuscript (and will show you how to do it here) to compare the interaction strengths for each state. \n",
    "\n",
    "2. The [mutual information](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html) using the implementation available in Scikit-learn. The mutual information can capture any kind of dependancy/relationship between variables and score their dependancy\n",
    "\n",
    "In both cases, the higher the score, the more \"different\" the feature is when in the two different states. Scores are in the range 0 and 1.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_model = stat_modelling.ClassificationStatModel(\n",
    "    dataset=supervised_dataset.df_filtered, \n",
    "    class_names=[\"closed\", \"open\"], # select the two class labels to compare. Has to be 2 labels. \n",
    "    out_dir=stats_out_dir,\n",
    "    interaction_types_included=[\"Hbond\", \"Saltbr\", \"Hydrophobic\"] # select which interaction types to include, in this case: \"Other\" removed. \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jensen-Shannon (JS) distances calculated.\n",
      "LBP_stat_analysis/Jensen_Shannon_Per_Feature_Scores.csv written to disk.\n",
      "You can also access these results via the class attribute: 'js_distances'.\n"
     ]
    }
   ],
   "source": [
    "# First we can calculate the Jensen-Shannon distances\n",
    "stat_model.calc_js_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information scores calculated.\n",
      "LBP_stat_analysis/Mutual_Information_Per_Feature_Scores.csv written to disk.\n",
      "You can also access these results via the class attribute: 'mutual_infos'.\n"
     ]
    }
   ],
   "source": [
    "# Now we can calculate the mutual information\n",
    "stat_model.calc_mutual_info_to_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As printed above we can access the results from these calculations from the class instance's (we called it stat_model) attributes. \n",
    "mi_results = stat_model.mutual_infos\n",
    "js_results = stat_model.js_distances\n",
    "# stat_model.__dict__.keys() # uncomment to see all attributes available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2. Work up the Statistical Analysis with the post_proccessing.py module. \n",
    "\n",
    "In this module we have access to 3 methods to process the results. \n",
    "\n",
    "1. We can convert the per feature scores to per residue scores, by summing (and then normalising) every per feature score that each residue is involved in.\n",
    "This can allow us to identify residues which seem to differ the most between each state. \n",
    "\n",
    "2. We can also try to predict the \"direction\" that each feature favours. This essentially means in which class is the feature on average stronger in.  \n",
    "\n",
    "3. We can obtain the kernel density estimations for selected interactions to compare how the interactions stengths differ between states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['stat_model', 'out_dir', 'per_residue_mutual_infos', 'per_residue_js_distances', 'feature_directions'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First generate an instance of the class. \n",
    "post_proc = post_proccessing.StatClassificationPostProcessor(\n",
    "    stat_model=stat_model,\n",
    "    out_dir=stats_out_dir\n",
    ")\n",
    "\n",
    "# As you have already seen in the prior steps, we can take a look at class attributes with the __dict__ method. \n",
    "# Note that some of these attributes will be empty until we have run the next few code blocks.\n",
    "post_proc.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBP_stat_analysis/Jensen_Shannon_Distance_Scores_Per_Residue.csv written to disk.\n",
      "LBP_stat_analysis/Mutual_Information_Scores_Per_Residue.csv written to disk.\n"
     ]
    }
   ],
   "source": [
    "# Now we can run the get_per_res_scores() method, changing the stat_method accordingly.\n",
    "js_per_res_scores = post_proc.get_per_res_scores(\n",
    "    stat_method=\"jensen_shannon\")\n",
    "mi_per_res_scores = post_proc.get_per_res_scores(\n",
    "    stat_method=\"mutual_information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBP_stat_analysis/Feature_Direction_Estimates.csv written to disk.\n",
      "You can access these predictions through the 'feature_directions' class attribute.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ihome/lchong/dty7/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/key_interactions_finder/post_proccessing.py:774: UserWarning: Warning, this method is very simplistic and just calculates the average contact score/strength for all features for both classes to determine the direction each feature appears to favour. You should therefore interpret these results with care...\n",
      "  warnings.warn(warning_message)\n"
     ]
    }
   ],
   "source": [
    "# Here we predict the \"direction\" that each feature favours. \n",
    "# This essentially means in which class is the feature on average stronger in.  \n",
    "# Because of the nature of the method, a warning is given. \n",
    "post_proc.estimate_feature_directions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['14Tyr 161Asp Hbond', '77Arg 121Thr Hbond', '10Thr 68Ile Hbond', '72Ser 121Thr Hbond', '74Thr 121Thr Hbond', '14Tyr 143Gln Hbond', '75Asp 188Lys Saltbr', '17Phe 164Ala Hydrophobic', '91Asp 184Ser Hbond', '162Glu 184Ser Hbond'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also extract the kernel density estimations for the feature with the largest differences. \n",
    "x_values, selected_kdes = post_proc.get_kdes(\n",
    "    number_features=10) # top 10 features based on Jensen Shannon Distances. \n",
    "\n",
    "selected_kdes[\"closed\"].keys() # here we can see what features were in the top 10 and could be plotted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['14Tyr 161Asp Hbond', '77Arg 121Thr Hbond', '10Thr 68Ile Hbond', '72Ser 121Thr Hbond', '74Thr 121Thr Hbond', '14Tyr 143Gln Hbond', '75Asp 188Lys Saltbr', '17Phe 164Ala Hydrophobic', '91Asp 184Ser Hbond', '162Glu 184Ser Hbond'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_kdes[\"open\"].keys() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Now we will take a look at the most different feature in both states using the plotly plotting library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalised Interaction Strength</th>\n",
       "      <th>Closed</th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269569</td>\n",
       "      <td>18.388928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.208417</td>\n",
       "      <td>11.694717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.105272</td>\n",
       "      <td>3.124036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.075119</td>\n",
       "      <td>0.668882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.073774</td>\n",
       "      <td>0.336527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normalised Interaction Strength    Closed       Open\n",
       "0                             0.00  0.269569  18.388928\n",
       "1                             0.02  0.208417  11.694717\n",
       "2                             0.04  0.105272   3.124036\n",
       "3                             0.06  0.075119   0.668882\n",
       "4                             0.08  0.073774   0.336527"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_df = pd.DataFrame(\n",
    "    {\"Normalised Interaction Strength\": list(x_values[:, 0]),\n",
    "     \"Closed\": selected_kdes[\"closed\"]['14Tyr 161Asp Hbond'],\n",
    "     \"Open\": selected_kdes[\"open\"]['14Tyr 161Asp Hbond']\n",
    "    }\n",
    ")\n",
    "\n",
    "interaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=Closed<br>Normalised Interaction Strength=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "Closed",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "Closed",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAB7FK5H4XqUP3sUrkfheqQ/uB6F61G4rj97FK5H4Xq0P5qZmZmZmbk/uB6F61G4vj/sUbgehevBP3sUrkfhesQ/CtejcD0Kxz+amZmZmZnJPylcj8L1KMw/uB6F61G4zj+kcD0K16PQP+xRuB6F69E/MzMzMzMz0z97FK5H4XrUP8P1KFyPwtU/CtejcD0K1z9SuB6F61HYP5qZmZmZmdk/4XoUrkfh2j8pXI/C9SjcP3E9CtejcN0/uB6F61G43j8AAAAAAADgP6RwPQrXo+A/SOF6FK5H4T/sUbgehevhP4/C9Shcj+I/MzMzMzMz4z/Xo3A9CtfjP3sUrkfheuQ/H4XrUbge5T/D9Shcj8LlP2dmZmZmZuY/CtejcD0K5z+uR+F6FK7nP1K4HoXrUeg/9ihcj8L16D+amZmZmZnpPz4K16NwPeo/4XoUrkfh6j+F61G4HoXrPylcj8L1KOw/zczMzMzM7D9xPQrXo3DtPxWuR+F6FO4/uB6F61G47j9cj8L1KFzvPw==",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "OOsiEp1A0T9zhq6wZK3KP7ZZIWIf87o/qqtEWP86sz/+Q5bt2OKyP1Fbr1oFLq0/htTsJ9Skoj8U1dWw3L+hP7Qak3QPo6M/yQRgxdWgoT9igFvagxWgP4EQFXuC/6U/qC1++NKItD/L8IVI+inFP9V/6sjjS9U/TuPyrhIA5D/CJwW+A4jwP+6pDjz2jvc/Vp+gpKjg/j+uj/+P43IDQM4SYLEdygZA2HLmDnTbCEDO87+P8gcKQOeQHoV03QpAnVyo3+oLC0BMIbMBMEYKQAUYAMtZ7whAqJN8RPddB0Am4p/thbMFQAZLX1k2IgRAJSLil4w0AkCFgNA9x/T+P8NNg0ICJfk/q2BUsr268z9uniXt8EDuP1W/cWCbxuY/2xz3RUlx4D9VkA8NxgbXP/tcShgj/88/SKy5BhglxT+9F1EveUa7Pw2Qi8jOO7M/vjsGA2udqT+20kNt+VOZP5BGzb6EzoM/DKGIxMeJcD/+X6aMPc9VPzbQ8jBjzi4/UuDla7lnMj9OKZw7uJxTPw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=Open<br>Normalised Interaction Strength=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "Open",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "Open",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAB7FK5H4XqUP3sUrkfheqQ/uB6F61G4rj97FK5H4Xq0P5qZmZmZmbk/uB6F61G4vj/sUbgehevBP3sUrkfhesQ/CtejcD0Kxz+amZmZmZnJPylcj8L1KMw/uB6F61G4zj+kcD0K16PQP+xRuB6F69E/MzMzMzMz0z97FK5H4XrUP8P1KFyPwtU/CtejcD0K1z9SuB6F61HYP5qZmZmZmdk/4XoUrkfh2j8pXI/C9SjcP3E9CtejcN0/uB6F61G43j8AAAAAAADgP6RwPQrXo+A/SOF6FK5H4T/sUbgehevhP4/C9Shcj+I/MzMzMzMz4z/Xo3A9CtfjP3sUrkfheuQ/H4XrUbge5T/D9Shcj8LlP2dmZmZmZuY/CtejcD0K5z+uR+F6FK7nP1K4HoXrUeg/9ihcj8L16D+amZmZmZnpPz4K16NwPeo/4XoUrkfh6j+F61G4HoXrPylcj8L1KOw/zczMzMzM7D9xPQrXo3DtPxWuR+F6FO4/uB6F61G47j9cj8L1KFzvPw==",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "JLdC0JBjMkBw+v/ysWMnQHud8rAG/ghAFA6fwHtn5T8rKPzxqInVP5C624B4INA/RdPEnS9Myz++ZrQULeDIPy78biLHFcc/dDL68D2CxD8SD4INoynDP9tpH8uFlcI/MZfawfu2wD/RKjPfesu+PzYiNCRALL4/dOycUy0Uuz/qoDHAnSi4PzoyjuFruLU/ndHbQzSZsT8d1Rr4lR+tP4f43UYhZKc/59lgWkGJnj/1FP67lyqVPzVyOSW/ypA/DbhUZqjqiz9TQCjQdjOKP8UiCXW9G4M/SEs2pTrXez+quwXrOjl0P1MRzt6fwXI/dHwfvFTvdD+XkGpxRdJmP6PVWG+TqEM/snRnGCYTCj8Bl6QJg1S6Pu8FRXzCDFQ+RKprK47Z1j38tm6mUGBDPXoSPTjZWpg8c0anXfOg1jv1Vz7pnQf/OmudjMVGXQ861u5Djz5aBznfO1lhrJrpN1DspS0OqrQ2ge+W4E2MaDU6NGY2tnUFNPSOxjram4sysNM4SL0i+jCwZ2PlTjRSLw==",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Comparison of the KDEs obtained for Closed and Open Confs"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Normalised Interaction Strength"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Density"
         }
        }
       }
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEUAAAFoCAYAAACxEUX3AAAQAElEQVR4AeydB2AURRfH/3t3qfQuSJEmIkVAEFFRP0GRoghSRWmCUqR3kN577wgovYOgiAiiKIgoVUBBRIr0XtLv7ps3yYVLv0AS7pI/ZLZMfe83s3s7b2dmTXb+IwESIAESIAESIAESIAESIAESIAESSO0EqF8sBEzgPxIgARIgARIgARIgARIgARIgARJIVQSoDAm4RoBGEdc4MRYJkAAJkAAJkAAJkAAJkAAJuCcBSkUCJPDABGgUeWB0TEgCJEACJEACJEACJEACJJDSBFgeCZAACSQlARpFkpIm8yIBEiABEiABEiABEiCBpCPAnEiABEiABJKZAI0iyQyY2ZMACZAACZAACZAACbhCgHFIgARIgARIIOUJ0CiS8sxZIgmQAAmQAAmQQFonQP1JgARIgARIgATcggCNIm5RDRSCBEiABEiABFIvAWpGAiRAAiRAAiRAAu5KgEYRd60ZykUCJEACJOCJBCgzCZAACZAACZAACZCABxGgUcSDKouikgAJkIB7EaA0JEACJEACJEACJEACJODZBGgU8ez6o/QkQAIpRYDlkAAJkAAJkAAJkAAJkAAJpDoCNIqkuiqlQiTw8ASYAwmQAAmQAAmQAAmQAAmQAAmkBQI0iqSFWqaO8RFgGAmQAAmQAAmQAAmQAAmQAAmQQBolQKNImqp4KksCJEACJEACJEACJEACJEACJEACJOAgkHqNIg4NuScBEiABEiABEiABEiABEiABEiABEki9BB5CMxpFHgIek5IACZAACZAACZAACZAACZAACZBAShJgWUlLgEaRpOXJ3EiABEiABEiABEiABEiABEiABJKGAHMhgWQnQKNIsiNmASRAAiRAAiRAAiRAAiRAAiSQEAGGkwAJPAoCNIo8CuoskwRIgARIgARIgARIgATSMgHqTgIkQAJuQoBGETepCIpBAiRAAiRAAiRAAiSQOglQKxIgARIgAfclQKOI+9YNJSMBEiABEiABEiABTyNAeUmABEiABEjAowjQKOJR1UVhSYAESIAESIAE3IcAJSEBEiABEiABEvB0AjSKeHoNUn4SIAESIAESSAkCLIMESIAESIAESIAEUiEBGkVSYaVSJRIgARIggYcjwNQkQAIkQAIkQAIkQAJpgwCNImmjnqklCZAACcRFgP4kQAIkQAIkQAIkQAIkkGYJ0CiSZqueipNAWiRAnUmABEiABEiABEiABEiABEjgPgEaRe6z4BEJpC4C1IYESIAESIAESIAESIAESIAESCBeAjSKxIuHgZ5CgHKSAAmQAAmQAAmQAAmQAAmQAAmQQGIJ0CiSWGKPPj4lIAESIAESIAESIAESIAESIAESIAESSAICbm4USQINmQUJkAAJkAAJkAAJkAAJkAAJkAAJkICbE3g04tEo8mi4s1QSIAESIAESIAESIAESIAESIIG0SoB6uw0BGkXcpiooCAmQAAmQAAmQAAmQAAmQAAmkPgLUiATcmQCNIu5cO5SNBEiABEiABEiABEiABEjAkwhQVhIgAQ8jQKOIh1UYxSUBEiABEiABEiABEiAB9yBAKUiABEjA8wnQKOL5dUgNSIAESIAESIAESIAEkpsA8ycBEiABEkiVBGgUSZXVSqVIgARIgARIgARI4MEJMCUJkAAJkAAJpBUCac4oEhpmxZn/LuHSlRsIs1rTSj3Dbrfj7r1ABAaFpBqdfzv4F+Yt/QqT5q7G2q9/fCC99h74E/OXf40bt+48UHomiptAaGiYZrv95/1xR0rCkOCQUN3GH9V1vW7zTqzYsN1ljZKi/bpcWCwR47sXCkO5Lrbt3BdLykfvJfcxkW/nnkOPXhgnCXb/dkS3+dt3A5x8XTu8decejv9zTrdh11K4b6yAwGCcOnMB12/egc1mTzFBpcwla7/Tvwny2yByuFg4o5EACZAACZAACaRhAmnGKPLtD7/h7WZ9Uabqh6jepBdeq98Fz1T5EO37TsJ3O39P0Qe3R9He/rt4FRVrtkXzTiMfRfFJXuasL75EM6XLxDmrMHfJJsxetDHOMsQINn7WSkgnNHqkn349DAm7ev1W9KAkPx84bgFKvNocf5/6L0beK7/8XofVaflppOGqQvU22k/SiJPzGu/3wpCJX+Dwn6di5CEePYfOipJG0jm7/mPmS7QUcWKkELabtu5OsLz46ijBxBERhk1apNv47t+ORvik7E7a4bQF61wqNDHt16UMExHJlXthaKhVXxcbvv0pETmnXNR7AYFavm++/zXlCnWhpO93HdBy3bx114XY0Ib5z5Z9jcrvdMALb7WHXP9yn5bfpzVf/aiN2S5llKhIyRM5VBlB5T4ssleo/jFqNe2j9Sr1WgsMGrcwzntWUknzy76juswRUxbr3wT5bbjzAMappJKH+ZAACZAACZAACXgOgTRhFOk9Yg66DJyGk6fPo0nd19G/S1O0afo2KpUvgR3qIbZT/6kICg72nFp7AEl9fbzx8vPPoFzpJx8gtXslkbfEU+evRYG8ubBhwXAc2bEQK2YNjFPIi5dv6Le3R47/G2eclAhwvDG1I+qbUxlJMXjC58iVIwtmj+kOP1/vKOI0qVsVDd7+H54vV1y10xA9GqFRm8H4fNWWKPHkJMxqkx1ee7Es3nnzpRiuTIkiOtzdNklRR08WyqvbeNbMGdxNvSjyJLb9Rkn8kCdp7l74kLySM7mMxmnVbSwmzF6pi2nZqAYGdmuOD+q9gTt3AzFg7Hz0GjZbh7n7Rka5vNtqAKZ8tgZeFgtaN6mFAep3tmn9aihcIA9WbdqBYcqYm5x6iKFR8p83rgcObvsMuzZOR/asmcSLjgRIgARIgARIgATiJZDqjSIyvHrjt7t0h3PTFyPRt2MTNKr9Gjq0rAt5eJoxsgv8/XxjhSRTTmINSIRnUuSRiOLijCoPhzNHdUGv9o3jjJPUAcml+8XL17SoNV57HkUKPq6PM2dKr/dJsUkuuWOTbf8fJ9Ch32TdBhdM7I2c2TNHiZZVdfD7dnwfA7s2w9ThnbB1+XhMHdZRxxkzfZke5aRPom16tGuM4b1bxXDv1nw5WsyHP01JXvFJK51JaeMlij0RX7QkDXsQ3V1tv4nNOyHFHuZeGFveSS1fbGVE90vpMpOzvM3b9kCm74kxb828oejWpgEavPUqen/yHlbOHqh/s77a9gtkBER0Du52/tnSr/RLh8oVS2H13MHo3LoeGqrfWfm9WTt/KLp+3ABeXpZYxU4qxkf++hdlSxbVLzssZjMyZUgHsznVP+LEypSeJEACJEACJEACiSOQ6p8YRk5dookM7t4CBfPn1sfOm1cqPYNtqyaot/M+kd7yVqvhx4NR8n8tUK1xD8hw3HsBQZHhcjBadUi7Dpqh54B37D8FMrVB4srwYQmXzm7b3hPxXI22egixDOWVN4MSJk4e4CR8y469euqHDJsu8WpzvP/JcEhaieNwh46ehMSV/CWOlNWyy2h8vyvqWg2OPH/YfRD/nLmg39pJh3vpum2Qoc2Sh+NtmuQdEhKqRxuIrpKnDHuW6URbdkQdkn7h8nXItAwZ4i3lN+88Cj/v/UOyiHSOsrf/tA+LVn+Leq0Han4yZUnkiYyYwEFCZf118iz6jpqnc9m4dZfmInr9+fcZ7Rd9I+zGz1qhvZeu/S4yvkx10J4RGxnuLnUqjKXeW3Ufq+fERwRH7mS0kdS3g4XUV3QWkZETOJA6+qjHeB1rwaReeuSLPolnIw/5r71UThv0JJqMcgoIjNo2xd8VJ8ykDUu9S/1Lnclb64tXrieYXEY7yNQYmc4jvCSt1LtjNEzUDOyQKTQfdBihp/ZIm3BeAyahOpJwqWOpG2l/Faq3QWztX4yfEu/s+cuRxUudio5Sb7IXPcXJNKI7sQytl5FjkrfEESfXz+lzlyLzcxwcPf4v2vQar9u4xOs6aDquXEt4ClZC7dcVrkHBIbodSxuWN/QLlm+GlC/TsxzyxbZ/kHth9HxckU/SuNq2XOUtxgG5T0lbk/Y6duZyKcYlJ+sFyf1L2p3UlbQhud8uWbsVsq6KI5PE3sOu3biNfupe5LgXSPved/i4I7t492IImDh3lY4zSP02RTeGym9Vr/bv6fDpC9brvWxk3Rpp4/IbIaPLhIXoJPeky1dvSpQoTtq9hDlkjO1+ldhrJEoB6kTW55IpQOoQw3q1Qob0/nIY6cRA8WHjGpg+sjOc/63atAOOOpVrO77fWdEjrutXfleFidwH5fqSY3FyP5DyXG2LEpeOBEiABEiABEggbRJI1UYReRiWDo0M361csXScNZxRPcQZhqHD5e27zH8+f+kq3nrjBWTOmB6ycFv9jwZGrvUgEfcdOg4xHsjD9bad+1BIGVzOXbiiDRHSqZKHzx9/Oaj9r9+8oxcE/fGX+4sCXr95GxIunRkZchwQGKw7xfKwK2md152QB0KJ6+/ng9dfLq/ehhXBnv3H8EnfyXA2ODjynDp/Ld5q2kcbW7b/vB+Hjp2ETKuQPI6e+FfE1274lMUYo4w7V67fxP9eKIM8ubJDOinykKwjqM2Z/y7rtVikU1K8aAFUf60ipPPwUY9x2LDlZxUj/M9RdodPp2DUtKWQc+EusrfrMxGST3jMuLcSRzou8ZUVGhaG66ozIrkEKGPAlWs3VWf0pjb6iF90FxIahpu372pv5/jRO8Ri6Pli1RYI41w5skAWTGzTa4LiZtVpZSNrkoh8Ut9P5MsNeSsq9SUshJvEcdVJB6ZVtzEQmWTEUsliBeNIGru3TP2qU72yDjx2InaDkA6MYyMLEspwd2nDhQrk0bpInUnnZu/+P+NIFe4dGmaFrE0jC136eHvp60R4Sr33H/NZeCSn7RZl+Os1fDakcyJtSNqEGCUc7SehOpL40nalbuJr/3KtSzxZUNhRvOM6lXrboox9cp1KmBhlxsyI2rEW44IYBeXakrqV6Vnb1fUjhh+pL0kn7lfFp/5Hg7Bzz2GUfrowyj9TTB9LXUp4fC40nvYb6iLXMBVP9Fy2fhtqfdAb45TRb4tiLAbJuMp+kHth9Lxclc/VtuUqbzH+iFHjj79O6VEAT+R9TBvZossX17m0Tbmn3A0IxHNln0KVyuVw7sJVZexeginz1kQmk/YvXF25h11X9/R3WvTD+m9+0kaAV9X98/LVGzh24nRkfvEdXFEGNDEmyHX/jGpDscWtWvlZyEgxMbRIx1/i/Hv2ov7dkN8IWYdIRkP4+nhB7kmN2g6GGLolnjhX71eJuUYk3+juiKoX8WtS9/V4p6uIrBJP3Bj1u5OY39n4rl+7Hfo3QPKVa/BKxG9CYFCwNmw/6H1O8qMjARIgARIgARJIGwRStVFEOtlSjU8VyS+7BN3Jf//TIyek4/b14tEY1fcjrJg9EPKWSzpcy9Z/FyOP9i3qYN+3c3U8Wd9CIkin6pOW9/3XfjZUvPHL70f03nkjD8USvmXZWEiZXT6qr4Od14t4oXxJfL96EtbNSvQZjAAAEABJREFUH4ZJQz7BnLHdsXL2IB3P0bHUJxGbY+rBvNV7NfUw5h/XTUGnVvUiQu7v5OFx9aYfIAaAb5aMwZj+bbB4Wj9dznt1qkZGnKYMLBJXwqXccQPaYv2CYcp44IthkxbF+FKCGEKWzuiP7asm4svPR6B983d0Xt/t/E3v49tMc6Es4TV+UDudTWMlpwzVFleqeCHtF30jHdahPT/U3q2a1NJMJL4M59aeERvpKH23coJm/O3ycahYtrjqOF3RBiCJIp2SIRM+l0N8uXA4Fk3ti1mju0GmZInn5HmrZeeSu3M3EB/3HKe/gDS2f1vd0XMpYbRIpZ4qqH0OH/tH75030hGQt8PRncPgtem73Tr6kB4t9aiTCYPa47sVEzBx8Cd4PHcOHRbXZoPqCEoHVdY5kWH/cp2sXzAcFco8pTuJB4+ejJJUOnYy9Wfv5lmav7QziTBj4Xq9wHFCdZTY9i95R3eyhtBv38zR1+k3S8fo9iuGEWvEGixi0BTjglz7P2+YBuEh7WRYr/C2s3DFZp1lmNWq2v0X+liuh2WqrcuUnd2bpiNvAtwkUXztN7FcpVNdtlRRfD65D3aun6qu30+liFhdYu+FsWXiqnyutC1XeV+4dA3ydSlpQ3KPFAPi/Im9IMexyRibX45sWfTaQ3JPmj6iM6YM7YjvVo7XBoflsXwtyJV72MzP1yvD7x29NtVXi0ZB8hWZ6tZ4OTYRYvj9d/GK9nNM/9Mn0TYyKqxowbza9+Ll63rv2NSu9qKuc/lNEL3EKCPtQYxjEkfaaWLvVwldI5JvbO7fcxe1t0wD0gcJbB7kdzY+2bwsZn1fkWLLlXpSH8u1K/cnV9qipKMjARIgARIgARJI2wRStVHEMXf/sZxZXapl+XKARPz4g7f02z85FvfR+2/JDl9v26P3jo2sRdKuWW3I23LxkwdcMTLIA3zbpvf9ixXOpx/A5UsnEk+cw9WtURkS7jiXdRHk+Nf9x2SnneQpw6tlqLy8Ndyi3ngfOhbe8Tx15ryO47zp3qYhxLgiHbxsWTIidzz6y7Sai1duRCaXcsSgIh7yYC1vWKWTULPK8+Kl3eOPZUeLhm/qUQ6/H4o6XLxJ3ap4xunNZxX1tlMSSedG9nG5BykrrrwexL9Dy7qRnGS49+uvlNfZODojMhpDRizIg7aMErGqzrS4/I/ngsxjP/7PuShvaXXiODad+k/R066k/Tz7EAvfStlSxIlT52QXxeXNnR0F1Bv16C5LxNorZrNZx5fOmYwAkBOTycAbSu9yqqMt53G5b3/Yq4PE4CVp5EQWh5WOixxv2/m77CJdhTLF9cKvDg/hJSMxpGN8+dr9tucIj75PbPuPnl44S/2KjBIm14SUL8fXb96WXeTaLC0aVdfXvtStuNdeKqfDHV/7OfnveUg7kGvixQoldZhspM2YH3L9gsRyFR2kgy9GpayZM6j6ziWixOoSey+MLRNX5TO70La+i2gjCfHesfuAFqXW6y9EMTrJwtE6wIWN1Lvcm4OCQyDGvG0790F0yZIpg76HyX3VORtX7mHrvwkfJScGZMMIH2Uoefj5+sguQee4r+TIFnUNoegJZS0o8XMeqSTnwk3qXI69vCz4OOI3at8fJ8QLib1fuXKN6Ixj2fx34ar2letUHySweZDf2YSu37iKdKUtxpWW/iRAAiRAAiRAAmmHgCkFVH1kRWTPGv7AefnaTZdkkNEgErHIE4/LLtKlT+enOxwyAiPSM44DGSIcFBwaI1TmWd+JZQ2D6BHFwCJv3KTD6FifQR7auw6agRfeag+Zty7HMkojelrHuUwzcBzHtZeH4FqvV9JvO6s36YnG7YbqqTTOOsqbR0n/dCwLVxYtFP4G87+L4Q/EEi82lzFDOu0tUyT0QRybpCgrjqwfyDtThvCFW8VoJBmc/S98nQoZsl66Sks4O5lCI3GuXr8luwTd9Zt3IG80ZQROm17jEX29mgQziIhwMWLtjyfyPRbhc383Wb0NlxEZ0Z3DwFc1wlgla+BIu5I2JbrJmhH3c4n96O9//9NGPkeHzRHLcd043hw7/GPbF4l4A37ZySAXWzzxS2z7lzQJuUwZo9av49qXaRrOdStsJC8xHsn+zH/h64vIm3k5T0qXWK7+fn4uF5/Ye2FsGbsqnytty1Xep86Ej0J4vtzTsYnkkp8Yt2Z8vgHPVvtIr2Eha2zI1A0xbkkGdptddnG66Pcwuc7l2nUYneNMGE+A49qRdUniiRY59S971ozxRUOBiHvAhUtXdbyzSXC/in6N6Ixj2eTMnkX7yrQVfZDAxlH3jvuFI3qifmejXb+OPKLvXWmL0dPwnARIgARIgARI4KEJeFwGqdooki9PTl0hf8WxCKcOdNoEqzeJcurt7SW7KE6MFeIhC+TJPrFO3iQnNo3jBWT7PpP0+iXSEZs2opOesiGfG3S8KUxsvo74w3u3Qv8uTSEP97KYpUzZkQUzZRqBxAmK4CGfWJRzZ2exhI80cDBzDnM+Nptca2JJUZZzuQ97bDbff/sred0LDJQdZJ2Zwd1bIDbn6hdwJO38CT31tBkZYdJz2Kwoa5foglzYSFqJVqZEEdklyonhbevycXjnzZd0Ohl9JAs3vtGom56Hrz3j2Ny5GxjrlyTkjbUkcV7XQM7jc4YRlXNscZOj/ZuilXvvXnj9yhtpqZ/ornubRlq023cC9F4WwtQHSbhJSq7RxUrsvTB6ejl3VT5X2parvG/dCV8PqGD+mIY/kckVN1MZRKYvWKc/DStTvdbMG4If1k6G8+i3+PIxm6Lew+5EGLedR/jFlz62sLwRU61kjZDYwh1+YoiS49w5s8kuQecYGZEU96vo10hchT+RL3yEkiwcHVccZ3/Hb8bD/M66KpsrbdFZNh6TAAmQAAmQQOIJMEVqIBD1aS81aOSkQ45smfQbbek8yqcPnYKiHIZZwxfTzPd4uBHlwqVrUcKtVhtkYT5ZeNEwEu7ERUmcyBMZmSBlycOcYRiQBRJlJIKsRSDz1v/3Qln9FR0ZkZLIrGNEF0NNo9qv6TnYst7DhEHtNC9ZAPHWnXt64VVJ5Pw1DzkX5xj+necx1x7WJU18ThZ5lfDkLMsaUc9STmKdo1OZT3Vm6tV6BbE5fz9fl7J9pkRhbVSYMKi97qjJIq2y8KBLiSMiyVcWZGFYOS0Ry0ge8U/I5XksO8Qw9uvXMyHrv8jCrTKKRb7qE19amYogI3uCQ6KOiHK0CQer+PI4HzHCKPr6JdHrKDnbv7N8jtE2YmCKrW5rVKmoo+fMHj76zNW34jqRi5uk4BpXUYm9F8aWT2LkS6htucr7sRxZtSgyOkMfPMBGpspIskXT+mmjpqwxlT1rJjgMuxKWGOeY8hL9dyIxeeTMnkWvayPTIeVaji2tfNVKrjMxWjsMjrHFEz/HfbPA4+EGCsc1mBT3K8k/Ple0UD4dvGLD97h1+54+jm0TFnH/Tenf2YTaYmyy0o8ESIAESCAOAvQmgVRKIFUbRQzDQI924W945XOVjmG7znUpa2LUfL83AgKDUbp4YR0knwrUBxGbbT/tU+FBeLZ0sQif5Nut/uoHXdaLz5XShTi+tBL9oVh0kQ6sjvQAG0krX89wJJUOfbVXn0PZUkW1l3Ra/Xy99SgSMSidPH1e+8tGHm5lqoUcP/3kE7J7aJecZWXMEP6JyIfpxBQrHP7gv3DlFr1AqrPCMs0pvi9/OMd1PpavHs0a3VUbouQLR/KJUOfw2I5lpJJ8/US+XCPhsvCt1J0cJ8bt3HMIN2+Fv4U3DEMbZ2QtBcnjxD8x1ygRf4crH3EdOD556fBfo9quHDuuIzmOzUkHbsuOvRAjY9bMGXSUuOooudq/LtRp80zEaJtpC9ZF+UyrRAkIDNJfI5Jj+VKP7Ddt3R1lDRmZRnblmmvTpyR9bO5hucaWp8PPMBJ3L3Skc967Kp8rbctV3kUjplltVLydZZEvYDmfx3d8IWKRUufRBbfvBuDU2fCpOfGljS1MpnnI+hmyoLbUuyOOtJO/Y1nfxxHuvDebTZG/TUMnfqGnMTqHy/13+ORF2qtTq3f1Pq6N3H/mLwtfCPi5ssV1tOS4X+mMY9nIF53EoCr69x/7GRwjaRxRRT5Z1LtNrwnay3F/SInfWVfaohaKGxIgARKIhQC9SIAE0g6BVG0UkWqsVfUFvPz8MxAjgnxaU6YISAd04pxVaNllNJp2HAFZvwOwq3il9Sc2pcPTe8QcbN6+B/I5yC4Dp0lW+ksD+iAJN9IJmzB7JaRD3G/UPAybtEi/QWzVuKYuRRbTlI6jjBaR9Q4WrvwGEk900REecHPj5m206TVeM5BpM1t2/Ar5yoMsQijrXRQrHP7Fni4RX8ORT7DKlxqkI/xR93F6oVAZZeJ4I/mAYkRJllxl5X88p2a6dN02zPxig2YtukQpPIETWZSxb8cm2mBVq2kfyBoF8uUfYfZuq/6Qz3gmkEWswfIWc/aYbjpsxJQlkFEj+iRiI8Yr6RzJGggd+k3Gm+/1RIsuo3Qnqvcn76H6a+EjGCKiR+7GzliGviPnxnDSOZFIIvvrjbpj7Izl+vOmKzZsxxDVOZOwJnVfl12crnnDN3WYGBpnLFyvp3Y5ritZgLR6xKgKHUltpGMyftZKSNuRz/i+1y78a0y92r+nQsP/4qqj/OrNd3K0//BS729frFBSLwYr19m7H/aHjMJZ89WPEPbVGvfAsg3bdGRZZLjaqxX0Yqstu47R94f+Y+bjDcVSOoU60gNuEss1scUk5l4YW96uyudK23KVtyx4LPUvRtjuQ2Zq3vLZ5HZ9JsYmYqx+lSuW1v5te0+EfHJavsBU8/1ekCmDOuABNq2b1NKpPugwXN8LZKSXtBMxlOgAFzayyLbca6XN1W7eF/I7INeh5FW7xaf6N0um+Djkd86yz4i5mPXFl1i44huIgVTu3xXKPAWZYinxkut+JXnH5jq3rqe/ZCa/H7Vb9NOfiZb7rVw/cn+Ue8WdiKlnLz+fcr+zrrTF2PShHwmkQQJUmQRIgATSNIFUbxQxmQz9ucQRfVrrrxfIw/WIKYsxb+lXkAdYeTifNOQT+Pn6wDAMzBrVFdLpkQ6cPIRLp1fmfy+fNRDSIUqotZjN5lijmNWbwdgC5C2/PKiPUB3i9d/8BPkyx5p5g+FYn0JGiMiimdIxkC/BSCdW4smXPyStc54mU3h1GkbcU3xMRnicbFkyaT2FgTyEdx00Q3c4KpUvgRF9WsGkuEneDj5BwaGQN5piLJI08vWDXu0bSxTtEirbEa4jx7FxtSwDhs7BFI+eOkLERjjJiAphO23+OgjrfRFfzTGM8LyMiDwjkkTunOWWL01IPhnS+0HWKBCjgxjNZLqT8IhMlMBB9LJktM2MkV10KunwRf+ajHQu5K3qgSN/6y+jvFenip7y5PhSkU4YsXHU2/af90M6BNGd43O5ryhDobQpMbL1Gj5bG0T+PvUfxAggH/oAABAASURBVPDz/LPxL2qZLUtG/elimeI1XRlFpO3IdSVfQ5HPpcq0LBHHMAzZwdfHC2KEkrYjxpHrN+9gdL+P8UqlZ3S4bOKqIy8vC1xt/xHFqbYb3sYl37icg5Nhuh937IC2+KRlHcjIAuk4Dxg7H8JeFkl2LNgo+Q3s2lx/slk6s3J/kE/7fti4BmT0gIQn5IyItha9/SaWa0LlRA83mVy/FzrSOu4Xcu6qfK62LVd4y1pO88b31GzFSC28ZaSUdMJFJsMwZBevE+OhTD+U+hLDgxi8Kj1bQtehJDSM8Dwc17phhJ9LmLNzhItf/bdeRfMGb+pRY3IvEMNy6acLRxol4shCkkY6uU4WTOoFx+fB5XdADJOSl6+PF2Rdm9GffhwZ3/lA1u2ZOn8txs5crn/HZG2gacM7OUfBw96vpL1Ihs7XiJzH5mQ60qYvRkGMRXfuBkKmYIpBRK4fuT/KJ4T7d22qkxqG8dC/s3HJFv131tW2qAXjJg0RoKokQAIkQAIkEJXA/R5BVP9UdSYPUPJQtmXZWPz2zRxsWDAcm74YqY/njO2O118uD8MIfxDOlDEdZK2HPV/N1B3P71dPgqQr9VTBKExWzB4IWYcjiqc6WT13cKz+6+YPw871U1WMqH8tG1XH/m/n4pulY/DLphmQr4XI23HnWPKJ1O9WTtAdUclHdGjX/B1djpw74r6o3nYf2bEQ8tlYh59j7+frDQkTA5D4idFF9Dy47TN8u3yczlsWb503rgeij/4QPsJj85IxOt4+Ja989td5oby4ys6ZPbMud2DXZlJsgs6VsmQNDdHF8QnYBDNVEaQDLmylPrevmohRqlOuvCGdK8lL1kuQc4eTqUTiX8Np1INhGHpkhqQXVusXDNMLNsqaHMLDkTau/dCeLTWL6GVJfJFPyhPnmDIg7UvOHU7aj7Svfp0+0NOaJF10J0YbR/zY9iKDpHnrjRd0uxY9pA1JG5DjhEaJSFpxYhCRdLJgpci0W7XdWaO7QTpHEi4unb+v1lfk/mnDVAivLxcOh7Q5+fKRxHF2wiC2OnK1/bdvUUeX55g6IHnHdZ0KQ+GTO2dWiaadfOa1bdPakPrcsWaSvk/INfn14tF4+40XdRzZyD1CjD/SltZ+NhRyPUjHVtqF6Cpx4nPxtd/EcJ0wqF18xcQa5uq90C/a/cKRmSvyudq2XOUt9fndigmQepD7ttSJdL6l/ob1+tAhWpx7uQctmzlAp5e2uuvL6RjTvw2kDiUPqU9JnJh7mBg0erRrpO/ZOs+N07XxXdZ9kjyj30Ml/9ic5CMGNWk3jmvp5w3T9G+FrG1jGOG/S9HTjld1/+vXs7B5yWj9+yFrA8m0Hud4hmG4dL9KzDXinH/0Y38/H30/lfuWMJZrQ347d2+argztrSGGKUcaYT5hUHvI74rwk2tJ4pZy8Xc2tutXuC+c1NtRhN672hZ15NS6oV4kQAIkQAIkQAIJEkgTRhFnCvKwL53SgvlzQ46dw5yP5QFTFriTB2pn/+Q4FuOCPETLG+m48pc3ptIhERef3HGlj8tfHsplBIzkG9/irdKZyv94Tkg8kSWu/JLCPznLkvrMlSMLpIyHkVVYifFCjACGEXvH5WHyT6m0oofUqbQBr4gvCiWmbNFfrhNZHyW+dNJmhFfhJx6HtLn44sZWR5Je5BSXlO0/NjkMw4Aspin3ifiuSZFTOuwiW2z5PIyfq1wfpgzhKDomdC+MrQxX5HO1bRlGwrzlepU1aETW6KMBYpMvup8jvbRV6ZBHD3/Qc2kfOs+IT48/aD6SzsFUDNZynpATo2P+x3NBfj8Siit1IdeflGEYyX+/EsZybcgoy/iu96T+nY2Lg+gv944Hvc/FlS/9SYAESIAESIAEUgeBNGcUSR3VRi1IgARIgATSMAGqTgIkQAIkQAIkQAIkkEQEaBRJIpCJzaZoobyQqQzlyzyV2KSMTwIkQAJpiABVdRCo+nJ5/buRM3sWhxf3JEACJEACJEACJEACD0mARpGHBPigyR/LkRV1a7ysP4X6oHkwHQmQQCojQHVIIB4CsuaG/G7IdJB4ojGIBEiABEiABEiABEggEQRoFEkELEYlARJIOgLMiQRIgARIgARIgARIgARIgAQeNQEaRR51DbD8tECAOpIACZAACZAACZAACZAACZAACbghARpF3LBSPFskSk8CJEACJEACJEACJEACJEACJEACnkGARpGHqSemJQESIAESIAESIAESIAESIAESIAES8FgCLhtFPFZDCk4CJEACJEACJEACJEACJEACJEACJOAygbQUkUaRtFTb1JUESIAESIAESIAESIAESIAESMCZAI/TOAEaRdJ4A6D6JEACJEACJEACJEACJEACaYUA9SQBEohOgEaR6ER4TgIkQAIkQAIkQAIkQAIk4PkEqAEJkAAJuECARhEXIDEKCZAACZAACZAACZAACbgzAcpGAiRAAiTwYARoFHkwbkxFAiRAAiRAAiRAAiTwaAiwVBIgARIgARJIMgI0iiQZSmZEAiRAAiRAAiRAAklNgPmRAAmQAAmQAAkkJwEaRZKTLvMmARIgARIgARJwnQBjkgAJkAAJkAAJkEAKE6BRJIWBszgSIAESIAESEAJ0JEACJEACJEACJEACj54AjSKPvg4oAQmQAAmkdgLUjwRIgARIgARIgARIgATckgCNIm5ZLRSKBEjAcwlQchIgARIgARIgARIgARIgAU8hQKOIp9QU5SQBdyRAmUiABEiABEiABEiABEiABEjAgwnQKOLBlUfRU5YASyMBEiABEiABEiABEiABEiABEkhdBGgUSV31mVTaMB8SIAESIAESIAESIAESIAESIAESSPUEaBRBqq9jKkgCJEACJEACJEACJEACJEACJEACJICYCGgUicmEPiRAAiRAAiRAAiRAAiRAAiRAAiTg2QQovUsEaBRxCRMjkQAJkAAJkAAJkAAJkAAJkAAJuCsBykUCD0qARpEHJcd0JEACJEACJEACJEACJEACJJDyBFgiCZBAEhKgUSQJYTIrEiABEiABEiABEiABEiCBpCTAvEiABEggeQnQKJK8fJk7CZAACZAACZAACZAACbhGgLFIgARIgARSnACNIimOnAWSAAmQAAmQAAmQAAmQAAmQAAmQAAm4AwEaRdyhFigDCZAACZAACZBAaiZA3UiABEiABEiABNyUAI0ibloxFIsESIAESIAEPJMApSYBEiABEiABEiABzyFAo4jn1BUlJQESIAEScDcClIcESIAESIAESIAESMCjCdAo4tHVR+FJgARIIOUIsCQSIAESIAESIAESIAESSG0EaBRJbTVKfUiABJKCAPMgARIgARIgARIgARIgARJIAwRoFEkDlUwVSSB+AgwlARIgARIgARIgARIgARIggbRJgEaRtFnvaVdrak4CJEACJEACJEACJEACJEACJEACEQRoFIkAkRp31IkESIAESIAESIAESIAESIAESIAESCBuAqnFKBK3hgwhARIgARIgARIgARIgARIgARIgARJILQSSVA8aRZIUJzMjARIgARIgARIgARIgARIgARIggaQiwHySmwCNIslNmPmTAAmQAAmQAAmQAAmQAAmQAAkkTIAxSOAREKBR5BFAZ5EkQAIkQAIkQAIkQAIkQAJpmwC1JwEScA8CNIq4Rz1QChIgARIgARIgARIgARJIrQSoFwmQAAm4LQEaRdy2aigYCZAACZAACZAACZCA5xGgxCRAAiRAAp5EgEYRT6otykoCJEACJEACJEAC7kSAspAACZAACZCAhxOgUcTDK5DikwAJkAAJkAAJpAwBlkICJEACJEACJJD6CNAokvrqlBqRAAmQAAmQwMMSYHoSIAESIAESIAESSBMEaBRJE9VMJUmABEiABOImwBASIAESIAESIAESIIG0SoBGkbRa89SbBEggbRKg1iRAAiRAAiRAAiRAAiRAApEEaBSJRMEDEiCB1EaA+pAACZAACZAACZAACZAACZBAfARoFImPjgth568FwlPdjTshWsPAYKvH6uCp7JNBbo+vw9v3QnE3MMzj9WDdeu490bnu5ObofM7j1FGvnliP8ht9424I740e/Lzlie0uNpmv3gpGSJiNbZFt0S3aQKjVjis3gx6pLPKsQJc6CNAokjrqMY1pQXVJgARIgARIgARIgARIgARIgARI4OEJ0Cjy8AyTNwfmTgIkQAIkQAIkQAIkQAIkQAIkQAIkkCwE3MookiwaMlMSIAESIAESIAESIAESIAESIAESIAG3IuAuwtAo4i41QTlIgARIgARIgARIgARIgARIgARSIwHq5MYEaBRx48qhaCRAAiRAAiRAAiRAAiRAAiTgWQQoLQl4FgEaRTyrvigtCZAACZAACZAACZAACZCAuxCgHCRAAh5PgEYRj69CKkACJEACJEACJEACJEACyU+AJZAACXgmgf1/nMDGb3e5LLzEb9xuKK5evxVnmpVffo+O/afEGe5JATSKeFJtUVYSIAESIAESIAESIIGUIMAySIAESCDVENjwzc/oPWKOy/rcvReIQ0dPIjTMGmeai1eu448/T8UZ7kkBNIp4Um0ltaxBgbCe/BP22zeTOmfmRwIkQAIkQAIk4DEEKCgJkAAJkEBqJtCzfWPs2jg9Nav4ULrRKPJQ+Dw3sWXzUhgd38adPq0Q0r42fGYOAEJDPFchSk4CJEACJEACrhBgHBIgARIgARJwQwIyHaV551EICAyOIt2kuavRd+Rc7bdwxTeo8X4vVKjeRrtW3cfi4NGTOkw2cvz+J8Nx8vR5TJ2/FhK+dN02fLVtNwaPXyhRtNv92xHUaz1Q51Hi1eao0/JTfPntzzrMefP9z/sh+Umchh8Pxh9/xT8yZOeew5HxqzXugRmfb4h3tIlzWY/ymEaRR0n/EZVtXD4P743qorBaIyUwH9oNy+5vI895QAIkQAIk4PkEqAEJkAAJkAAJkIBnECj9dGHsPfAntu38PVLgW7fvYe6STShS8HHtd+deAN54pQIGd2+BAV2a4s6dALTqNhYy3UUi3L5zD7IeyNvN+mLrD78hW5aM4o0Ll67hwJG/9bFsbt+9h1LFC+HTzh9gwqD2eLJwPvQZMRf7Dp+Q4Eg3cc4qlCtVFK3eq6kNIi06j8a9gKDIcOeDnXsOoU2v8cibJwcmD+2Aaq9WwPQF67Bo9RbnaG55TKOIW1ZL8gplOq8sfHZ7jEJMp47F8KMHCZAACXgIAYpJAiRAAiRAAiRAAh5L4Kki+VGyWEGs3LgjUodvvt+jj99+40W979CyLjq3roc3Xi2PSuVLoHnDNxEQGIR/Tp/X4Y7NyL6t8eXnIzC638d4r04Vh3fkvtqrz2Fg12Z4+40X8Hy5p/HxB2/rsINOhhPxWD6zP7p+3ABdPqqPz8b31GX9sPugBMVwE2avxIsVSmJU349QtfKzOp0YRtZv/ilGXHfzoFHE3WokBeR0SVK2AAAQAElEQVSx+6eLtRR7xiyx+tOTBEjA3QhQHhIgARIgARIgARIggdRG4L26VbHv8HGcOnNBq7Z8w3bUrPI8smfNpM///PuMnhLzTJUP8UrdTug+ZKb2DwoO1XvHpkKZ4o7DWPc3bt1Bv1Hz8FyNtnjh7fZ4q2kfHS8wOOpyCv7+ftpfNk8Xe0J2+O/iFb133oSGhuH4P+dw7MRpPS1HpuaI27nnMGQqj3NcdzymUcQdayWZZbIVfBr2rDmjlmIywfp81ah+PCMBdyBAGUiABEiABEiABEiABEggDRB4/eXy8PfzxfpvftIGBjE01Kv1qtb81p17eLfVAD19Zd64Hti+aiLWLximwxK7addnEn785SAGdW+OzUtGY+/m2ciaOYNL2RiGESNeiDKKiGeVl55Fp1bvRroJg9ph1uhuEuTWjkYRt66eZBLOyxtBPaYANd+DkSMXYLcj9MUasOUOt/4lU6nM1gUCjEICJEACJEACJEACJEACJJA2Cfj7+eDdmi9DFkeVaTQF8uZChTLFNIxDR//R+57tGumpM7lyZIGPt5f2S8xG1h+Rz+02a/CmHoWS//FcyhDjk2AWvx38S8cpmC+33jtv0vn7aqPK7bsBqFyxdBT30nMlnaO65TGNIm5ZLckvlD1zNtjrtoL/h8pyp6x9pv/CL7LkLzmyBB6QAAmQAAmQAAmQAAmQAAmQAAk4EahTvTJknRD5Gk2TulVhGIYOLVEs/AX2qo07IEaNrT/+hq6DZuiwxGzSp/ND8aIF9EKsv+7/E/IlGpmGc/3mnRjZyNdnTp+7pL9MM27mcogh5qWKpWLEE4+2zd7Blh2/QtYWOXHqHI789S+WrN2Kj3uOl2C3djSKpEj1uG8hltIVALMFpn+OAoH33FdQSkYCJEACJEACJEACJEACJEACqZxAscL5ULZkUa1lzSqV9F42Mr2lR9tG2Prj72jcbig6D5gGiSthEXYTOdQu5rmh/R0bWTj15u27aNFllF6jxGwONwtETzdv6Sb9CWD5Mo3VasPMUV0jR6cYRtQ8G779P/Rq3xjL1m/HOy0+RYOPB2HElCWQBWQd5brrPlz7pJSOeXkUAcPiBVOJcpAmbf7jF4+SncKSAAmQAAmQAAmQAAmQAAmQQGojsHhaPxzZsRCZM6WPolrzhm/ipw1TsemLkfjtmzkY3ruVjlehzFM6XuWKpfX5Yzmy6nPHRr5aI2uQOM7lKzHfLB2j89m1cbr+So2U17ZpbR3Fkc93Kybg2+XjtJP4DiOMRIrMU06UE8NK0/rV8OvXM7FjzSR8v3oSDm2br79Co4Ld+o9GEbeunpQRzlQm3AJpObw3ZQpkKSRAAiRAAiRAAiRAAiRAAiTgYQTcQVxZR6Rg/tzw8/V+KHEMw4DkkylDujjzMZkMPP5Ydu0MQ16jxxk1MsAwDOTIlhk5s2eGGEoiA9z4gEYRN66clBLN9GxlXZTp8G696Ko+4YYESIAESIAESIAESIAESCCtEqDeJJBmCNAokmaqOm5Fjaw5YMuVD0ZQAMynjsUdkSEkQAIkQAIkQAIkQAIkkOoIUCESIIG0TIBGkbRc+066W0tW0GemP37Ve25IgARIgARIgARIgARSIQGqRAIkQAIkEIUAjSJRcKTdE1vJilp58x979J4bEiABEiABEiABEvB0ApSfBEiABEiABBIiQKNIQoTSSLj1yWdg9/KB6ezfwJ2baURrqkkCJEACJEACqYYAFSEBEiABEiABEngAAjSKPAC0VJnEZIbt6We1apZDu/WeGxIgARIgARJwTwKUigRIgARIgARIgASShgCNIknDMVXkYo2cQsN1RVJFhVIJEiCB1EGAWpAACZAACZAACZAACSQbARpFkg2t52Uc9swLWmjTkb2AzaqPuSEBEiCBlCTAskiABEiABEiABEiABNyXwK3b93Dj1h3Y7fZIIX8/dBx/n/ov8jy5D06cOod9h48nWTE0iiQZylSQUYbMsOUtDCM0GKYTh1KBQlSBBNyaAIUjARIgARIgARIgARIgAbcnYLXasGz9NlR+pwNeeLs9XqrdAc/VaIsJs1dq2ecv/xrbftqnj1Nis/XH37Fw5TdJVhSNIkmGMnVkZCv5nFbEfJhTaDQIbpKIALMhARIgARIgARIgARIgARJILgI2G3D+gh2XrgBOgziSpDgxekyYvQp9OryPvZtnYef6qRjcvQU2fZc61qKkUSRJmknqycRaIsIocoRGkQeuVSYkARIgARIgARIgARIgARIggRQicPykHT0GhmLAqDD0GxaKfsNDce78/ektDyPGrTv3MGnuanRv0wA1qlSEv58vsmbOoI+/Xjw61qy/37UfbzfrixKvNscHHUbg+D/nIuMtXbcNNd7vhQrV26Be64HYseuADgsMCsGoaUv1aBRJu2TtVoifBAYEBmHQuIU6jYxW2fDNT+KdZI5GkSRDmToyshYuAbuvP0wXz8C4eTVBpRiBBEiABEiABEiABEiABEiABEgg6QgcPGJHYtz8xVbcun2//MtXgPlLrInK4/DR2I0o/5w+rzOuUjn8S6X6JGLj6+MdcXR/J2uLfNJ3Ml57qRwWTe2LHNky4cOuoxEQGIz9f5zA8MmL0KnVu1g641M0ePt/OH/pGuTfaGUQ2X/4BMYOaIt+nT/AkrXf4bsff5MgjJ25Aj/uOYjen7yHaSM6o1CBPNo/qTY0irhOMm3ENAxEfoXmwM9pQ2dqSQIkQAIkQAIkQAIkQAIkQAJuQCAkBJg6J8xlN2V2GK5ci2nQOHPW7nIeUt7MBWGxan/56g3tnzVzRr1PaPP19l+QN3cOdG5dD+VKPYl+nT7A9Zt3sGf/UQQFKeVUBv5+fiiYPzcavPUq3qtTRY8IWbVpB2q/+RIyZUiHjOn98WKFkti68zeEhoZh5Zff45MWdfBuzZfxzNOFUap4IZVL0v3FYRRJugKYk+cRsDrWFeEUGs+rPEpMAiRAAiRAAiRAAiRAAiTgsQS8vYFnShguuzIlDVjMMdX19klMPoYyNBgxM1E+ObNnUVvg6vVbep/QRkZ+lC1VNDJatiwZkStHFly8fB3lnymGhrVfQ5te4/FMlQ/RddAMnLtwRYVd0/HXfv0jhk9erN2xE2eUXmZcvHJdh5UpeT9P7ZGEGxpFkhBmasnKWroSxNZoOrYPCAtNLWpRDxIgARIgARIgARIgARIggbROwAP07/CRBYlxLz0fs1tf6w1zovJo29ISK5lC+cOnqmyNmMriHEmmxDify3G2zBnx199n5FC7ewFBuHTlhl6HxMvLggFdmmLXl9Mxa3RXnDpzHtMWrENWZTiRyEN6tMDiaf0i3YRB7fFYzmwShEvKqKIPkmETk14yFOIpWYZZrbDZxBzgKRInk5x+6WB/4ikY1jCYxTCSTMUwWxIgARIgARIgARIgARIggeQjwJzTBoHG9cxoUt+MZ58xUPFZE1p9YEb1qknT1c+UMR3aNauNEVMWY93mnbhzNwBXrt3E19v2oFbT3jEAv/RcKb2w6pYdv+q4C1ds1nFkKs3OPYfw1bZf4O3thYpli6Nowbx64VaZMiPnI6cuxQVl/AgNs+KPv07h81Vb4GUxo0rlcli8divO/HcJh4/9g+0/qZf3Otek2SQNqaSR5ZHmIivb1m3ZX1XuL1Hk2LZzn141t8SrzaPsg0NS9wgKa8mKmoP5jz16zw0JkAAJkAAJkAAJkAAJuDEBikYCaZaAshvgfy+ZIKM9Wjc14/nyJhixz4Z5IEYfffA2urdpqAwjS/B8rXZ49d3OGDhuAWpVraTzM6nC1J8+rlS+BD5pWUdPjZG4C1duwZShHZEjW2Zl4LBAviJT/s2PUPaN1rh5+y5aNa6h043s+xHSp/ND1QZdUabqh2j48WDcUuES2KJhdfy6/09Ub9ILLbuOgYw4Ef+kcqakysiT8xk3awWkYk5GrKzrrIsddm29+nrxaDg7b6/Yhxc5p/XkY2vJClp808Fdes8NCZAACZAACZAACZCAuxCgHCRAAiSQcgRktEaLRtWxd/Ms/LhuCr5fPQl7vpqJrh830EJMHd4JH73/lj6WTdumtfH7ljnYsmwsdm+arkd6iP/zzz6NX7+eiR/WTlZ5zcacsd2R57HsEqTXHZk5qotOt33VRBzc9hk6fviuDitbsih2bZyOb5ePwy+bZmDZjP7a0KIDk2BDo4iC2KpxTWxbNUFXhDqN8efr44UCeXNFcYaRhKa3GCU+eg9bgWKwp88E061rMF04/egFogQkQAIkQAIkQAJpkwC1JgESIAEScBsCsnBqzuyZYTLF3x/29fHWX6GxmKOuAmsYBrJnzQR/P59YdZJ0sjBr9HRimHlcGVDM5qQ3YSR9jrGq5t6emTOlx2M5ssLLEvvoj+s376DvyLkYPOFzPQdK1h5BGvhnLfW81pJTaDQGbkiABEiABEgg2QmwABIgARIgARIggZQlQKNIArxzKWOJDBUqmD+3jtlz6CyMnrZUH8vGx8sET3UWiyEqaCtfbDqYnglfV8RydK/H6hibXvQzuWV9WswGzMrizPpxz/pJa/UC9S+t6fwI9HXLe5G7cZA3cXJ/dDe5KE/au1d7WUx6jQLWfdqre3esc8MAvFWbfJSyqUcF/qUSAqZUokeyqVHqqYJ6UZnWTWphYNdmGNqzJZau2wbHaJH0fl7wVOfrHT4yxkt1RmPTwf+5lwDDBOOvQ0hnsnqsnrHpRj/3a7feXmZ4KyMj68b96iYt1gnUv6TVm/VKng/WBrzUb7T8XpPfg/Ejt6Tj5u9jhsVk4vOgBz/7p6brwWwY8PO1PNL2qB4V+JdKCJhSiR4ppkaObFl0WWFhVr2/djsYnuruBoRqHYJDbbHqcD3YgK1IKcBuw63dP8Uax1N1p9zu124DgsIQGGxlO/Pge0rkdZUKdJCbY2rSh7q43z3P1TqR3+i7gaG8N6aC+4qrde6u8W7dC0WoNfZnRneVmXJ57r0voboLs9lx627II703yrMCXeogQKOIqkcZ9REaGqaOgNCwMDiOxUNGhfx+6Djkk70Xr1zHnMUb9TeVfX28JTjVO2up57SO5iO/6j03JEACUQnwjARIgARIgARIgARIgARIwHMJ0Cii6q7n0Nko83ornLtwBZ+O/kwfnzpzQYUAFy9fQ9OOI/Qne6vU76qnzQzp2VKHpYWNtUSEUeTQ7rSgLnWMnwBDSYAESIAESIAESIAESIAESCBVEaBRRFXnhEHtcGTHwijOsbCqfHtZvrH8zdIx+HnDNP1N5Ly5cyCt/LPleQK2TNlg3L0F0+njaUVtAFSVBEiABEiABEiABEiABEiABEggtROgUcSFGpapMvny5IR8uteF6J4XJQGJrc9U0jE4hUZj4IYESIAESIAESIAESIAESIAE0hwBm82OC5evIyAwOFXpnuaMIqmq9lJIGVvEFBrTH7+mUIkshgRIgARIgARIgARIgARIgARIwB0ISgYdRwAAEABJREFUyJqb0+avQ6nXWqBqg66oUP1jNG43FH+f+s8dxItXBlcCaRRxhVIaj2N9ujzsZgtMp44BgffSOA2qTwIkQAIkQAIkQAIkQAIkQAJuRsBmhe3sKdgunAXs9iQVbspna/H5qi2YNbor9n07F9+tnIDcObNqw8it2/eStKxHkRmNIo+CuqeVafGC7amyMJTcZi64qijwjwRIgARIgARIgARIgARI4NERYMnOBMKOHsCtNnVxu9sHuN2psXbW0387R3ng4+s372D+8q/Rv8sHqFyxNHy8vbRBZESf1vD18cKSdd/pvDd+uwtdB81A/zHzUaF6G1Rr3AM79xzSYbI5f/EqOvSbrMNadR+LLTv2ird2MupkzuKNqNd6oA4fP2slAoNCdFhKbGgUSQnKqaCMyK/QcApNKqhNqkACJEACJEACJEACJOAxBChomiMQ+vvPSIwLmDEc9pvXIjnZLp5DwIwRicojbP8vkemdD/49e0GfvlKpjN47NrLuZtWXy+PPv09rr2s3bitDx6/ImT0zxg1oiyIFH0ffkXN1WGiYFWIIyZDeH19M6YO61V9WBpTp+E8ZSiTCoaMnsWnrbrRsVANj+7fB8g3b8dvBPyUoRRyNIimC2fMLsZasqJUw/7EnyYdj6Yy5IQESIAESIAESIAESSPMECIAE0jyB4CDcG90rEa4nbJfPx8AWduqvROTRC3cnfBojD/G4cu2m7JApQzq9d95ky5wR5y9ei/SqVL4EOrSsi1cqPYOBXZtDRpmcPncJvx/6C7KvW+NlHbdg/sdQslhB/LD7oD6XzeAeLVCjSkW8+kIZvPZSWfzy+1HxThFHo0iKYPb8Quw5csOWKx+MoACYTx7xfIWoAQmQAAmQAAmQAAk8WgIsnQRIgARiEvDxhdezLybCvQSYLTHyMfn6JyIPVV7Z52PkIR45smWRHWJbO+Tq9VvI81g2HR59IyNG/P189UiS8xEjQibNXY3hkxdr5+VlQWBQ7F+xyZjeHwFxhEUvJynOaRRJCoppJA9ryQpaU36aV2PghgRIgARIgARIwGUCjEgCJEACJOAqgXS9RiMxzvt/tWJk7VO3aaLySNd1WIw8xENGdch++8/7ZBfpAoNCsO2n31HiyYKRfs4HMjUmIDAIWTNnRLYsmSAGkoWTe2PxtH6R7sPGNZyTPLJjGkUeGXrPKzjy07xH+Glez6s9SkwCJEACJJBiBFgQCZAACZAACaQgAf+WneHXqhu8nn8VXi+9Dv8OA+D7dpMkkSBLpgx6rY8RU5Zgx64DCA4JxYVL19Br+CwEBYei0TuvRZZz7fotXL56E2fPX8bU+WuVQSQDSj5VCGVKFtFxxkxfDjGUiJOpM9/t/F37P+oNjSKPugY8qHxrsTKwe/nAdPYkcCd8bpkHiU9RSYAESIAEkoEAsyQBEiABEiABEnjEBCxe8HmjDmS0R7qOA+Fd+Q3AlHRd/Y4f1kWz+tXQvu8klHujNao27IZLl29g2Yz+UdYaOf7POfyvXme8+V5P7D98AtNHKGONr7eOM2dsN/z06yH9dRn5Ok33ITNhqP9xkTMMI66gJPdPOlJJLhozdDsCJjNsTz+rxbIc3KX33JAACZBAGiJAVUmABEiABEiABEggzRGQ9T8+aVkHh7cvwNbl4/Dr17OwYvZA/YUZZxiVypfAga3zsHP9VGxZNhalny4cGVy2ZFF8vXg0dm2cjh/WTlZ5zESVyuV0+JEdCyHh+kRt+nX6AAO6NFVHKfNHo0jKcE41pdz/NO+eVKMTFSEBEoiNAP1IgARIgARIgARIgARI4D4Bk8lAnseyI52/733PaEdiQMmaOUM03/un8hWb7FkzwTBSbiTI/dJjP6JRJHYu9I2DgLVU+Kd5TUd/B2zWOGLRmwQ8jADFJQESIAESIAESIAESIAESeGACL1QoiWb133zg9I8yIY0ij5K+B5Ztz5wdtryFYYQGw3z8/nelPVCVNCsyFScBEiABEiABEiABEiABEiCBpCTwZKG8qFyxVFJmmWJ5mVKsJBaUaghEfoXmD7efQpNqmFMREiABEiABEiABEiABEiABEiCBpCdAo0jSM31EOaZcsWEln9OFmf/Yq/fckAAJkAAJkAAJkAAJkAAJkAAJkIAnEvBMo4gnkk5FMtsKl4Dd1x+mS2dhXLmQijSjKiRAAiRAAiRAAiRAAiRAAiRAAm5FIJmFcTujyIXL15NZZWb/0AQMA9bI0SKcQvPQPJkBCZAACZAACZAACZAACZAACQAghJQn4HZGkRGTF6FOy0+xYcvPCAwKSXkiLNElApFGkSO/uhSfkUiABEiABEiABEiABEiABEjAiQAPScAtCLidUaRZgzfxWM5s6DtyLl6u0xFTPluDC5euuQUsCnGfgLX0C7CrU9Of+4GwUHXEPxIgARIgARIgARIgARIggdgJ0JcESMBdCbidUaT8M8Uwc1QXbF4yGo3feQ2LVm9F1Ybd0HXQdPx28C/Y7dIVd1ecaUcuIyQIRrqMMJRBxK9nffgsHA3jFo1XaacFUFMSIAESIAESIAESiIMAvUmABEjAgwi4nVHEwS7/47nQ9eMG2Lp8HMqVehJbduxFs04jUbt5P6z9+kdOrXGAekR7r9WzgHu3AcOAEXgP5j3fwWvNHPAfCZAACZAACZAACaQlAtSVBEiABEjAswm4rVHk3IUrmDR3NV5v1B37Dh9H6acLY0CXpiiQNxf6j5mPd1v192zyHi69+UjMz/Ga/9rv4VpRfBIgARIgARIggXgIMIgESIAESIAEUh0BtzOK/H7oONr3nYRqjXtg7pJNqFnleayeOxjLZvRHw9qvYerwTvh68Wi88+ZLqa4yqBAJkAAJkAAJkIC7EKAcJEACJEACJEACaYGA2xlFFq7YjL9P/Yde7Rtj15fTMah7cxQvWiBKXchokY/efyuKH09SloC1RIUYBVqLlY3hRw8SIAESIAEPIEARSYAESIAESIAESCCNEnA7o0jLRjWwfNZANK1fDZkypouslqDgEPx38SoXWo0k8mgPQuu1gbViVdh9fKEqBfZceRH67kePViiWTgIkQAIuEGAUEiABEiABEiABEiABEnAQcDujyPzlX2P5hm0O+SL3585fwRuNuuPi5evgv0dPwJ4pG4Kb90Jwu6GQxVbt3r4QP/AfCZCAOxGgLCRAAiRAAiRAAiRAAiRAAvEQcDujSFyypvP31UG37wboPTfuQcBW8GnY5Qs0504CoSHuIRSlSKMEqDYJkAAJkAAJkAAJkAAJkAAJJI6A2xhFVmzYjgXLN+Pk6fOQxVbl2OHmLN6IzgOmIWvmDCjyxOOJ05Cxk5eAlzfs+YrAsNthPvlH8pbF3O8T4BEJkAAJkAAJkAAJkAAJkAAJkMBDE3Abo8h8ZRAZN2sFTp+7hN2/HYEcO9zcJV9BFlcdO6AtzGa3Efmh4aeWDGyFntaqmE4e1fuk3jA/EiABEiABEiABEiABEiABEiABEkgOAm5jYdiybCyO7FiIZvWr6S/OyLHD7d08C2P6t8Hz5cI738kBwk3y9EgxbIVLarlNp2gU0SC4IQESIAESIAESIAESIAESIAES8AgCj9AoEjufnu0bo36tV2MPTGbfMKsVNps91lLu3A3AjVt3Yg1L656RI0X+5vSZtN4WqD8JkAAJkAAJkAAJkAAJkAAJxCTgvj5uYRSRdUQmzV2tjQ7bf96PL1ZtidMFh4QmC83AoBDUbdkfX2/7JUr+AYFB6NBvMp6v1Q4v1e6Axu2G4ur1W1HipPUTW9acsGXKCiM4EKbz/6Z1HNSfBEiABEiABEiABEiABEggLROg7h5FwC2MIufOX8HcJZtw+04ANm3djdHTl8XpgoKT/gsnsnZJ+Tc/0ou8Rq+9peu24fg/5/D96kn4ZdMMmE0mTJ63Jnq0NH9uK1JKMzCdPKL33JAACZAACZAACZAACZAACaR+AtSQBDydgFsYRV56rhT2bp6N/I/nxIRB7fTaIo71RKLvM2VIh6T+16pxTWxbNQG5cmSJkfU33/+KerVeQc7smZEhvT8+qPc61n79I+z22KfZxMggjXhETqHhuiJppMapJgmQAAmQAAmQAAmkOQJUmARIIBUScAujiHxRxt/PB4ZhIDQ0DLfu3IPVatO4w6xW/Lr/Txz+85Q+T45N5kzp8ViOrPCyWBD9n3wNJ//juSK98+XJqY9v3w3Qe27CCdgKldAH/AKNxsANCZAACZAACZAACXg4AYpPAiRAAmmDgFsYRZxRz136Fao26Ia7AYF6NEaTdsPQossoNGozGJ8t+9o5arIfy2gQWVPE18c7siwfby99HBAQpPc+XiZ4qrNYDK2DyWQ8tA5ehZ6E3eIF0+Vz8Am+89D5eSpTym164Lq3mA2Yk6Atsg4evA7I7j47qH/kcZ8HWTw6FvIbLfdH1kEy14EHP8+lVNvwspjUC0w88O98SsnJctLGtaLepcNbtclHWd/qUYF/qYSAyd302P3bET1dRabJ/PL7Ufzx1ykM7t4CnVvXw5K1W1NUXMMw4O/nC+fFXR3H/v6+Wpb0fl7wVOfrbdE6eKnO6EPrkN4XliJP6/z8zvzpsUwemoMHt4dHrbu3lxne6qH0UcvB8j33npaUdQf1LynzY15sVw/aBrzUb7T8Xj9o+tjS0Y/t8UHagL+PGRaTic94fNZzizZgVv00P1/LI5VFPSrwL5UQMLmbHpev3sCThfJqsfYf+VsbJepUr4yGtV/DpSs3INNZdGAKbQrkzYUz/12KLO3s+cv6OGN6f72/djsYnuruBoR/ySc41JYkOgQVKK6Z3PvjYJLk56lcKfeDXRMBQWEIDLay7XjwPSU1tX25maUmfdKwLh5/T5Hf6LuBoR6vB9vgg/02uhO3W/dCEWpNmmdGd9KLsnhm2wyz2XHrbsgjvTfKswJd6iDgdkaRnNmz4NiJM3rqzDfb9+D5csUha47INBZBnhxfn5F1S2QtE8k/NCxMr2six+KqvVoBqzbuwOWrN3H3XiAWrd6KujVehmEYEkznRMBWKHykiPmfI06+PCQBEiABEkgZAiyFBEiABEiABEiABEggsQTczihSu9qLeprMczXa6k/kvlenqtbpx90H9T5v7hx6n5SbnkNno8zrrXDuwhV8OvozfXzqzAVdhJRfqEAe/K9eZ1Ss2VYbTDq0rKvDuIlKwBqx2Krx71+A1Ro1kGckQAIkkJQEmBcJkAAJkAAJkAAJkAAJJAEBtzOKvFvzZb2GSJXK5TCyb2tUKh/+VZODR0/iw8Y1kC5iLY8k0D0yiwmxfAa4YP7cOlzKmzmqC3ZtnI4f1k7GitkDkTN7Zh3GTTQC6TPCljMvjLBQmM6eiBbIUxIggQclwHQkQAIkQAIkQAIkQAIkQALJQ8DtjCKGYeiFVkf1/Qhvv/FipNbDe7dC148bRJ6n9IEs/Jo9a6aULtbjyrMVDp9Cw0/zelzVuYvAlIMESDSjFJ4AABAASURBVIAESIAESIAESIAESIAEUoyA2xlFRHNZUHXt1z9i0tzVMVxyrCkiZdIlDQFbwQijCNcVcQEoo5AACZAACZAACZAACZAACZAACTxKAm5nFNmy41e8Vr8L+o+ZjzVf/YAvv/05inMsiPooobHsuAnYipTQgaaTf+h95IYHJEACJEACJEACJEACJEACJEACJOBmBNzOKDJ/2WZULFscezfPxs71U7F91cQoLkPEp3DdjGMUcdLyiS33E7D7+MF06zqM65fTMgrqTgIkQAIkQAIkQAIkQAIkQAIk4OYEHtYokuTqBQYFo3yZp+Dv55PkeTPDlCFgK1JKF2T+m6NFNAhuSIAESIAESIAESIAESIAESMDzCaRKDdzOKPJypWeway87057c2myFimvxTaeO6j03JEACJEACJEACJEACJEACJOBZBChtWiHgdkaRogXzYv8fJzBu1gosWftdDBcSEppW6sZj9bQWjlhX5B8aRTy2Eik4CZAACZAACZAACZBA2iFATUkgDRNwO6PI9z/v19WxYPlmjJiyOIYLDA7R4dy4LwFboRKwGwaMs38Doawv960pSkYCJEACJEACJEACaY8ANSYBEiABZwJuZxSZNOQTHNmxME6XKUM6Z/l57I4EvLxhz1sYht0OE0eLuGMNUSYSIAESIAESIIG0QYBakgAJkAAJJEDA7YwizvIGBoUgNMzq7MVjDyFgK/S0ltT0zxG954YESIAESIAESIAEkpcAcycBEiABEiCBxBNwO6NImNWKGZ9vQOV3OqD8mx/hm+17tFZteo1Hx/5T9DE37k/AWjjcKGLmSBH3ryxKSAIkQAIk4HkEKDEJkAAJkAAJkECSEHA7o8hPew5j+oJ1ePWFssibO0ekknVrvIJtO/fh1p17kX48cF8CtoIRi62eOOy+QlIyEiABEiABjyBAIUmABEiABEiABEgguQi4nVFk+YZteK9OFQzt2RIF8uaK1Lv004X08fmLV/WeG/cmYM/+GOzpMsAIDoTpwmn3FpbSkQAJkID7EKAkJEACJEACJEACJEACKUjAlIJluVTU8X/O4cnC+eKM6+3tFWcYA9yLgO3JZ7RAppNcV0SD4IYESCAaAZ6SAAmQAAmQAAmQAAmQwKMl4HZGkdLFC+Or736BzWaPQmbll9/rc+cpNdqDG7clYCsUMYWG64q4bR1RsBQkwKJIgARIgARIgARIgARIgATcjoDbGUXaNquNvQf+RK2mvXHsxGl8+8NetO09EbMXbUTn1vXgw5EibteI4hLIWphGkbjYpHZ/6kcCJEACJEACJEACJEACJEACnkDA7YwixQrnw9rPhqJg/twICg7F9p/34+LlaxjcvQU+bFzTE5hSxggCtvxPwm4ywXTpLBAUEOGb6nZUiARIgARIgARIgARIgARIgARIwEMJuJ1RRDiKYWT6iM7Yu3kW/vh+AdbNH4Z6tV6ByWRIMN0jI5DIgs1m2Ao9rROZjx/Ue25IgARIgARIgARIgARIgARIgARIwF0IuJ1R5PrNO/hh90FMm78Oc5dswr7DJxAYFJLyvFhikhCwFYwwivxzLEnyYyYkQAIkQAIkQAIkQAIkQAIkQAIkkFQEtFEkqTJ72Hy+37Ufld/pgHZ9JmLmFxswae5qNO04Am806oaTp88/bPZM/wgI2BzripziF2geAX4WSQIkQAIkQAIkQAIkQAIkQAJRCPAkKgG3MYrI6JBP+k5GxbLFsXhaPz11ZtfG6Zg/sRcypPdHozZD8M+ZC1Gl55nbE7AWLqllNGSkiM2mj7khARIgARIgARIgARIgARIggRQgwCJIIEECbmMUmTp/LcqWLIrpI7vovb+fLzJlSKeNJEun91eGET98sXJLggoxgpsRSJ8R9px5YISFwnT2bzcTjuKQAAmQAAmQAAmQAAmQQGohQD1IgAQehIBbGEVu3b6HYydOo0XD6vDz9Y6hR+ZM6dGo9mvY9tPvMcLo4f4ErAVLaCFNJ//Qe25IgARIgARIgARIgARI4KEIMDEJkAAJJBEBtzCKXL95W6tTrEg+vY9t82ShfLh+8w6sVk7BiI2PO/vZCocvtmr656g7i0nZSIAESIAESIAESMAtCVAoEiABEiCB5CPgFkaRm7fvag1l7RB9EMsmU8Z02vduQKDec+M5BKwRn+U1/X3Yc4SmpCRAAiRAAiRAAo+CAMskARIgARIggRQl4BZGEbs9XOetP/yGr7b9Eqvb/Ru/XhJOyfO29txPwO7jB9Ot6zBdv+x5ClBiEiABEiABEkgWAsyUBEiABEiABEjgURNwC6OIA8LAcQvQc+isWN30hesd0bj3NAImE2yO0SKcQuNptUd5SYAESCBpCDAXEiABEiABEiABEnBDAm5hFClZ7Al8t3KCSy5DOn83xEiREiJw3yjCET8JsWI4CZCA5xOgBiRAAiRAAiRAAiRAAp5BwC2MIt7eXsidM6tLzmQyPIMspYxCwFbY8QUaLrYaBQxPSMDzCVADEiABEiABEiABEiABEvBYAm5hFPFYehTcZQLWIqVgNwwYZ08AoSEup2NEEnAvApSGBEiABEiABEiABEiABEggNRGgUSQ11aY76+LlDfvjhWDY7TCdOubOklI2BwHuSYAESIAESIAESIAESIAESCCVE6BRJJVXsDupZy1UXItjOul+64powbghARIgARIgARIgARIgARIgARJIUwRoFEmgurft3IcSrzaP4YJDQhNI6bbBj0wwW6GIdUVOcV2RR1YJLJgESIAESIAESIAESIAESIAESCCSQCo3ikTq+cAHdtjh7+eLrxePjuK8vSwPnGdaTegwipiPH0qrCKg3CZAACZAACZAACZAACZAACZBAshB4sExpFHGBm6+PFwrkzRXFGYbhQkpGcSZgz5Eb9nQZYAQHwnTxjHMQj0mABEiABEiABEiABEiABEiABFwlwHhJRoBGERdQXr95B31HzsXgCZ/jq22/IMxqdSEVo8RGwFa0tPbmuiIaAzckQAIkQAIkQAIkQAIkQAIJEGAwCSQnARpFEqCbK0dWtGhUHQXz59Yxew6dhdHTlupj2Xh7meCpzmIxRAWYTEaK6WAUCV9XxHL6WIqVmZz146Pqn86EpGBgVu1QXFLkxTySpk7SMke5OaZl/am7+1xD6tYIi9lIkvss69V96tUT68JLPTfKQGlPlN3DZPaI6z05n69dydtQP9ReFtMj7U8oEfiXSgiYUokeyaZGqacKonubhmjdpBYGdm2GoT1bYum6bZGjRTL4WuCpztfLrLl5qYetlNLB7+nwkSLmk0c9lpszq3Sq/uksSAoGPt4myANXUuTFPJKmTtIyR6h/aVl/6u4+15BFPfTL7zXrxH3qJK3WhZ+3BWZlFUla/VmvnsrT+Xn4URybTIC/j/mR9ifUowL/UgkB1ZxSiSYppEaObFl0SWFh4VNort0Jgae6u4FhWpfgUFuK6XAjZxHY1V3Mfv40rl25mWLlJlcdXVf1TxeCpGAQEGRFUIgtSfJKCnmYR9LUq6dylJujp8pOuVNX2w1Rv9F3g8J4b0wNv7cersPtgFCE2exsix5ej0n1G5Fcz9au5mu1AbfuhT7SvoQ8K9ClDgI0iiRQjzIq5PdDxxEYFIKLV65jzuKNqFi2OHx9vBNIyeBYCZjNsD1RTAeZTxzWe25IgARIgARIgARSFwFqQwIkQAIkQAKeQoBGkQRq6uLla2jacQTKv/kRqtTvqqfNDOnZMoFUDI6PgK1g+Loi5n+OxBeNYSRAAiRAAiTgCQQoIwmQAAmQAAmQgAcToFEkgcrr+nED/L5lDr5ZOgY/b5iGZTP6I2/uHAmkYnB8BGyFw40ippNH44vGMBIgARIgAbcjQIFIgARIgARIgARIIHURoFHEhfqUqTL58uRE5kzpXYjNKAkRsEZ8ltc4pYwiNltC0RlOAiRAAo+GAEslARIgARIgARIgARJI9QRoFEn1VeyGCqbPCHv23DDCQmE6e8INBaRIJJD2CFBjEiABEiABEiABEiABEkiLBGgUSYu17gY62wo9raUw/XNM77khgRQkwKJIgARIgARIgARIgARIgARIQBOgUURj4CalCVgd64pwsdVkRs/sSYAESIAESIAESIAESIAESIAE4iJAo0hcZOifrASsBR0jRY4mXTnMiQRIgARIgARIgARIgARIgARIgAQSQYBGkUTAcqeoni6L/fGCsFu8YLp+GcbNa56uDuUnARIggVRFIMwKXLgA3LxppCq9qAwJkAAJkAAJkAAJRCfgCUaR6DLzPDUQMJlgK1JKa2I6+Yfec0MCJEACJPDwBA79YWDmXAuGjrLovZwnJtc/jhgYMz487YQpZsyaa8at24k3johBRQwrYmBJTPmMSwIkQAIkQAIkkKYJpLjyNIqkOHIW6CBgKxw+hcbMdUUcSLgnARJI4wSCQ4BNm00YN8mMkWMsWLbChKvXXDdIXL4MrFln1qM8QlVeYpSQ8/PnDQQGAQEBwJ070EaOGzcNXFN5X7lq4JJKd+EicPYcsGGTGUEqrqMqzl8w8P0PrssgBhQxpIhBRYwzYmARQ4sjP+5JgARIgARIgAQcBLh3BwI0irhDLaRRGYyr6glc6W75fj18J3aD6fhBdcY/EiABEvBcAmLU+GmXCUuWm7B2gxl/HXfdmCBa7/zJhF/3mnD7drgR49hfJqxcbcatWwYuXgJO/Wvg6DETft9nQMr5brsJGzeZsGKNGQsXmfH5EgvsdsnpvpPzmfPCjSyjxlkwdqIF45XRZeIUMyZPN2PqDDOmz7Jg5hwL5sy3IDj4flrH0e/7TRgwxIIRylAzcapZjx75fLEZK1W5X35lgsjx824T9u03sOFLE8SQ4kgrBpaNX5thtTl8Et7L6BYxqDzoaJeES2AMEiABEiCBFCfAAknATQnQKOKmFZPaxTL//gMse74LV1M9sZuOH4LPzAEwgtRrzHBfbkmABEjA4wisWGXGt9+ZlDHEhAMHDWUcMePwH+GGkXv3oEd9nD1n4PgJAwcPG/jlVxN2/GDC5i3KiLLejD2/xfxZFmPIuMlmzJhtwYIvzFi+yqRHc0g5Pyojyt59Jhw5YuCfU4YypiQTsghDixg4btwwtNHj5D8GZATIb7+bIHJs2WrC+o1mnDgZrq+zJIGBwNgJFm2AmbfQjCXLlL4bzFrvHT+asEdxEEPIib8NHDpiinW0i4yCcc4zoWMxwgi760rehOIynARIgASSmgDzIwES8BwCMZ++PEd2SurBBMx/7o8hvRhEjDPHY/jTgwRIgARSisC1qwY2q8795Nlhei/nCZV985aBf08b+PV3A3/HYhBYrYwdMspi9HgLpkw3Y+58MxYvM+uO/9ffmLD9BxN27zHhwCEjyrQV53IzpLMjR3Y78ue3o1hRG8o8Y0el522o8qoNNavbUK+uFU2bWNFA7Y1oNgk579jOiiEDwhJ0Q1WcIoUjLCBOAjTEYQt1AAAQAElEQVR4Nzx97+5h6KTyav2hFR+8Z8W7dayo+aYNryk5KlW04ZnSdqRTsjoljTy8p2zeMlXnzBkDf51Q+iqjkei9fYcJXykOq9easWipGavWmGId7SKjYTZ9HW6AEYOTGIEkv5DQyCIiD/46btJGGDEkTZpqxrSZFogxJzICD0iABJKSAPMiARIgAY8mQKOIR1cfhScBEiABEkgqAjKSY9Y8M3bvNuHwUbvey/mZcwZOnjL0lBUxYKxRRo75n5sxYbJZTymRvZxv2mSOVRRbxLQRX18gSxY78uS2o3AhO0qWsKP8sza8XNmGalVteOctK0oUj2mQyJ0b6NnNig7KGNGquRVNGttQt7YV1d+w4ZWXbahYwYbSJe0QY0apUnZtqJA0Xt6A7MVwIQaVWIWLxbNhfSveUPIUezLc+NKkkRWlVP4S1d8fyKaMM/ket6NoETueUeVVfM6GV5Uc1avZ8O474UYSievsChW0o3tnK9p9HIYWTa1o1MCG2rWsupyXX7KhQjkbSjxtg8TLlMk55f3jy5eV4em38Kk6MjVp4aLwqT/DRlowfJQFMg1IpvRI/axaa9LrpzhSX74CfP9j4h557t4FxPiyS7WHc/9FszQ5MuY+DRKgyiRAAiRAAqmNQOKeEFKb9tTnkRGwPlU2Rtl2k3o7mK9oDH96kAAJkEBKENh30ARZE8S5LDmf+5kZn6sOuCxAKlNdDh4KHxkiI0QkrhgKxNDxVHEbzLHYRSoow4eM0ujbMwxdOljRprUVzd63osG7Vrxd04aq/7PhxRdsKFfWjjrK2PGcMnJkzGiHny9QvJgN9etapRiXnRhI2rYOQ//eYZC9nLucWEX0UcaUl5Q8TRrZtPGl2JN25ev6nxhQxJAio1mKKcOKGFgaN7Qik9LpsVxAwSfsePopG54tZ4eUU/U1G96qZUPDejY0/0CxaWKFjG5xLlHO33zdijdft+k0YlCSUTOZM4fLJvUko0ZkSo+MuAkJcU4dfiwGjsnTzBBjihhOtn1vwq+/myDrvsg0m4DA8HiyPXfewKRpFojx5ZutJsxRbUCmB0lYmnJUlgRIgARIgATSAAEaRdJAJbujitZnX0HoW81gy5UPdh/15K96EobNCsu2Ne4oLmUiARLwIAKyhoR0cq0RIzTiEl3iyKKmq9aYIYuObv0u9p9EHx878uezo2RJO2RUQy1lyJCpKp+0DZ+OIlNKxNDxXgMb6rxthYwIcZQpxpL/vZyAII7Iai8GiVrVbXpURR9lRGnc0Ibs2ewqxLP+iilDSl1l4BHDihg+fJShxVUNZFSLjG6RUS7Oo11efMGOFyrZ9OgSMSjJqJmuHcOn9fTqFm4Aer+xMpy8ETtvu8J47bqh114Rw9YPO03Y9JUsihu+XsuosRYMHWnRi88uWWZGdMOKTPW5fcdVLQBZI8V5sVgx1riemjFJgARIgARIgARSikDsT4ApVTrLSdMEQmu8j6BB8xE4aSOCuk6E3WSB5atFMB3ek6a5UHkSIIEHIyBrRsjaEZOmhndyZWFPWVvCkZus+7HzZ5Nez0O+oiLrTcjnbw8fMXDjpgHVZ3ZEjbL/4D0bWrWwQtbrkFENzz1r01NVcuaIEk2flC5lR8+IDrp02Nu0tiJDBh3kThu3l0VGt8goF1dHu6RLFz5V6Mmidrz4vE1PTYquZA1lbOrY3ormTa2QETm6LsvbUOxJm57SlD49EBoKXLtmQKbORE8v06Dkyz0yXUem6nyxxKwXlpXRQ/I1IFlPRqbpyBonMmplzTozLlxQeYZA79euN+Py5ei58pwESIAESIAESOBRE6BR5FHXAMvXBGyFiiO0YXvIrG2fz4bBuHJe+3NDAiRAAq4SkDUjpFPqiB8QAKxaa8K8BWYMGW6BrPuxdZtJf/lFvqLi5wfdIZbpHWL0GNgvTK9t4Ugve5n6UiB/XOYSiRHTWczQa3lkjpjaETMGfZKbwDtvWyFrnBR/yoYype1oUM+G5yuEj7op9IQdZZ+JGPVTwwYZzSLGq55dwzDo0zB062TVa77EJmMWVadiHBGjhxhB9u03IOvMyNQqMZKIUU6MJjPnmmMsFiv5ydeFZPFeMb7IeXxOjCsyOmXuFzYsX23gj6OmWPOMLw+GkQAJkAAJkAAJJEyARpGEGTFGChEIe/kthFX4H4zgIPhM/xQIcprgnUIysBgS8GgCaVh4mRbx98mYAGQKxOkzBsKsQNYsdsg6F7LApyxa2qdHmO4Qy/SO/PnsEGOGrG0ha3982s0C2b9VM/apGDFLoo87EfD2AuRrOI0b2FD3HStKPm2DrEuSkIwm9VSUKZMdVavY4O0dNfaLlWyQ0T8DlPFMpky1/UjajxVv1bTqBW/LlQlfQDenjCCKw44m07UmzzDraTojx1owfbYFi5eZ8OVXJsh0Hpli88+/hh6tsm6DGZu3mHDoD+D3/cDK1Sbs3acEjCoWz0iABEiABEiABB6SAH9dHxIgkyctgZAPusOWrwhMl85CRowkbe7MLTURoC5pm4AshLnrFxOWrTRh1DgLZAHNO3dkrFlMLrKAp6w50bmDVS8cKgt8yroVMWOG+8iaIE/kN6KsDRIewm1aIZA3jx2dPwnT7UUWd/3oQyuqvW6LVF8W1839mIw0sqPCs3ZUedUGGZ0iC+jKWjNtP7LGaoQpXeL+dB2zGbh0CTh+woTffjdBFn6VKTYLvzDr9vzHkZjtec8eA86joSIF4gEJkAAJkAAJkMADE6BR5IHRMWGyEPDyRnC7YbD7Z4D5j1/h9fXiZCnGwzKluCSQJgiIoePzxWYMG2WBrAvy3fcmPcIjJBj4+6SB7TtMWKA6jENGWDBnnhnffGvCsT9NkGkyMjIge/aYr+flKyUlVUdU1pxIExCpZJIRkDVGZGSRLO6a9/GYbSu+gnKothh9sVgZsVK/XtTpOvJVoq6drGjdwgpZPFYMMDJyqXBRe6xGFZm2I1N0BgyxQNbEWbHGjB0/mnDkmAkS5iyTjI6Sa0iuJbmm5NqSa8w5Do9JgARIgARIgAQAGkXYCtyMAGDPnA3BbQbBbphg2fg5TMf2gf9IgARSNwH5UszKVSac/MfQX/2QL8j8uNOESVMsGD7GAlmvQTp/p/41EBYGZMxgR8kSdtR40wZZkLNf7zB0bKc6lqrTKWtIFH/KpteUkLf3qZsctXNXAtEXi5V2GZusmTPZkS9feHsWA4yscdPsPatu49Hj58oFFCtqg0zxka8nHTkSbixcoa4dWfxV1s4RY4l8UWnZSjPkGpJrSaaRybUl15hca9Hz5TkJkAAJkAAJpGUCNIo8ytpn2XESsBUtjdB6bWCoGD5zBnPhVcWBfySQGgnY7cCly8COnWbcvCVXfFQtb92BXlwyZ06g/LM2yNv3Lh2t6N5FGUDeteL552x6UVNZL0KcrB0hb+RlLQlZU0JGkETNkWck4BkE3qpph0zTcUgra5W818CKJo1tejHYvr3C0KJp+IKy5crY9Rd05EdTjCXyRaXjx2NeT3KN/aCutX9PGwgOceTMPQmQAAmQAAmkbQIpZhRJ25ip/YMQCHutTvjCq0EB4QuvhgQ9SDZMQwIk4EYEZJSHdMh+/MmExcvM0ItNzrJgx46YHTgRO19eu17w9JM2YXi7pg3PlLIjS2ZlSZFAOhJIxQTkU8E9uoahdxcDvbvZIWuVZMlyv+37+gAFn7DrBWVlRFSb1lZ82jtMx6tXx4ps2e7Hdcb0vbrW5EtMw0dZMGGyGUuWm7Bth0lPwZHPEYuh0hFfpqfJVLWhI8On68inhx1h3JMACZAACZBAfAQ8KYxGEU+qrTQoq154Nc8TeuFV7wWj0iABqkwCnkNAOkwydF86UNKRkg5VQCBw7C8Ttmw1Yc58M4aPtuhP43633YTjJwzIp3HlbXixYjb4+cbUVaYgyMKnMUPoQwKpn4BZPaU9nttAtqyu6Spfz8mZAyitjIcVK8Q0isg1JtN4HssFSN4ycuSv4yb88KMJMgVn8nR1jSpjiVyrq9aatZ+sQyKfEJYRKPLp4bNnDdeEYSwSIAESSDsEqKmHE1A/tx6uAcVP3QRk4dX2w/XCq5YDP8Nry/LUrS+1IwEPJSAdJekwScdJOlDSkVq20qRHgixbYcLPu004d86A1QrVwYv6aVz5vOn7jWz44H0rChey60+hyudzX65s01NmPBQJxSaBR0qgQnkb5BqSa0k+LyzXllxjMgWt3cdh+LRPGNp+FIY6ta2oVMmGQgXterpOSCj0tXrosAFbTLsKtn5vwp/K0HnzJo0jj7SCWTgJPDICLJgEUh8BGkVSX52mOo3sWXNGLLxqwLJhPhdeTXU1TIU8lYAs2HjuPwO7lMFj3cbYf05Mqt/0eB47Kj1vQ6P6NvTqFoZOn1j1p06jfxpXPoMqnzSVKQCdO1hR9X82WMyeSodyk8CjJSDXjlxDci3JNSXXllxjDqnkk8DyWeGyz9hR/XUbmn9ghRgoZb2e9xtbUeLpWCwiKvGpfw0sVYbOCVPMGDEmfOTXV9+YICPF/jtv6IWQVTT9d/WaATGKjlTxxk0yY9Nmkx4dpgO5IQFPIEAZSYAE0gSB2J9i04TqVNKTCMjCq2F1WsOw26EXXr1+2ZPEp6wk4BEEbt02sG+/gd17TJARH9GFloUZT/xtYJt6Uyyfxh0x2oI5n5nxzdaYnwN1pK1Vw4qPW1lR/Q0bni5uAz+N6yDDPQm4J4GMGex4sqgd1ZShRAwr0aUsoa7jJwrYIdPaZPrbv6cN7PnVBBkpNnueGTJ9Tr6Es3KtGfIZYJk+FxgE3Fb3l1/3mvD9Tj56RmfqLueUgwRIgATSKgH+MqXVmvdAvUNfr4+wMi/C0Auv9gO48KoH1iJFdlcCJ08ZmDTVjPUbzdi8xQRZG2Tb92bIEHp5CzxzjgWyMOOipWb8oDo18rZYpslIB0o+jVvpOVsM1aRDVaRwDG96kAAJeACBLJntqP+uDTK6xMsLkHVIatey6hFfLZtZ9QLI8iWoJo2seO0VZfR8ygaZqqPeXeDKVQN/HDZw82ZMRfftM0HWFJKRJXIfuXXLiBnJyUc+JSz3pSXLTPreI+sUOQU/6CHTkQAJkAAJkEAkARpFIlHwwBMIhLToDZssvHr+X3DhVU+oMcroKQRkCoys9+Es746dBlavM+u3wBcuhodIx+i58jbIZ2+lQyRD7Ru8a0WNN22QDpOESwdKOlLSoZKOVXhKbkmABB4NgQcvtbgydHzUyor+fcIg65DIlDfn3OT6LvakHa8qo0ijBjboqToqbqsWVlR7wwYjFnuHjC6Rr0/JyBIZcTZ+shkDhlggo0sWK8PH5q0mfc+RUWm/KwOKjDaREWx/nTBh2/cmLFaGWWcZeEwCJEACJEACD0uARpGHJcj0KUvA2xfBsvCqrz8ssvDqN8tgOv0XjFvXUlYOlkYCHk7g+g1DjwL55lsT5i4wQzog0VWS/oysByKL6QCpDgAAEABJREFUNcoaA317hXeMatWwQb5gkUW9SXZOIx0m6ThJB0o6UtKhcg7nMQkkOwEW8MgJeHsB+fPZ8WIlG/KpfXSBihSx6QVgZYRZntz2yK9OyeiS48rwsXu3CTI6TUalbYhlrSJZx0iMKn+fNPSIFFkYNnoZzuc3bhr49jtlTFlmxtffmHCJs2+d8fCYBEiABEhAEaBRREHgn2cR0AuvfjQQsgSc14b58B31Cfx6N4LPpJ5AaAj4jwTSIgH52ou8UR02yoJJU834Tr1RlYVQhYVjLRD57OZi1TGQRQ8ljowC2fWLCfLlGIkX3cmaAbIeiCzWKGsM+PpEj8HzR0mAZZOAuxOo87YNxYvZtOEjY0Y7nqtgQ8N3bXoR5QbvWtGmtRV9eobpqTgffWhF/bpWVPmfDWXL2FEgvx2mOJ5SZfrNF0vMenTJsJEWyD1NpvwtUve3jV+ZIEaTg4cNHD9hYNYcM37aZdLHv/xqwuy5FtxUhhJ3Z0f5SIAESIAEUo5AHD83KScASyKBByFgz50f8hbbOa35r/2w/LjJ2YvHJJAmCIjxY+UqE2TufUgIIKNAftxpwmcLwjsNjrVAtu0I7xjIoofyNrfgE3ZUftGG9xqqjko9K+RrFM7AXqlscz59lMcsmwRIwAMJZM9mR2N1fxHDR/fOVtSqbtMLtEZXRQyweR+3o1RJO+S+U+dtKz5sbsVLL8W8B5nMQMnidshir5kjRqvJPU0Whz6hjCB7fzdBjCZr1pn1VBsJcy4vzAqsXmeCGISPHDNBRp7cueMcI+rxDWVAWbHGjFHjLBg7wawXlOW6JlEZ8YwESIAEPJ0AjSIu1uCduwG4cSueX00X82G0pCFg+vevWDPy2rwEPgtGwbJlGcyH98C4eiHWeA5P4/J/2pAixhTTxbMOb+5JIMUJyBDwo3+a8NMuk36jKYsVxieEjP44e87A/gMGNm0242YsixWe/S98eLnkkysXIGuBvPOWFTLF5dM+YWjR1IrXq9jwlHqTW+Jpu14PQMKrV7PpODL8XdLSkQAJkMCjIPBCRZueiuMoW4y5b9e0okF9K2Sx164drRgyIAw9uoRBRpo0qGfDm6/b9NQd+dpVhoyOlFH3Z84akKmDK5QxWb6gNXaiBbKuycSpZiz43AwxqMhou1+VgWXpchOOHDEQEADcuWtAFojd/n3iHp/FYM3FYqPWAc9IgARIwJ0IJO6u7k6Sp5AsAeoVQ4d+k/F8rXZ4qXYHNG43FFev30qh0pOvGJmLO22OgXY9QjF8nA2yyGJiS7t21YA8MIi7di36uI3E5pa4+PaMWWNNYNy7BfOv2+C9fj58ZnwKv/5N4depFnxHtof352PhtXVluLHk+mWY92yF3+AP4b1ssna+Qz7UfrFmHIen6fRxlXYKvFVZ3hvmw7iZ+LVNTMcPKLlWwbL3eyAg8YY3MfxYdn4Fy44NMF04HYek8Xsbd25CdDGCAuOPmNShqSg/MWJcVdfB5cuALebLzXg1DQoGps80Y/lKU+Tcd1nnQxLJdfbXcRN+3m3SX4aZrx7Y5Y2ljP6YO9+MdV+a8dtvsV9/OXPY9dtWWeOj/cdhqFXDhnJl7forEpJ3dJcpo12HV1IdEVkwNXo4z0mABEggJQn4+wOyaGu3zla0aRWG3j3CUK6MTJ6NKkWGDICMNCn5tA0vVLKhmjKMNKpvQ5OGYVEjRpzJiJTyz9pQtKgduXIicvTKjRsGTp02IFNvZLTdxk0mXLwU8/6676CBhYvMWLnGjE1fm7D9BxNkas6hPwzI89X588DNmwZk5J6s1yRTGx9msdjbdww9+kWmB0l5/52PKVOEanHu5HdJfp/kd0p+r+KMyAASIAESSIMEaBRJoNKXrtuG4/+cw/erJ+GXTTNgNpkwed6aBFK5d7C87VixyozTZ6B/sC+qTtw3W02Qjperkh84ZGCK6sRt+soEcVPVsfi5ml7inT5jQB44Fi8Lf6C4d098XXO2J56ELXeBGJGD2wyFLMQaWqcVrBWqwJavMIyQYJjOHIfll2/htXZuuLGkXxP4LByjeq/W+3mopwSvDQsgRoqY7hBM//4J4+xJmC6dhXHtEszHD8J3TAdYftwIy+E9sHyzDL5jOyKudU3uF3T/yHveMPhO7KHkmgPv+SPgN6CZzvt+jPiPzAd3wW9gC3gvnQTvFdPgO7Q1xEASfyqnUJsVPjMHwK9nffiOag+/7nXg9dUipwgJH5pOHYPPlN7w61wbfgOawuvLBUD0z5jEl8292/BePAG2LvUR9kltCBNDGa3iSxI9zLJtLXyHtFIyvAWfsZ1gPvJr9Cjxn9+7g3vLlyFg+ADcmTIBoQd+jz9+tNDLl2z4bsT3uDp8JG6NHIYfBm3CP3/H/jDuSCqGEJnmImuB7Nhhgs+Vf1H71lR8eL03at6ejXv/XkT/wRZMnmHGEvWmcou6RuWh+l/1wC7XsOSTMwdQ7EkbKle2Iav3bbx2ZzFaXu+H+jfHomjQb3j+Obuely9fg5H4CTnjxhVYft4My/Z1MM6dTCh6zPCwUJgP/KSMfMr4+Ieqg8S0A0duoSHQBjoli8MrsXvjyoVw+R+kfCks8C6sJ/8E1F5O6UiABB4tATHY5skDWCyJk0PSvPSCDc5fwSld0o5337Hi7Zo2fNDYivZtwvSaJjJ67pO2YWj2voRZ8erLNpR5xh4lraP00FAD/5wy8McR9XLoNxN2KKOILOK6eq0ZstbJrHkWTJhihqzxJAvGOtI59jJlZ+PXZm1MEYPK9yq9rHuyZ69Jj/6TfP86buDUvwb+Vc9Ks+eGr5Mi04N+VeXJ6JbLVxy5Jbz/V/1ujJ9kxrRZFkyZbta/KxcvJZzOOYaMdlm93sDMz2z4YacJiZ1CpB6x9BRPMfCLfjI60jl/V45p2HGFEuOQAAk8CAHTgyRKS2m++f5X1Kv1CnJmz4wM6f3xQb3XsfbrH2GXu7uHgpA3DDL0Prr4K1abMG6i+rGcFv7DOWuuGfJWWt6GyNuJ5atMkB98GQIqP/7OCOSHSjptv/1u4MAhQz8o/PmXSb8xkR9jeQCQH2B5Q3FTvT2Rxc8+W2jG3n0mHD8R/kAhZUk+0eWK9dxkxorCE/Bt+mY46lMJu/3ewrw8U3C7SCVYSz6H0DcaIrhlbwT1nYWAmVvVfiaCm/dCaLVGsJaoAHumbFCVGCNr043L8J3YXbke0Vw3+I7uAL8RbeA7qCX8Pn0fPhO6IfqQAOnM+/VuCD9ldNHxhn2s0n2i8uqmDQdigJBOv8/C0fCZOxSW33+IIoOhOufeC0bCa9MXLjnLsqlKhmiGHWX48fp6MSybl2pDjUwl8vp2he6oykgZr+9Ww/LdGtXxXQtvZRgyH9p9XwbVidRlS3oZfSIdZHG7t8Cy+1uYlWHJvOc7PRrHvHebMjRthffk3jAf+x1GcACkM+qlyvVaPh1isJG8xZkO/wKz6iSLscJ89DcdX9KY/toP8/xxuiOOm1eBO7cgTMyzhsH8z1GIwcX0758w/fsX5CtD0lk2nTmhjVPSaTf9dwqWn76G9+qZepSMERyk03nPGAjTqT+1PMbVi9rQZFKGFun0G6oc7W5dg3HrOmSUTODQ3sjxw3xkP7cbuY5tRqbZvXHvx59gBCmdVJ5QhjXIK7/7pKIcXf5iJWqfG4FygdvwTNAPqHllMoLmzoAMv/5ykwly7ciQ7GkzLRgzIXyY9ojRFship3PmmXHsp8vofPVjVA5Yi+LBe/C/e8vR6Vo7+NruqfuOHbL2R4VyNlSrqh7i37PqaS4yZFwe4Js0suGN12zoEtYbNe5+hqeDd6Fi4Nf4+EYPPOfzSxQ54zuRuvBTRi0xUHmvmgG/4W10m4kvjXOYEXgPfkM+hM/swcrIp4yP0/vBd1xnQBnenOPFd2zZ9Q38etSDrxjo+r4HH5Ve6ie+NM5hMmrKd0hrbZwT+eValPbnHCehY+8lk+DftQ7u9Gml917LJieUJEq48d8/8FG6+3Wpre8TXqtnI762EyWxOpE25718KnyV/v7d6sJnlmrLyhCrglz+k2vTd2Q7bSSUvZy7nFhFFBnkXqHvV1+MRWIZqix0Gm+VVvKQvCRP8XfVyXRGrzWzIKPwZC/nrqbV8dQ1a9m+Fj6zBykD+GiY9/2I2O75Om4cG9HbHXQInfwpjHkjH0wHdW+Wa9pnRn/9mwD1GxOHurF6y/1Tv0xQbdp75XTIPTfWiHF5JkU9PKQO1cqcx9CnZmJQul4YWmQyGlT8O9YFXL29ADE0Fy5kR/ln7XjtVZs2nhTOH4JK9zbggxuD8N7NYSgb8B1KFrOiaRMr6irjyptv2PDKyzaVxoYST9tQqKBdj8bLkN6uqchWjNRirBajtRiv/ax3sHevATGmiBOjiHwh56vNJj36T0agLFluhnyyeL56VjJuXkP12/OU0bsP6t6chMeD/8JU9XsiC8w6nttmzrHgMxVXRqUsWxH+vCafPd68RR2vsqHkpS8jdShwdhvWKwOHjGqRF1QXLgDyfHbrlqGNHaGhWvTIzYm/Deyatx8Ft49DhZ/6wv7lUqz6PCAy3JWDNfNv4PKMBXh8RT+EfTYVq8f9jcS8DDv9T5h+4SAvHuQFhLyIuHjB5krRkXEOrTmCP/tOwZkuA/DHsEU4e+xWZJgrB/fOXcN/kxfgSr9PcX7UVFz97bgrySLjWEOt+G/ZN7g0aLh2cix+kRFcOLj88xGcHzkZV/v1x7lpixB46aYLqe5HkfiSTtJLPpLf/dCEj0RekfthdBBuwk84Ck/hmnDJjEECyUvAlLzZe37up89dQv7Hc0Uqki9PTn18+67jx0CfpopNmHqxLUM0r103IEMsz18wIAYNeRty4oSBo8dMkKGhMp82MNCIofO9uwa+/MqMtevNekjpUvWjLG9MxNghbzVkZXh5QyFvTxYvM8dIL5/jGz3eggmTzZis3mRMn22BdBglvfzIL1Fvy2WxszUq/xWrLfj9ZFZ8m6E55mcdgTWZu+JPeyls+c6s36yc+teIsj9pLYq/c72O42Va4c9aI3G0zQpc98kbQ4YgUwbcLF0dt56ugtvFKuNOkYq4V6AsAvKWQNBjxRCU4wmEZMmD0AzZYTN5xUgvHkbAHYhxRI8oUR0kk3Tojx+CGAHkIVt3+sWwEM0gImnFmf/+A15fLXLJmW5dkSRRnBF0F15fLoT3lwsgU3q818+H17p58BJjibg1s+EtnY1VM2H5dVuUtI4TnX7pJD2CQx6ovb8YB905+Hys7mDIui0+80dpo4opOMCRLHLvtXMjpDPnM3OAHoniqx7IpaPoM60ffKb2gYwsEec7qSd8juyKTOc48D57FD5jO8J3jHLKGOU7+hPVURbXHtLJE+OUdHp9h32kZXSkc+wNWxgkjXTy/fp/ADFi+SpDlZ/qaPr1aQztejeCdJqlE57tVswHmxxLB0N3bDu/Bf9OtZSrCf+2r8fqnjv5maPoyOABotIAABAASURBVP2zt77Emyuro87XNdHk+1pouacWOhyuhV5/v4Uhl97GkIu1MeTyOxhypQ56XG8BC6I+haa33cTgO+9hwI330O5EEzTY+wGqbGmKUouaI8/kFvAd/CF8h7SCjA7yHdQCfv8diyzbceCrDGy+ip+P4ig8xcjgM74LfCd0he/EbvCd0B0+k3oo1xM+c4cBchNwJFZ7L9V2pDPlqEfdwVRGD585g+GtjHpi4PP+bBi8PxsBn8k9tRFKJYv8MymDltS5bkNLJkIMDl5LJ8NLGRqk4y+jm7RTRhjvZVMgYUZwYGR688kj8J7ZX7djL9WepV1qo90mZTTU18hi1dFboly4AdBnzlCYLvwbmd64e0u10VGQzrFl+zo9xcyyYwMsP3wJWUfIsnMTtFOGNRkh4y3XxE9fRaaXA68fN8FrwwLI9DbLbztgVtetdLDN+3+C+YC4n7UBQK5t84GfIbzMygAoRgAZUea1bTV8VkyFGJ1Mfx2A6fhB5Q7BdOIw5FoXHU3/HFNGPOUULy/V8RT5TDJSRt1LxLjoPWuQ7oyazv+r9DsN08Uz0PeXS+cg6yIZl8/DuHpBuYvqPrNPXaNjYBLjoTLoyV5GxZlVeWJgEod7twHpHAfehRiztKxBgRCjIlQnVupW7heikxhDfdR1LPoLD1ecxNVpxJCqjK6Sl+TpSlqJIzL6qGveS4y3h/dA9nIu/hLuivNeNBZSn1InYsjVRmhl6HUlrcRxJx1sv+0Edm1FYnUQI7TcZ6Vtm5VhWn4T5D4s+rnipG3IaEgvmXaq2rTl+/XwVQZLadeupJc4D1sPSaWD7/aVSP/3r/DbmXgdmtqn4t3bk7TBu5wyfDe5NRwN0i1FkcJ2lCltxwvP21DlVZseedKwng3NP7BC1m3q0dWq1zupX/gXbaSuqIzVYrQW43WrG71Rs7oVNd60oaoyasuolEqVbNqwInnKeihFi9ghi8lmSReCDtc+QZV7S/B08C94IXADOiqj+WOhpxAYBDie2y5cBMTAISM6jqmXUo7ntd2/mFD1fEwdip1crke1fKYMKTPnWiDPZ+PV89eosRYMHRluvJcv+4ghf/+i32LoUONoH2x0Gu0iI17ichvWh+GtfR2i6NDyTHtsX3JWfylo588myEiZn3eZ9HTu3XtMejqSjJyRkTF7fzfh3uwZ+oXDM+rFQzlVD/Ii4uzcVfq59PAfhn4Z98dRk35WPfanCfJiTkbbyEs4Mer8vvJPPP9dZ5S7sRFPBe3Gc/99gcwzu+Hvv22Q9bnk5Z28NJSpT8JSnLzMk+dheT69fD4U3qM7oeifS1Hg+h4UOf0l8n7WAf/9dhqyUO/du+q2eg+QkZwyiiYoCJAXkPI+xTEq5sK0hSj643gUvLRDOzkWP7lWXHFXfzmGJxZ3RpEzm5D/+i948sgXsI/sDpusHuxCBhJP4ks6SS/5SH6SrwvJdRSRV+R+UB1uHvlXcxN+wlF4CtewwBCdPzck8KgIJM4o8qikfETlymgQWVPE18c7UgIfeZWgzgIC1N1O7bNn9IGnuVLFvOHro4SP9teskQlD+5oxsKcZfbua0LOjCV3amfBJaxPaNDfhww9MaKriNKlvQsYM0RKrUz9/4IXnDFQoa6gHBQMliht4qqiBooUM5M9rIPdjBnJkB7JkAqJ/5UIl13/yY3JTvamQNUouXQLOnTfw72lDD7mU6T2y2NnBQ+rH76iOHmNz4ICh36zI25WE3Ba/prDivnHGDgNrM3TA0Mu9MPTGpxhyewgG3xuFgSETMMA6DZ8as/CpZQH6+i5Bn/SrsE7FjS6A5DE18zSMyLEEY7MvwMRsczA12zTMzDoB87KMwsLMQ7A4c38sz9QL36ZvHj25Pv/Hu5QKa+aSu2UKN9LphBGbICM9tqV7X7n3sD1dY3yfrhF2pGuIHf4N8KN/Pe12+tfFT/51cNareESqqLtjPhXxq1915d7Eb37V8JvvG/jd73Xs862KfX5VsM/3NRzwfRV/+TwbNWHE2S1zNsgInqM+z0Py+tPnOfzpXQHHfcrjuPezOOFdDn97l8VJrzIIM7wjUjnvDJyxFMMZr2I4q/bnLEXxn6UI/vMqjAuWQjhvKYiL5idw0VIA90yqQTknjTi+Y8qCG6ZcuG7OhZumHLhpzo5bpuy4bcqKOyrsjpFZpw0yVMONSOO8s6n2EKJkC0Vs8jnHBOyGPaqHOjMMA972YPjYg5QLhJ89QLl7yt2Fv+0O/O234W+9Bf+wm/C2BqkUMf8sAbd1R9eQDq/q+Jou/wfT5XO6Q6w7xhdOw3T+X30eMzVg3LsLk+pom08dg1l1vKUDblZGN+mQm5ShznTiIMx/HVBuP8SAgOj/bFaYD++GWXVstVOdfrMYApRBwKLevIuBz/LbD7D89j1kJE/05HJuPvo7pFNm+elrWJTBwUsZIsTQIB1/ixgoxInB4scvYVjDJEkUJ7LL1DQ9AmnzEkQaDMUwsulzZfxbqNwCbTgxnT0RJa2cGIEBqnM8I9ytmKanmXkvnwpvMcwoA423ODHYLJ4Ay7Y1kiSGk7K954+A92fD4TNvmO6cimHIRwxEswdBDADayaiO65djpDfv2gxfZQD0VQao8JFo3ZRBqivEQCWGKpl25zAAWnZtiZFe6lobv4a2hjaEiUFMRqwNagG/gc2Vawa9fpIyAPpM7gVEH3Knzn3Gd9XT5GSqnH/3d+HfvS5kRIxf13fCjX9d3oafGAA71oT56G8xZBDd4zIK+neqqYyGynAo6bvU1oao6BlInul6vIt0fRoq1wjp+jZGun7vId2nTZCu//tIP+ADpB/YFOkHNYP/8NYQQ41zHnLuP6IN0o34GOlHtkX6UcqNbo/0Yz5RrgPSj+uoXCekH98Zcizt0jm9HPtsmIcMU3q45HxWTpMkUZzokH5iF5fSp5vYNVYd0imjpEsyTOqirqsfopQvJ4nRwfeLMZIkipPrSfi4IkM6xdK4E+0tdFgo0k3p5RKDDJO7xaqD97q5rqVXdZVcOvhP7u6aDEqHdL99HYWhnKT/bplr6ZUOzx8aK0miuAKhR1H1h0/w+i/dUHNfN9Q+1A0NjnVDk5Pd0OxMV7S+0A3trnZFp1td0edeG2SxqQcipxxMsKFTcB+My9AFY9J3wWj/Lhjp1wUjfLtgmHcXDPXqgsHmLhho6oIBRhdUDIxq7JWsXr+7GN0COqPrvc7ofKczOt3ujA63OuOTG53R9lq4+/BiZ3xwujPevTpakkRxosMLm9ui+NquCbpXt7WLVYc3DvZB0VVdUWRlVxRe0RWFlCu4vCueWNoVBZZ0Rf7FXZFvUVfk/aIryt6OqUOli4uQY243ZFcu25xuyDa7K7LM6qqMHV2RaUZXZJzeDRmmdUP6qd1Q+ofBUeSXk1yhp5FlcgdYxnaDeUw3mEZ3gzG6O6AMDeLsI7rDOrw7woZ2g/fIT5Ap7JIki3Qm2JB9QR/c/bQ77vTrjtt9u+NWH+V6d8eNXt1xvUd3XBPXvTsudOqOwsdXRaZ1HBQ6vkaHSfilzt1xqUu4u6z22nXtjsvKXVEu8+IhiP4ve/Bp3O3+SXg5qiwpM9L17I4bTi6gxyeQ+NHzyLJkCG4pmV1xIm/09KKXK2klTrpZfSHcnPMQrsGHTiCx/SmLyUDm9N6JTpfYcuKL76xHqj1OI4qZ0oieD6SmYRjw9/NVlt7QyPTBEeZef39f7eftZYKnuayZTWjb0oLCBQ14ewO5cwEN3zGjciWzOjYh3+MmFCpgxpOFzShRzIwyJc0oX9aMSuXNeFnFea2yGQ1UfIVHM5CNyQS8964ZLZtY8HFzCz750IIubSzo/okFvTqpNw49LBjax4KR/b0wdogX6r1tlmRRnOQ3qJcXRg3wwtC+Xhig0vTpbEEPlUenjy1or/L8qJkZLd4z4+3qMdNLZoWVAabqKyb8r7IJr7xoUjqZlKHGhOfLm1ChnAnPPmOgbCkDpUsYOJTxDYzNsRBrMnbRbkz2hTiY4Q0ULWygiMqniOJTOMIVesJQTMJdwQIGCuY38GfON3HE50UpVjurMrBsTt8SgflKIX2Bx+H9REGYCj4J6xMlEVywHO4Weh43Cr2MK4Wq4Hzh6vi9QAuIYUEnjtgEmDJgba5+OFi4OQ4Wao4DDlewOfY/Ee72qf2+As0hbn3mjjEMOxsztMHufK3wS77W2JXvI/yU92PszNsGO/O1xY687bX7Pm8HbHu8I9bk6Kl+0lXl4f4/MSQszzUUm3L3xMbcvbAhd2/l+mD9Y32x9rF+WJPrU6x5rD9W5RqIRTlH4K4p8/3EEUdbFAcZwTM/60h8lnUU5mUdjXnZxmBO1rGYk20cZmcbj1nZJmBm9okQ40tEssjdMWVEmZx9NqZkn4XJOWZhUo45mJhjLiZmn4fxOT7DhBzzMS7nAoxT9bc4c//IdI6DMHhhRoEFmFdyORaVXYHllVZhzUur8WWV1dj85jp89/Z6/Fh/A3Y1/hK76q9VhhmLI2nk/nChZrg1chsCxm9D4NSfYJ31E8zzf4Lf4p+QeaWTW/4jbuR/KTKd4+BOhgLIvOg7ZP78W2ReuAWZFn6DTPM3K/c1Mn32FTLN24RMczci05wN8G/dzZEsyj5dr1HIOHUlMk5ZjoyTlyHjpKXIOHEJMk5YjIzjFyHjuC+QYdznyDB0FuDjGyWtnPj8rzoyDJutwmciw5AZSC9u0DTV8ZyK9AOmKDcZ6ftPQvpPJ8JcJKaBzFB5pus5Gum6j1BuONJ1U67rUKTrMgTpOivXaRDSdRwI/w4D4P1qDSkyhvOpUR/+H/VUOnaHf6vu8PuwK/xadgl3zTvBr3lH+DXrCN86zWKkFQ9T/sLwbdQavg1aKfchfOu3hG+95vB9V7m6TVW6D+D7zgfwqd0Epmw5JUlUp24sPm++C+2q1YXPG3Xg/fo78K5aW7m34f1arXCn5DcXeTpq2ogzy5Ml4PXCa/B6/n/KvQqv515R7mV4VagMr/IvwevZF+FV7gWYS5SNSBF1Z6TLAEuJcrA8XQaW4s/A8lRpmIuVgvnJkjAXLQEpV/ibCz0F+PpFTRxxZuQpANPjyuXJD5O4x/LC9NjjMOXKA1PO3DDleAxG9lww0qWPSBF1Z6h8jQyZYKTPoOJkAPzTAX7+gK9yqp7h7QPID4LZK2pCV870q9BgIFgZ94ICAKs11lT2u7dgv3lduWuw37gK+/UrsF+7DPvVS7BduQjb5QuwXTqvwm/Env6mSnP2H9jO/A3baeX+PQ7bqb+U+xO2k8eUOwrb30dgO3k09vTKSGg9dgCuOPvd27HmYfvrD5fS286fiT39pbMupbf+dTjW9PbE6HDrVqx52P4+6poM/52KPf2lc66lP3Yw1vT2oHsupj8Ae1w6qDp2pR6tcehgv3zRRRmUDsqoGF0RW3CAi+kPALeuRU+uz62qzbqig+l87PXgfVt10I8fgOnEAZhPHoDXPwfazhUVAAAQAElEQVTgfeoAfE8fgN+ZA0h37gAy/HcAGS/sV08nNl2m88bLHojctw4iz+2DyHv3IPLdO4gCAQfxRNBBFA6J6jLYrjsnjTzOF/pnjLjR08p57tBTkWmcD7LYLrqUvnCw0lE9rTinlWNvW5Br6ZU+maxXJEkMly/0L5fyyBN2MkZa8chivexS+nAdYt4bLfaQyPQFgw+ioOIvTupBu8CDeEK5AsplDLsiRcZwjwWfQD6pQ+WkLiPdnYN43MnlDDoRI614ZAi9otuCtIeEnMgraZydWT2J5r55wKU8MoVedk4aeRxy8VKi+1Pq5x1elqTthyW2TxepAA88noDJ4zVIZgUK5M2FM/9diizl7PnL+jhjevUgqY6u3g6GJ7pceULwyUd2zBjrhU97mFH22dBE6VG0WCi6dbTjnbfDXVd1LH6usihVOhRFCtsVwfA/iwWoWc0OvwzBgFcwvPyC4Z8xBJmyhSBbrhDkzhuCfE+EoFCRUBQrHooXXwhFqRL300su6VSVNG5oRdWqYaj2RhiqvxmGmjXC8PZbYXindhjerROG+vWsaNjAivcaWfHC83ZcteTF7nRva3fFKz9eqmSHrHSvXUsrWke4jz604qNW4e5jtf+4tRXNlWFpYbZhGJhzHSZlm4X+uTZif7730bG9Fe3aWNE+wn3S1gqH69DOCnEd1V7irXt8IGZmnYCNypCxOHN/jMixBK+9mxNdOtjQpaMNXR2ukw3dOoe77mrfvYsN4nwrvYjROb7AqozdsDZjR4zLPh83y9ZE7x429OpuQ2/l+qhjh+vb0waH69fLhtebPoEp2WZgl19tyKiObemaYE6eaejS3YIBfW0Y6HD91LFygz61YbDD9behXz8LluUeDhkBEmT446o5D75L/z7yN3oDo4baXHJXXmmJPX41cMuUXY/cEEPR/mfUm69hrqV/uc2z2JChvR41Emz44pRXCSzKPhQfd8moGUo9SH02+8AKaR/v1g3DW7XC28j//heGl6t540Cpjgg2/OD4d9qnJHJ+UAdZsocgXaYQ3R7tlmAE24JxJyjaNX83FBk/bImgTI87kiPELxt8WnXA1RATroaacTXMgmthXrhm81bOB9fsvrgGP1xTzK6Z0uP2c9Vgq1glMj2UldH2ZiPcerICrqu8rvvnwPV0OXE9fS5cz/AYrmfMjeuZ8uB65sdxI3Ne3MitjG+NO8CuOr6OTOxFSuJe7Va48VgRSPiNPMVwU1ze4riZ92nczF9CuZK4WaAUbj5RGiHvtALkQnRkoPbWt5pqGW49VRG3nnoet4or9/QLuFXiRdwqqVypyrhV+mXcfuYVBNZtC+TIrVLd/7MXLI57dVpr/W5XrI7bz1fHnUo1ceeFWuHupbdx56XauFO5Nu7WbAZ7oafvJ444Cq3bGnerNsLdNxor9x7uVmuCu29+gLvVlavRTKVrjru1muPeWy0RVv29iFT3d7byr+BevfbKtcO9+mrf4BMENOyAgEYdleuEgPe6hLv3uyH4k2Gw+/nfT6yO5Dyo3RAEtuyHwFafKtcfgR8NUG4gAj8ehMA2gxHYVoW3G4rgzmNhV8YLRPtnrdYIQV3GIqjreAR1m4Cg7hMR3GMSgntORnCvKQjuPVW5aQjuOx22KnWjpQbsBYoidOgChAyej5Ahai9u2OcIGfYFQoYvQsiIxQgZuQSho5YirNdkSPuJkolqT2H9piN04lqETlqP0MnrETblS4RN3YiwacpN/wphM75WbjPCZqq34ukyRkkuJ/bX3kHYvG1R3QwVX9JN26TzsUp+UzbA9uKbkiSq80+PsDHLYR27Qjm1H7MMYaOVvKOWIGzkYoQpHcJGLIJ1+Oewfdg7atqIM+v7XRA2YDas/WfB+ulM5WbAqvSy9psGa5+pyk2BtdckhPWYAHv6TBGp7u/sJZ+Dtft4l5y9XOX7CSOO7D6+sHYd41J6W8N2Eami7mzvtnYpvbW76BBLPSRCB1uFV6IWrs7sXj6wdh7tkgx2xVslifFne6eFS+mtqh6QMUuM9HiqjGvpVV3ZK1WJkV7r0HGES3nY4tKhdlOX0osO9qw5Y8iAwiVdSy86vFAtZnqz6kZ2clGHD3vFTK98bNUbuSiDaks58qgUUf/kfuvq9RCqfqOiplb3JZPSocMw12Ro1Sd6cn0eVKWxa+lVW7rrH1OHW9mfci29qocrpd7SZTpvrIYZwa0Hu5THzUZ9YYfhnFwfny9dz6X00pau+RXUaZw3V9MV0emDuoxHUGflOo1HYMfxuNch3N39ZDzutA93p598xzmpPhaZLtQbjKutx+Pqh+NxueV4XBLXQu2bj8dF5S40G4/zyv1ba4CzDjq9bE4WqoOzTca75K74F5EkUdwV34I4+/4El9KfLFIvSlo5sSuu3qWfTlQ/RPobYTY7bt4NSXQ6SZtUTuSnSx0ETKlDjeTTotqrFbBq4w5cvnoTd+8FYtHqrahb42UYhqELDQm1wVNdmNWudbCpm8qD6JAxkxXlyoS7jBmtieJgs9sgi5T16BIW+Zm9555LXB716lrRoqlVLz5ZXx136hAGb2/X6+PVV6145y0rSirjijg5Fj9XWWTJYoMYS0pUzAi/Ek/i+Zd98GELK0Q3V/IwTDY0rG+F9cky2J2lIc7m/R9efC0dnnrK5jLLqq9ZUfC53DiaqyYO5KiD7GUKoGZ119MXfELpX6sodhbphEWPjcQfJT5E9UZZXOZoV29uXm5RDNvKj8GQ/F9hTrHFCKjRAiWegcs6vPhGOvzzWndMLrIKYwqtx/6XBuDVujlcTl8gvxXp6tbF58UXYFD+zfiy7FSUa1beZR2krp5uWx3/9liDPTVn4vcPliLdyInIlNvfZRlCcuaHbeQCBA5agKD+cxE2TnX0nnzG9fRWA0HNeyNg3BoE9ZqGwPHrEFT7Q9fTq/tQcMU3EDhmNYJ6T0fgiKUI7DYRIb4ZXc4juMgzCBzyBULe74qQ+u0Q2G8WgqrUdz29lx8CBnyG4I8HQgwZwe2Hh8ugdBPGrrjAdsMQ8nYLWEs9j7AXqyO44ygEFyvvsgxBL9RQD7j9Ya1YFdYyLyo92iLo/e4upxdewT2nIbTqu7CUq6T3ci7+rsgfYgWCWvaFLPZs9/WHPVsuhFaph6BX6rgsQ/DrDRH2ytuwZckB+GeA9ZkXENyij+vpVVsMbt4TtvxFIZ142ct5cI58ruVhMxDcuCPgl17/PshG8ghScsVgYFgQYnghxOyjnC+CLb4I8fJHcK1munxJq53KK/i9zgjJkB3B6bMqlw3B6jgkYw6EZMqJkMy5EJJF3GMIzpoHQRWqIvTlWjqpYxP2Uk0Ev1gTIbkLIThPYQQ/XkS5ogjO+6RyxRCc/ynliiP4iRIIKVQaIR90i2IYseV+AkGNOiC4cGmXXFCD9jF0CFUGtOAny7qW/n91Y9UhqGpDl9KLnCEfdH8oHYKVAdBauIQDoWoPfght9AmCn3rWJRmCFG9pv85GtrAKryHozSYupRcdgmPVobPL6YPqtkGsOhR/zrU8RIc3GiKGDtXecy29tJemqh4yZo3kaMv5OIKbuK5DYL2YOoQow2ywizro66FWU0AZUhxCWEtXQtBbzV3XQRl97dF1aNzJ5fShDWPqECrXU4nnXcuj/GsIUTrYlSHFoUNoqUqw1XVdB6N1NwSrlwSO9PIiwvvjLq6VX7g00rdshWu5yjqSQ6buXqmi9Hr2RZfy8H7lNRwvrX6fYI7M43S2F5C+RUuX0sv1cK9BF9yy5IpML8cBjbvq9LYnS8NWTLmnSsNevDSMp8OdqURpmEuGuyxtP8K5jOUi04ca3jjxbBtkqvIi/MuVhn95pWeF0sgg7jm1r1gaGZXL9HxpZFYuZ82XdXxJ58hE8svRoTWyvVTaJRf4XtcYOgQ27OJSWikjR/uWEG6O8q2Kp3BNV/Ax136j1POO47dIPvgQGub6M68jXVLuHXpw7/kETJ6vQvJq8F6dqihUIA/+V68zKtZsi9DQMHRoWTd5C01DuWfIAORRxn9vr8QrLXapgk/Y8eILNpQqaYevT+LyMKvWX66sHQ3etWonx+KXmFwez2NHrRo2/Vm/qq/ZkDGDPTHJIYuotWxmxad9wtCpvRWvvGxLVHp/f6B2LSt6dLWid/cwNFS6ZM6UOBleeN6mR6/07x2G1sqo4zyCxxVh8j1uh3zC8FOVvnMHK6r+z4bEcPT3C9dhUB9geH8jSXSQBepckd05Tr6CXihVqwiKv5ADIpNzmEvHqkHac+WFLc8TgNODn0tpHZHUG3rbE8UgHWqHV6L2Xt6wFXgSdulQJypheGRJJ8aIsNfqwJ63cLhnYrYWL2WMeAmhrzeAGAbg9BDvUjbpMujRHsHthkKMM9biz7qULDKSqgNruZcR3LyXMs4MQthr6l4t00IiIyR8YHssH0LfbYP0vcfqvZwnnOp+DPvjhaANQhM3IHDYYoTW+xjKQnc/QgJHUvchqrMRpAxbAePXIrjNYNhy5UsgVdRga4UqCOozA4GTNuq9nEeNEf+Z9dlXEDBmpU4rOkhe0jbiT3U/VOJKGkdayUvyvB8j4aNQ1WELmKCMg8rIJ/sQ1QlNONX9GNJpDBy1Qhv3xNgXNGAu7Nlz34+QwJF8oSy6DmHPvZZAqqjBSaWD1/DPYB+1GInWIUNmBHefpI2k2lg6djXCXngzqpAJnEn71UZaZawVo21Iyz4JpIgaLPeBGPWg7pNRY8V9Zk8KHeq0QgwdEnGPthUri8CRS7XBWxu+lfFbjGxxSx0tRBk3Y9RD5ZrRIsV/GlrzAwSOC78eAsesQnDbIXH/zsSSlXS4o+uQqHt8hA7W0cvgO2wuAqUtJVKHMKVDkBj81TUtOoS2S5wOhjIWWNULB3nxIPUgLyLs+Vz/nbL7pYPfoDEIHLUcQb2nIWTSWmR8951YaMXtla9tY9wdsw5nPpyOa4NWIcewwbD4ecedIFpI9ueLwzLpC5zvOF87Oc5e/sloseI+lbKyjh6NK/2X42yraQgYuxZ5W6nfubiTxAiR+JJO0ks+kp/kGyNiHB4ir8gdRQelVxzRY3hLWcJN+AlH4SlcY0SkBwmkMAHVLUzhEj2suHT+vpg5qgt2bZyOH9ZOxorZA5Eze2YP04LikgAJkAAJkEAiCCgDl4wQkdEuiUgVJaqklTyg8ooS4OqJX3pt5IPau5okSjxllJOOnz2H68aQKOnViTvoYMpfBMiZR0nzYH9ipBJjKZTR9EFyEEOdTRlrkS7jgySHGEcfuh6UoTc2HVwV6KF1UEYUMXiL4RvK+Opquc7xHr4e/PT1IIYi53xdPk4KHbLmhKlQMTx4W3IDHTJlUxyVDok0mDs4e2XwgxgG/HI9WF/AUG+NMhfPB3Fy7Mg3Mft0ebIh27PF4JUukW8DIwqRdJJe8onwStTOSAIdhJ9wFJ6JKpyRSSCZCJiSKd9Ul22mDOmQPWumVKcXFSIBEiAB/jPAFwAAEABJREFUEiABEnB7AhSQBEiABEiABEggmQjQKJJMYJktCZAACZAACZDAgxBgGhIgARIgARIgARJIOQI0iqQca5ZEAiRAAiRAAlEJ8IwESIAESIAESIAESOCREqBR5JHiZ+EkQAIkkHYIUFMSIAESIAESIAESIAEScDcCNIq4W41QHhIggdRAgDqQAAmQAAmQAAmQAAmQAAl4AAEaRTygkigiCbg3AUpHAiRAAiRAAiRAAiRAAiRAAp5JgEYRz6w3Sv2oCLBcEiABEiABEiABEiABEiABEiCBVEOARpFUU5VJrwhzJAESIAESIAESIAESIAESIAESIIHUTIBGkfDafeBtnmx+8FSXJYO31tvPx+yxOngqe8od87rJmM4L6f0sbIsefE9JTe1abo6pSR/qEvOe4ylM5Dc6S3pv3ht5b3zkbSB7Jh94W0yPXA5PuXYpp1+ythUvs4EcmX2TtYyE6lCeFeg8lkAUwWkUiYKDJyRAAiRAAiRAAiRAAiRAAiRAAiSQWghQj4QI0CiSECGGkwAJkAAJkAAJkAAJkAAJkAAJuD8BSkgCD0CARpEHgJZakthsdly8ch1hVmtqUYl6eACBO3cDcOPWHZcklbZ54fJ1BIeEuhSfkUggMQR4D0wMLcZNbgJXr99CYFBIooq5FxAEuUdKW05UQkYmgXgIhKjf3EtXbsBut8cT636Q/FZL/Ps+PEopAmm5HLnvWa22tIyAuichARpFkhCmJ2X1w+6DqFizLarU74pnqnyIlRt3eJL4lNUDCQQEBqFDv8l4vlY7vFS7Axq3GwrpBMSlytwlm3TbrNqgK8q90RpdB03Hrdv34opOfxJIFIEHvQf+d/EqKlRvgwmzVyaqPEYmgbgInPnvEmq83wuv1O2E8m9+hP5j5iM0LP6XFdJ+Jc1zNdpA7pF///tfXNnTnwRcJiBGkBmfb0BZ9Zv7Wv0ueLlORxw8ejLO9GHqpdrQiV/gf+92Rr3WA3Q7/nrbnjjjP2QAk5NAJAFpq4MnLMSQiZ9H+vGABB6GAI0iD0PPQ9PKm6juQ2bik5Z1cHDbZ5g8tAMGj1+IcxeueKhGFNsTCCxdtw3H/zmH71dPwi+bZsBsMmHyvDVxip45U3p8NqEnfvtmDtbNH4a9B/7Eus0744zPABJwlcCD3gNllFPbXhMgBj5Xy2I8EkiIwLBJi/BUkfz6Xrfpi5H45vtf8c32uDuWO3YdQLs+E/HGKxUg8X/eMA358uRMqBiGexSBRyPsgSN/Y/qCdVg0tS8ObJ2Hd96sjC4Dp0HeyMcm0frNP+HLb3dhw8IR2Ll+Klo3qYWB4xbwHhkbLPolGYEtO37VBrvVm35IsjyZEQnQKJIG28Cv+4/pH6zGtV+DxWxG1crPokDeXPhh94E0SIMqpxQBedCvV+sV5MyeGRnS++ODeq9j7dc/xjk8t36tV/F8uafh5+uNJwvlxasvlMWPvxxMKXFZTiom8CD3QHkj2mPoTJQr9SSqvfpcKqZD1VKSwK079/Dz3j/U/fANfa8rmD833nnzRXz7w95YxZC3o5PnrcZbb7yAzq3rQeKLAVnuk7Em8ARPyug2BLb/tB+VypfQ9zkvL4tul5eu3MBfJ8/EKuPlqzeQNXMGpPP31eHPln5SP1/euHVXn3NDAslBoHLFZ7Bq7mDUer1ScmTPPNMoAVMa1TtNq31J/YiJEcTb2yuSQ+ECeXDx8o3Icx6QQFITOH3uEvI/nisyW8ebzdt3AyL94jqQoeQ/7z2MEsUKxhWF/iTgMoEHuQeOmb4cISFh6NfpfZfLYUQSiE4g+vnVaze1V97cOfReNnKflHVC5Di6k86mjLi7dy8QbXqNxwcdRmDGwvUICg6JHpXnJJBoAhcuX0PBfI9FppOXGHJy+Wp4O5VjZyedUhk516jNYGzevgfjZq3QBrvHH8vuHI3HJJCkBPz9fPBYjqzKGOeXpPkys7RNgEaRNFj/t9WbKX+/cKu+Q30fH2/I0HDHOfckkJQE5O2mPDj5qnbmyNcnwigXEBDk8IpzP2zSF6p9Buq3VnFGYgAJuEggsffAZeu36ZF0Ewd/Anl76mIxaT0a9XeBgMMo7PySQn6Pr9+8HWvqS1eua/9sWTKhbo1XULvai1iw4huMmrpU+3NDAg9DQO6Nvj4+UbKQ58W7AYFR/BwnObJlQdlSRZEtayaMnbkc23buw+uVyzuCuScBEiABjyFAo4jHVFXSCZoxQzo9vNE5x2D1lkmmNDj78ZgEkoqAYRiQB6vgkPtfkXEc+/tHNdBFL1Pegsq80fkTe+mpN9HDeU4CiSWQ2HvgQtXplNF1sxd9iTHTl+HIX6ew67cjkMWAw8vmlgQejEDG9P46YWhomN7LRn6Ps2bOKIdxuo6t3sUbr5SHTEns0+E9fLXtlzinIoL/SMBFAnJvDA6JOupIXmik9/eLNYdZX2zA7TsBmDOmO7YuH4/ubRqiY/8pOHHqXKzx6UkCJEAC7kqARhF3rZlklCtX9iyQqQzOD2EyHPexnFmSsVRmndYJSKdSvrLg4HD2/GV96OgU6BOnjSzsNnbGcv0WdNWcQSj1FKfOOOF5dIepoOTE3gNbNqqO8s8Ug6zdIM5sNsHXxxtxtd1UgIgqpBCB7Nky65Ic90M5+ffsReTOmVUOY7g8EdMSzkXcPyVCWJhVv+iw2+WMjgQenEDunNkg7c+Rg2PajGMajcPfsf/l96MoXrQATCYDcl9s1uBNyL99h47Ljo4ESIAEPIYAjSIeU1VJJ2iFMk/pzGRIuCwe+N3O3/WXZ16pVEb7c0MCyUGg2qsVsGrjDshD1t17gVi0eivq1ngZhmHo4hau/EbPj9cnajNg7HyI34RB7ZEpY3rIp1DFSZtVwSnyx0JSJ4GE7oF7D/yJeq0HauOxEGhY+zV89P5bke6pIgVQrlRRiL+E05HAgxLIlCGdXthS7ofyVaRTZy7or3m88UqFyCy7Dpqh12oQD4lfuWIpTFuwDvIG/8x/l7Hmqx/x+svldcdU4tCRwIMSeO2lsnrh332HT0DW8vpi9RbkypEFxQrn11nKb7KsY6NP1ObpYk9g09ZdkHYo02TleVJ546WKpWVHRwLJQsBqtUFe7FqtVohRWI7lRVqyFMZM0wwBU5rRlIpGEpAFiqYO74TR05fhmSofolP/qfi08wdwXugtMjIP0gqBZNfzvTpVUahAHvyvXmdUrNlW/6B1aFk3stwrV2/iz7/vr3AvHVMJlMUE32jUHQ7334Wr4k1HAg9MIKF7oMyfP3biNLh45QMjZsJEEOjX8X09Jav8mx+hVtM+elrMm/97LjKHU2fO4/zF+/e9Tzs3xfWbd1ChehtUb9IT8uWPT9VveGQCHpDAAxIoU6II2jR9W72gGI4yVT/Eig3fY/zAdpEGt+i/050+fBdVXnoW77YagOdqtMWcxRsxut/H4EKrD1gBTOYSgTVf/YAyr7eCTK1e/81P+nj9NztdSstIJBAXARpF4iKTyv1fe7EsDm2bj2+Xj8OBrfPQ+J0qqVxjZ/V4/CgIyIP7zFFdsGvjdPywdjJWzB4YZY2QHu0aYe/mWZGibVk2Fkd2LIzhZBpOZCQekMADEojvHvi/F8rqdlescL5Yc58wqB26ftwg1jB6kkBiCRTMnxtyv9u+aiJ+/XoWhvduBecFfdfNH4YJg9pHZisvMFbPHYzvV0/CzvVTIestZc+aKTKcByTwoAQMw4C8rPh9yxxsVc+He76aibIli0Zm1yPa77RMJxzUvTl2b5qOjV+MgLRL+SJNZAIekEAyEGjw9v/0b7TzM6KMPE6GophlGiJAo0hqr+x49JP5n2LNd374iic6g0ggSQjI8G8+wCcJSmbykAR4D3xIgEyepARkmoIYj13NVNZ5yJo5g6vRGY8EXCYgaybJ+jWyVogriSxmM+QTqa7EZRwSIAEScEcCqcoo4o6AKRMJkAAJkAAJkAAJkAAJkAAJkAAJkEDSEkiq3GgUSSqSzIcESIAESIAESIAESIAESIAESIAEkp4Ac0xGAjSKJCNcZk0CJEACJEACJEACJEACJEACJJAYAoxLAilLgEaRlOXN0kiABEiABEiABEiABEiABEggnAC3JEACj5wAjSKPvAooAAmQAAmQAAmQAAmQAAmkfgLUkARIgATckQCNIu5YK5SJBEiABEiABEiABEjAkwlQdhIgARIgAQ8hQKOIh1QUxSQBEiABEiABEiAB9yRAqUiABEiABEjAcwnQKOK5dUfJSYAESIAESIAEUpoAyyMBEiABEiABEkhVBGgUSVXVSWVIgARIgARIIOkIMCcSIAESIAESIAESSO0EaBRJ7TVM/UiABEiABFwhwDgkQAIkQAIkQAIkQAJpkACNImmw0qkyCZBAWidA/UmABEiABEiABEiABEiABIQAjSJCgY4ESCD1EqBmJEACJEACJEACJEACJEACJBAHARpF4gBDbxLwRAKUmQRIgARIgARIgARIgARIgARIwHUCNIq4zoox3YsApSEBEiABEiABEiABEiABEiABEiCBhyJAo8hD4UupxCyHBEiABFIfgTt3A7D9p33aBQaFRFHw0NGTEBfF041ORLbG7YbiyrWbWqr9f5zAxm936ePk2Fy6cgNS3h9/nYoz+2MnTmuWDqYnT5+PM64nBmzZsRe7fzuSIqJLe9z6429YsHwzlqz9DnJ8+Wp4XaeIAElYiLRNaTtXr99KwlyZFQmQAAmQAAmkHgLuZxRJPWypCQmQAAmQQDwEzl24gg6fTtFu2frvosSct+wriIvi6UYnd+4FaqNNcEiolmrDNz+j94g5+jg5NsEhIbq8u3cD48xeOu4Dxy3QPIdNXoQ9+47FGTd6wIzPN6DyOx2iez+S8z37j6HEq81x5r/LUcofPX0pFq/dGsUvOU5O/vsfXq7TEZ0HTMP85V9j0tzV+vh/9Trjq22/6CKDVb2LjBu2/KzP3WXzQYcR+HT0Z1HEuRvRVkPDrFH8eUICJEACJEACbkHADYSgUcQNKoEikAAJkEBaJlC4QB7M/PxL3Lpzz2Mx9GzfGLs2Tn+k8nf88F2M6PORlmHmqK54r04VfezKxm6zuRItReLYbfaIchz78NP1C4ZjzKdtwk+SaWtTZfcdOU/nvumLkdi5fir2bp6F71ZOQNP61RAWYViw28Nls7kRNxFa5BInx3QkQAIkQALuR4ASuScBGkXcs14oFQmQAAmkGQKdP6qPgMAgfL7ymzh1Dg0Nw5TP1qBa4x56FEHLLqNx5K9/I+MfPHoS738yHDJlZOr8tWjVfSyWrtsGh/+mrbt1uLzdb955FM78dwlfb9uDhh8PRoXqbTBiyhJcuHQtMr+FK75Bjfd76TAJl/wkr8gI0Q6+2rYbg8cvjPSV6S59R87Fa/W76DxENufpNafPXUKHfpN1mIzQkLjXb96JTH/r9j30GzVPh0v5A8YuiAxL7MGKDdvRddB0rNq0A3VafjziyXAAABAASURBVKrzHDtjORzTQXbuOYTlKo6UL3KKW/nl97oYmeI0fPIirYewE+5//n1Gh8mm/5j5ejSF5NFz6CwIWzFudR00I7KuRD8ZRSNMJI3DyVQYyU/0E9ZDJ36Bv06exZCJn+sokofIMmhcONeJc1apOr0/okimg0iZkr/k0Wv4bIifTqw2CemtosT4k3YoU5TqVH8JBfPnjgzPnTMreinDV+1qL2q/boNn6P2sL77U7UrklCk34WXOgIw2GaL0ER77Dh/XcXfuOazjCkdpxzM+3wDH6A1pW5KHtElJI/qIbs5tXDIR9sJM8hC9ZTSLpJPrY87ijZCpMt/+8JsuR/xlmpekE/fL70d0/cSVt8ShIwESIIEkJMCsSMBjCNAo4jFVRUFJgARIIHUSkA7nh41rYPaijZFrdETXdPjkxTr8+WefRv8uTXHxynU0+HgQzp4Pn2Jx+8493SF8u1lfbFWdwmxZMuosHP7SYS5Xqij6dmyiO6zVm/SCTDV58bmSaN/iHazbvBOfr9qi08jmzr0AvPFKBQzu3gIDVHl37gSgVbexkKkIEh7diUHlwJG/I72l0/zLvqPo0LKuzqNoobz4evseHS7GCDEC3FSGD8m7VZNa2KkME31Hhk+/sdns+KjHOKz/5ifUqFJRl//4Y9l12gfZ/HfxKrbs2IuZqhNe7dXn8NH7tbBQGaCWrgs3MORReRcvWkBnXbPq8xAn8lqtNq3zj78cQrMGb2JU349wLyAIMkVDjCWSQNYxGT9rJdr0moB7yrCVMYM/YAfCrGFoWPt/mDj4E3zSog5+/vUw+o2eJ0m0+2H3QW24unHrDrq3aYC6NV7Gtz/sxbUbt/FihZI6zv9eKKNlqVT+aX0uBgHHlBoxJjTtOALf7zqAxnWqokWj6tj+036In4RJgoT0ljjRXfp0fqhYtrhqDz/hy29/hhinoseR81eVbLJ/5unCWkZhZrGYEV7mr3i7eT+c+OccsmfNBKviKPXbptd45M2TA5OHdkC1Vytg+oJ1WLQ6vM3djmi/PYbOhNRFF2UoFEPJkAnhBiIp67yqx3dbDcCJU+cg4V0/bqCNQGIIsdpsKPVUIeTKkQWFlDFH5BEn5SPin0yriSvviCjckQAJPDABJiQBEvBkAjSKeHLtUXYSIAESSCUEWjaqAX8/X8jb7ugqiRFBRjlIHDFSNKr9GpZO76+jLVr9rd47NiP7tsaXn4/A6H4fR5k+svazoZBOZJO6r+sOtMTf+MUIyJST5qrD/16dKvj+5/3irZ0YMzq3roc3Xi2PSuVLoHnDNyGjCP5xYfFS6QRLR7XKS+VQp3plbdgY2LUZJgxqr/OWETGi6+wxXfHWGy+gWf1qyjBTRxlGDkOMAj/vPQwZrSA6iL4S5+MP3tJpH3STNXMGfLVoNNo0fRutlRFGpoKIEULyk+lL0rmXOI3fqQJxZUsWxY97Dmo5xvRvo2UUOYb2+lBzkHU/JK240sowINNMpo/ojClDOyJTxnR6L/X1SqVn8IoyILz9xot6kVRhI2nGz1qBvLlzYN38Ycp48hpavVcTW5aNhchR5aVnJYpmI7JUU4Yc7eG02f7TPshom3ED2qJds9rajVVyip9zPYpOcentlF2UQzE4FMibC31GzMULb7fXo2Rk1I6MQnJEfOv1F/ShtA2RUZyXMoqIp9SttLdFU/tC5KtQ5ilMmL1SG3vEsFS18rO6LYphZP3mnyRJpFszb4gekSLtsWe7xpq/tH+JsGjNVtlhzbyhmpe0rXdrvqz9ZCOy5MmVHUUKPg6RR5wYvCRM3Jp48pZwOhJwmQAjkgAJkEAqI0CjSCqrUKpDAiRAAp5IIHOm9HoEw9J12+AYDeDQ49TZC/rwubJP6b1sJL689T524oycRroKZYpHHjsfZMyQLvLU8fY8Qzr/KH6y8KvDQ0YlyJSZZ6p8iFfqdkL3ITN1UFBw+MKq+iSOjdlsQjXVkRddZArDtPnrcPjYP/Dz9dYpjhz/VxsWmnYciXqtB2onXzmRwEtXruspJHIsnVzZJ4WTjrqjfMlPRhSIAUGO43J//X1WBw2d+IWWUWTtNWyW9pNRC/pAbZ4qkh9ifFCHkX9bdvyqp+qUe6M1qtTvChmZIoE2mw2ySKkYGKooo5H4OZzImM7f13Ea717SS4SypYrKTjvH8d///qfPZSN5+kVwl3NX9C5VvBBWzRmEz8b3hBjGShcvDBm1I6OQZISL5BOfExbFCueLjCJTW47/cw7HTpyO5Cgsd+45DIcejsiZMqZ3HCJnjiz6+NLVG3r/199n9CiSnNkz6/PEbuLLO7F5paX41JUESIAESCD1E6BRJPXXMTUkARIgAY8g0KRuVT1aZMbn66PIGxISps+jd5jTp/NDmNWqwxKzMRkxf/rMZnNkFrImxrutBkCmiswb1wPbV03E+gXDIsNdORjT/2M9bSaLMvbItJxGbYdA1sSQtIGBwZDRFZ1avQuH+7TzB5g1uivy5skZOUXH2ZAj6ZLSOUY1xJdnUHCIDnbIKHsZbSNyvvpCWR0W2+bnvX+g66AZePrJJ7BsRn+9WOmg7s0jo4qRQE4yyFQbOXgAFxISbpzy8faKTO04tsbTJlzRWzI0DAMyVUtG1Uwa8gl+WDtZt80NW6KO7JC4CbmQ0PD2W+WlZyPrW1hOGNRO1Xm3OJNblHHNOVDy8fP1cfaKPDYMI/LYlYPoeUek4Y4ESIAESIAE0iSBmE+GaRIDlSYBEiABEnjUBOStfrc2DbDx213Yf/hEpDj5H8+pj52nbMiilnsP/ImC+R7TYUm5OXT0H51dz3aN9NQZGV3g6HDrABc2BgzUq/UKpg7vhF1fToNMPZm39Cu9voRMb5ARIeWfeQqVK5aOdC89VwoZ0/sjT65suoQT/4SP1NAnybzx8fFGUHC4ocFRlGOh0dw5s0XK6JA3X54cjmgx9lIv4jmoewtt/MmaOQMsTkYnMWaJ346fD0i0KM5ms8PHJ9zQERxh+IgSIeJEprfIofNCoo56k2k5Eha/iz1UDGIy9Sl6qMjsq+SSKVQSJuuHyN5hnJHjuJwY80Tf23cDYnB86bnw9VPiSuvsLzrvO3wcAcqo5vB3rHHj+OKMv58P5NpwhHNPAiRAAiRAAiSQMAEaRRJmxBgkQAIkQAIpRKBu9coQI8R1py+xSGdQppIsXfsd5KsosgClrPEgItV/61XZJakrUewJnd+qjTsgne6tP/6mRz5oTxc20rF+q1kf/XUbmQok0zlOnb6gpz6YTAbef/d1XLpyQ+U5XX8d5+Tp8/hq2y+o/9Eg3Lx1Fy9XekaXIl+ckS+JbNmxV8UN/9qJDohjI4vPOhae/ffsBb0Ip47qwua5Mk+pznYQZMFZ+QKMTPeQtS+kLjr2nwKZNiLTbWTfddB07Ngd06DhKEbWI5HjJWu2QtZGkTqTNTXEz+GaN6yuw+TLMof/PIXfDv6lv8Zz+M9/UOLJ+/xFjn1OBjJH+iqVn9UjN0ZPX4Yduw5o+cbMWKb9JMwRL7F74S9TnkRn+RLM0eP/6kVq+46cC2mTso6H5ClGnsoVS2Hj1t16WowsqhvfqKW2zd5R+fyq1xaRhVLlqzJL1m7Fxz3HS3YuuYZv/0/Hq9a4O+TrQSLjqGlLtZ9jU+nZEti555DmKW3XsR6JI5x7EiABEiABEiCBmARoFInJhD4kQAIkQAIpSMAwjMjSvL290PWjBpHnjoMRvVujaMG8GDzhc7zXbqjuYA7r9SEcHXBHPKesHF567+xvKMOEeDr7ybnDyVv9Hm0bYeuPv6OxKqvzgGlwrBHhSGOKODCMcNkNI3wveXh7eUEWuJQviVRv0lOvI5ErZxaM7vcRDMPQxhGZgiKLtoouslZFz6GzkD1rRsiIjcdyZNVfepE1KLoMnKYMItMjy8f9YqSoKG76gvUYPnmR9pPpKyuVUUdODCO2RFH9ShQrqEezyBdK6n7YX/OVEQ7zxveEyNOuz0TIF3NkL4YeWdBT8jabYj5GyBd9alZ5HmNnLkfDjwdj6vy1KFOiiESPdLLQa9umtbFq0w40ajMYzTqNhHTgc2TNBGkDPds3xubte/S6JJJPZMKIAxlRM298D2WouI32fSdB5Lp+8zY+U34SJtEMI6qO4of4AAJ6bRSRTUYqSf2JoUqMQPJlIVkktdqrz6lY4X/N6r8J+WqMrA/yYdcxkFEjhhFbmYAYNHopnZat3453Wnyqv5w0YsoSyHos4bmFb2NL7vCTKVczRnZBsSL5seu3P5AxfTrIV5skpbQ52b/xagWUeqqg5ilt96TT+iqOfCSew8Xm5wjjngRIgARIgATSCgFTWlGUepIACZBAKiPg8erIQqlHdiyM0TGs9XoliL98ycShpCwuOX9iL/y8YRo2LxmNg9s+0192cYTLtA5JIx14h5/sY/OXDrvElek6EkecfO1D/ORYXPOGb+KnDVOx6YuR+O2bORjeu5WWqUKZ8MVeZeSKxH/8sewSHfK1mu2rJupjP19vyFok+76di2+WjsF+tRddCj/xuA6XjcglX1vZtXE6vl0+TseZNbpb5GKsMt3m9y1zdPmS3lH+8+WeluSxuqE9W2oZRS5x7ZrV1vG6fFRff9lFn0RsmtStquNGnMJsNkE6/Xs3z9LrZ3zSoo4OKpQ/N4S7yCLy/vr1LKyeOzjSSLNi9kDIl3V05IiNjKKQL9bs+nK6rqsdaybraUQik5fX/9m7fx4pyjgO4M9sFIx4nIJC0OgrMLG2ojZWJha2WvtGLCRU2lkYCxEtTAyJCQd0JJS8D0JICKHkvntsuFsWbm+ZnZln5lMMu7fzzPPn8xuK/WZ25q15q9zb48cfvin3934rN6/9XO7+90tJXwmT0iBP5Ln9z9Wyd/1KyVNc8lnuT5I15n22PKlm768r5ebzLe8THGRftnXWnXaHt5333p0//SVP00ltUv+8prapyeG2OQfypKPbf1+dnyM5n1aNmWPim7Dl3o1fy539deWYrD33aMn+nA/xOXz+Lv5/fL4fWKVNtstffjE/t/LUnoSCj588LbmSajY7CGNyPqZeOXcz78xx3b7Tv40AAQIECExRQCgyxapbMwECBCoVyFNnPvvk4pF7VGxrKbmPSO6rkZBjkzFOn3q7fPrxhfmVD686fnfnTMkX2VwdsdzmndOnSsZftW+5bVt/54v9h+d2S9McfMle9Ju55F4duXpk8dlxr7tnz5TUKoHAq9pm36WL58vZ/TBiuU3ClYQEeV3et/i7aZpy6cK5+dY0R+e8aLPpa2oT/7y+ro8EduueI03TlI/Ov19yTNb+un6X9+UeK7nyJj9F+v36/yU/Ibv2763y/XdfLTctH+zulOPm/dJBPiBAgAABAhMVEIpMtPCWTYAAgTYF9EWAwHYFZrPZ/KqQ3DPkz/0w5MHDRyVX5Hz79eXtDqx3AgQIECAwcgGhyMgLbHkECLQuoEMCBAh0LpCfHCUEyU+lzt3sAAADwUlEQVRnbvzxU8nPrfJTsKZp9wqZzhdmQAIECBAg0LOAUKTnAhiewLAFzI4AAQIECBAgQIAAAQLjFRCKjLe2VnZSAe0JECBAgAABAgQIECBAYFICQpFJlfvFYr0jQIAAAQIECBAgQIAAAQJTF5hCKDL1Gls/AQIECBAgQIAAAQIECBCYgsCJ1ygUOTGZAwgQIECAAAECBAgQIECAQN8Cxm9DQCjShqI+CBAgQIAAAQIECBAgQGB7AnomsCUBociWYHVLgAABAgQIECBAgACBTQQcQ4BAdwJCke6sjUSAAAECBAgQIECAwFEBfxEgQKBXAaFIr/wGJ0CAAAECBAgQmI6AlRIgQIDA0ASEIkOriPkQIECAAAECBMYgYA0ECBAgQKACAaFIBUUyRQIECBAgQGDYAmZHgAABAgQI1CkgFKmzbmZNgAABAgT6EjAuAQIECBAgQGA0AkKR0ZTSQggQIECgfQE9EiBAgAABAgQIjFlAKDLm6lobAQIETiKgLQECBAgQIECAAIGJCQhFJlZwyyVA4EDAvwQIECBAgAABAgQIEBCKOAcIjF/ACgkQIECAAAECBAgQIEBghYBQZAWKj2oWMHcCBAgQIECAAAECBAgQILCegFBkPadhtjIrAgQIECBAgAABAgQIECBAYGOBakKRjVfoQAIECBAgQIAAAQIECBAgQKAagS4nKhTpUttYBAgQIECAAAECBAgQIEDghYB3PQsIRXougOEJECBAgAABAgQIECAwDQGrJDA8AaHI8GpiRgQIECBAgAABAgQI1C5g/gQIVCEgFKmiTCZJgAABAgQIECBAYLgCZkaAAIFaBYQitVbOvAkQIECAAAECBPoQMCYBAgQIjEhAKDKiYloKAQIECBAgQKBdAb0RIECAAIFxCwhFxl1fqyNAgAABAgTWFdCOAAECBAgQmJyAUGRyJbdgAgQIECBQCgMCBAgQIECAAIFShCLOAgIECBAYu4D1ESBAgAABAgQIEFgpIBRZyeJDAgQI1Cpg3gQIECBAgAABAgQIrCsgFFlXSjsCBIYnYEYECBAgQIAAAQIECBB4AwGhyBvgOZRAlwLGIkCAAAECBAgQIECAAIF2BYQi7XrqrR0BvRAgQIAAAQIECBAgQIAAga0LCEW2TnzcAPYTIECAAAECBAgQIECAAAECfQh0G4r0sUJjEiBAgAABAgQIECBAgAABAt0KVDKaUKSSQpkmAQIECBAgQIAAAQIECAxTwKzqFRCK1Fs7MydAgAABAgQIECBAgEDXAsYjMCqBZwAAAP//tPkCJAAAAAZJREFUAwBPzoLEe5hkLwAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.line(interaction_df, x=\"Normalised Interaction Strength\", y=[\"Closed\", \"Open\"], \n",
    "    markers=True, title=\"Comparison of the KDEs obtained for Closed and Open Confs\"\n",
    ")\n",
    "fig.update_layout(yaxis_title=\"Density\")\n",
    "fig.show() # to make this plot interactive, remove \"svg\" and run the cell block. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above graph it is clear that interaction above is only present in the closed WPD-loop conformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.X (REMIX) Project the Results onto Protein Structures with the chimerax_projections.py module. \n",
    " \n",
    "Naturally, we may want to visualise some of the results we have generated above onto a protein structure. We can take advantage of\n",
    "the functions provided in the pymol_projections.py module to do this. \n",
    "\n",
    "As the name suggests this will output ChimeraX compatible python scripts which can be run to represent the results\n",
    "at the: \n",
    "\n",
    "1. Per feature level. (Cylinders are drawn between each feature, with the cylinder radii marking how strong the relative difference is. \n",
    "2. Per residue level. The Carbon alpha of each residue will be depicted as a sphere, with the sphere radii depicting how strong the the relative difference is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: pickle the stat_model object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from key_interactions_finder import chimerax_projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: LBP_stat_analysis/jensen_shannon_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/mutual_information_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n"
     ]
    }
   ],
   "source": [
    "# Write ChimeraX compatable scripts for the per feature results.\n",
    "# Simply swap between the two statistical methods as shown below. \n",
    "chimerax_projections.project_chimerax_top_features(\n",
    "    per_feature_scores=stat_model.js_distances,\n",
    "    model_name=\"jensen_shannon\",\n",
    "    numb_features='all', # can be any integer values or \"all\" if you would like all features returned.\n",
    "    out_dir=stats_out_dir,\n",
    "    pdb_file=pdb_file,\n",
    ")\n",
    "\n",
    "chimerax_projections.project_chimerax_top_features(\n",
    "    per_feature_scores=stat_model.mutual_infos,\n",
    "    model_name=\"mutual_information\",\n",
    "    numb_features='all', # can be any integer values or \"all\" if you would like all features returned.\n",
    "    out_dir=stats_out_dir,\n",
    "    pdb_file=pdb_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: LBP_stat_analysis/jensen_shannon_ChimeraX_Per_Res_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/mutual_information_ChimeraX_Per_Res_Scores.cxc was written to disk.\n"
     ]
    }
   ],
   "source": [
    "# Write PyMOL compatable scripts for the per residue results.\n",
    "# Simply swap between the two statistical methods as shown below. \n",
    "chimerax_projections.project_chimerax_per_res_scores(\n",
    "    per_res_scores=js_per_res_scores,\n",
    "    model_name=\"jensen_shannon\",\n",
    "    out_dir=stats_out_dir\n",
    ")\n",
    "\n",
    "chimerax_projections.project_chimerax_per_res_scores(\n",
    "    per_res_scores=mi_per_res_scores,\n",
    "    model_name=\"mutual_information\",\n",
    "    out_dir=stats_out_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again using other PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: LBP_stat_analysis/open/jensen_shannon_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/open/mutual_information_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/open/jensen_shannon_ChimeraX_Per_Res_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/open/mutual_information_ChimeraX_Per_Res_Scores.cxc was written to disk.\n"
     ]
    }
   ],
   "source": [
    "# Write ChimeraX compatable scripts for the per feature results.\n",
    "# Simply swap between the two statistical methods as shown below. \n",
    "pdb = \"open\"\n",
    "\n",
    "chimerax_projections.project_chimerax_top_features(\n",
    "    per_feature_scores=stat_model.js_distances,\n",
    "    model_name=\"jensen_shannon\",\n",
    "    numb_features='all', # can be any integer values or \"all\" if you would like all features returned.\n",
    "    out_dir=stats_out_dir + f\"/{pdb}\",\n",
    "    pdb_file=f\"{pdb}.pdb\",\n",
    ")\n",
    "\n",
    "chimerax_projections.project_chimerax_top_features(\n",
    "    per_feature_scores=stat_model.mutual_infos,\n",
    "    model_name=\"mutual_information\",\n",
    "    numb_features='all', # can be any integer values or \"all\" if you would like all features returned.\n",
    "    out_dir=stats_out_dir + f\"/{pdb}\",\n",
    "    pdb_file=f\"{pdb}.pdb\",\n",
    ")\n",
    "\n",
    "chimerax_projections.project_chimerax_per_res_scores(\n",
    "    per_res_scores=js_per_res_scores,\n",
    "    model_name=\"jensen_shannon\",\n",
    "    out_dir=stats_out_dir + f\"/{pdb}\"\n",
    ")\n",
    "\n",
    "chimerax_projections.project_chimerax_per_res_scores(\n",
    "    per_res_scores=mi_per_res_scores,\n",
    "    model_name=\"mutual_information\",\n",
    "    out_dir=stats_out_dir + f\"/{pdb}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: LBP_stat_analysis/closed/jensen_shannon_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/closed/mutual_information_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/closed/jensen_shannon_ChimeraX_Per_Res_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/closed/mutual_information_ChimeraX_Per_Res_Scores.cxc was written to disk.\n"
     ]
    }
   ],
   "source": [
    "pdb = \"closed\"\n",
    "\n",
    "chimerax_projections.project_chimerax_top_features(\n",
    "    per_feature_scores=stat_model.js_distances,\n",
    "    model_name=\"jensen_shannon\",\n",
    "    numb_features='all', # can be any integer values or \"all\" if you would like all features returned.\n",
    "    out_dir=stats_out_dir + f\"/{pdb}\",\n",
    "    pdb_file=f\"{pdb}.pdb\",\n",
    ")\n",
    "\n",
    "chimerax_projections.project_chimerax_top_features(\n",
    "    per_feature_scores=stat_model.mutual_infos,\n",
    "    model_name=\"mutual_information\",\n",
    "    numb_features='all', # can be any integer values or \"all\" if you would like all features returned.\n",
    "    out_dir=stats_out_dir + f\"/{pdb}\",\n",
    "    pdb_file=f\"{pdb}.pdb\",\n",
    ")\n",
    "\n",
    "chimerax_projections.project_chimerax_per_res_scores(\n",
    "    per_res_scores=js_per_res_scores,\n",
    "    model_name=\"jensen_shannon\",\n",
    "    out_dir=stats_out_dir + f\"/{pdb}\"\n",
    ")\n",
    "\n",
    "chimerax_projections.project_chimerax_per_res_scores(\n",
    "    per_res_scores=mi_per_res_scores,\n",
    "    model_name=\"mutual_information\",\n",
    "    out_dir=stats_out_dir + f\"/{pdb}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using all trace points (aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: LBP_stat_analysis/trace_300_ali/jensen_shannon_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_300_ali/mutual_information_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_300_ali/jensen_shannon_ChimeraX_Per_Res_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_300_ali/mutual_information_ChimeraX_Per_Res_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_450_ali/jensen_shannon_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_450_ali/mutual_information_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_450_ali/jensen_shannon_ChimeraX_Per_Res_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_450_ali/mutual_information_ChimeraX_Per_Res_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_600_ali/jensen_shannon_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_600_ali/mutual_information_ChimeraX_Per_Feature_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_600_ali/jensen_shannon_ChimeraX_Per_Res_Scores.cxc was written to disk.\n",
      "The file: LBP_stat_analysis/trace_600_ali/mutual_information_ChimeraX_Per_Res_Scores.cxc was written to disk.\n"
     ]
    }
   ],
   "source": [
    "pdbs = [\"trace_300_ali\", \"trace_450_ali\", \"trace_600_ali\"]\n",
    "\n",
    "for pdb in pdbs:\n",
    "    chimerax_projections.project_chimerax_top_features(\n",
    "        per_feature_scores=stat_model.js_distances,\n",
    "        model_name=\"jensen_shannon\",\n",
    "        numb_features='all', # can be any integer values or \"all\" if you would like all features returned.\n",
    "        out_dir=stats_out_dir + f\"/{pdb}\",\n",
    "        pdb_file=f\"{pdb}.pdb\",\n",
    "    )\n",
    "    \n",
    "    chimerax_projections.project_chimerax_top_features(\n",
    "        per_feature_scores=stat_model.mutual_infos,\n",
    "        model_name=\"mutual_information\",\n",
    "        numb_features='all', # can be any integer values or \"all\" if you would like all features returned.\n",
    "        out_dir=stats_out_dir + f\"/{pdb}\",\n",
    "        pdb_file=f\"{pdb}.pdb\",\n",
    "    )\n",
    "    \n",
    "    chimerax_projections.project_chimerax_per_res_scores(\n",
    "        per_res_scores=js_per_res_scores,\n",
    "        model_name=\"jensen_shannon\",\n",
    "        out_dir=stats_out_dir + f\"/{pdb}\"\n",
    "    )\n",
    "    \n",
    "    chimerax_projections.project_chimerax_per_res_scores(\n",
    "        per_res_scores=mi_per_res_scores,\n",
    "        model_name=\"mutual_information\",\n",
    "        out_dir=stats_out_dir + f\"/{pdb}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.3. Project the Results onto Protein Structures with the pymol_projections.py module. \n",
    " \n",
    "Naturally, we may want to visualise some of the results we have generated above onto a protein structure. We can take advantage of\n",
    "the functions provided in the pymol_projections.py module to do this. \n",
    "\n",
    "As the name suggests this will output [PyMOL](https://pymol.org/) compatible python scripts which can be run to represent the results\n",
    "at the: \n",
    "\n",
    "1. Per feature level. (Cylinders are drawn between each feature, with the cylinder radii marking how strong the relative difference is. \n",
    "2. Per residue level. The Carbon alpha of each residue will be depicted as a sphere, with the sphere radii depicting how strong the the relative difference is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: LBP_stat_analysis/jensen_shannon_Pymol_Per_Feature_Scores.py was written to disk.\n",
      "The file: LBP_stat_analysis/mutual_information_Pymol_Per_Feature_Scores.py was written to disk.\n"
     ]
    }
   ],
   "source": [
    "# Write PyMOL compatable scripts for the per feature results.\n",
    "# Simply swap between the two statistical methods as shown below. \n",
    "pymol_projections.project_pymol_top_features(\n",
    "    per_feature_scores=stat_model.js_distances,\n",
    "    model_name=\"jensen_shannon\",\n",
    "    numb_features='all', # can be any integer values or \"all\" if you would like all features returned.\n",
    "    out_dir=stats_out_dir\n",
    ")\n",
    "\n",
    "pymol_projections.project_pymol_top_features(\n",
    "    per_feature_scores=stat_model.mutual_infos,\n",
    "    model_name=\"mutual_information\",\n",
    "    numb_features='all', # can be any integer values or \"all\" if you would like all features returned.\n",
    "    out_dir=stats_out_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: LBP_stat_analysis/jensen_shannon_Pymol_Per_Res_Scores.py was written to disk.\n",
      "The file: LBP_stat_analysis/mutual_information_Pymol_Per_Res_Scores.py was written to disk.\n"
     ]
    }
   ],
   "source": [
    "# Write PyMOL compatable scripts for the per residue results.\n",
    "# Simply swap between the two statistical methods as shown below. \n",
    "pymol_projections.project_pymol_per_res_scores(\n",
    "    per_res_scores=js_per_res_scores,\n",
    "    model_name=\"jensen_shannon\",\n",
    "    out_dir=stats_out_dir\n",
    ")\n",
    "\n",
    "pymol_projections.project_pymol_per_res_scores(\n",
    "    per_res_scores=mi_per_res_scores,\n",
    "    model_name=\"mutual_information\",\n",
    "    out_dir=stats_out_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heres an example of the figures you can make , see the manuscript for more examples and what the figures represent.\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/kamerlinlab/KIF/main/tutorials/miscellaneous/ptp1b_example_outputs.png\" alt=\"Drawing\" style=\"width: 70%\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 Perform Machine Learning (ML) with the model_building.py module. \n",
    "\n",
    "Now we will use ML to generate models that can describe the difference between the WPD-loop closed and open states. \n",
    "\n",
    "With this module, we use the per feature scores from each ML model to to evaluate how different/similar each feature is when the protein is in the closed WPD-loop conformation or the open-WPD-loop conformation.\n",
    "\n",
    "**We will use three ensemble based classification models:**\n",
    "\n",
    "1. [Categorical Boosting](https://catboost.ai/) - (Refered to as: CatBoost)\n",
    "\n",
    "2. [Extreme Gradient Boosting](https://xgboost.readthedocs.io/en/stable/) - (Refered to as: XGBoost)\n",
    "\n",
    "3. [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)  (Refered to as: Random_Forest)\n",
    "\n",
    "In all cases, the higher the score, the more \"different\" the feature is when in the two different states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will remove all feature involving the WPD-loop, otherwise the model building will be too easy.\n",
    "# This was discussed in detail in the preprint, but the basic idea is that if the WPD-loop interactions are \n",
    "# included then only one of two of these interactions would be enough to predict the conformational state of \n",
    "# the WPD-loop which is non-ideal for our goals. \n",
    "\n",
    "df = supervised_dataset.df_filtered\n",
    "\n",
    "# For D1D2, nothing seems super important, going to use ML with all features\n",
    "\n",
    "# filter to remove those residues on the WPD-loop (residues 176-189)\n",
    "#df_no_WPD_loop = df.loc[:, df.columns.str.contains('176|177|178|179|180|181|182|183|184|185|186|187|188|189')==False]\n",
    "#df_no_WPD_loop.head(3)\n",
    "\n",
    "# We will now use \"df_no_WPD_loop\" in the following cell as the dataset instead of \"supervised_dataset.df_filtered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Below is a summary of the machine learning you have planned.\n",
      "You will use 10-fold cross validation and perform 3 repeats.\n",
      "You will use up to 411 features to build each model, with 80.0% of your data used for training the model, which is 14253 observations. \n",
      "20.0% of your data will be used for evaluating the best models produced by the 10-fold cross validation, which is 3564 observations.\n",
      "You have selected to build 3 machine learning model(s), with the following hyperparameters: \n",
      " \n",
      "A CatBoost model, with grid search parameters: \n",
      "{'iterations': [100, 250, 500]} \n",
      "\n",
      "A XGBoost model, with grid search parameters: \n",
      "{'n_estimators': [100, 250, 500]} \n",
      "\n",
      "A Random_Forest model, with grid search parameters: \n",
      "{'n_estimators': [100, 250, 500], 'max_depth': [100]} \n",
      "\n",
      "If you're happy with the above, lets get model building!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the ClassificationModel class. \n",
    "# Clearly there are many parameters here, using your IDE you can hover over ClassificationModel to see what each parameter does\n",
    "ml_model = model_building.ClassificationModel(\n",
    "    dataset=df, # if want all residues included can replace this with: \"supervised_dataset.df_filtered\"\n",
    "    evaluation_split_ratio=0.20,\n",
    "    classes_to_use=[\"closed\", \"open\"], \n",
    "    models_to_use=[\"CatBoost\", \"XGBoost\", \"Random_Forest\"],\n",
    "    scaling_method=\"min_max\",\n",
    "    out_dir=ml_out_dir, \n",
    "    cross_validation_splits=10, \n",
    "    cross_validation_repeats=3,\n",
    "    search_approach=\"quick\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go ahead and build the models.\n",
    "\n",
    "We have one optional parameter in the command below which is to save the models generated. This can be useful if you ever want to come back and do the post-processing later.\n",
    "\n",
    "If you set this to true all the files required will be saved to a folder called \"temporary_files\" in your current working directory. \n",
    "\n",
    "With the current setup this calculation will not take long (maybe 5-10 mins to run on a standard laptop). However, you could perform a very exhausitve calculation using grid search CV (possible by changing the \"search_approach\" parameter in model_building.ClassificationModel() ), in which case it might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk at: temporary_files/CatBoost_Model.pickle\n",
      "Model saved to disk at: temporary_files/XGBoost_Model.pickle\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ml_model.build_models(save_models=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/key_interactions_finder/model_building.py:215\u001b[39m, in \u001b[36m_SupervisedRunner.build_models\u001b[39m\u001b[34m(self, save_models)\u001b[39m\n\u001b[32m    211\u001b[39m start_time = time.monotonic()\n\u001b[32m    213\u001b[39m clf = GridSearchCV(mod_params[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], mod_params[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    214\u001b[39m                    cv=\u001b[38;5;28mself\u001b[39m.cross_validation_approach, refit=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m clf.fit(\u001b[38;5;28mself\u001b[39m.ml_datasets[\u001b[33m\"\u001b[39m\u001b[33mtrain_data_scaled\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    216\u001b[39m         \u001b[38;5;28mself\u001b[39m.ml_datasets[\u001b[33m\"\u001b[39m\u001b[33my_train\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    218\u001b[39m end_time = time.monotonic()\n\u001b[32m    219\u001b[39m time_taken = timedelta(seconds=end_time - start_time)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28mself\u001b[39m._run_search(evaluate_candidates)\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m.param_grid))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = parallel(\n\u001b[32m    998\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    999\u001b[39m         clone(base_estimator),\n\u001b[32m   1000\u001b[39m         X,\n\u001b[32m   1001\u001b[39m         y,\n\u001b[32m   1002\u001b[39m         train=train,\n\u001b[32m   1003\u001b[39m         test=test,\n\u001b[32m   1004\u001b[39m         parameters=parameters,\n\u001b[32m   1005\u001b[39m         split_progress=(split_idx, n_splits),\n\u001b[32m   1006\u001b[39m         candidate_progress=(cand_idx, n_candidates),\n\u001b[32m   1007\u001b[39m         **fit_and_score_kwargs,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[32m   1010\u001b[39m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[32m   1011\u001b[39m         \u001b[38;5;28menumerate\u001b[39m(cv.split(X, y, **routed_params.splitter.split)),\n\u001b[32m   1012\u001b[39m     )\n\u001b[32m   1013\u001b[39m )\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(iterable_with_config_and_warning_filters)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = func(*args, **kwargs)\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:859\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    857\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m         estimator.fit(X_train, y_train, **fit_params)\n\u001b[32m    861\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    862\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    863\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = Parallel(\n\u001b[32m    487\u001b[39m     n_jobs=\u001b[38;5;28mself\u001b[39m.n_jobs,\n\u001b[32m    488\u001b[39m     verbose=\u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    489\u001b[39m     prefer=\u001b[33m\"\u001b[39m\u001b[33mthreads\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    490\u001b[39m )(\n\u001b[32m    491\u001b[39m     delayed(_parallel_build_trees)(\n\u001b[32m    492\u001b[39m         t,\n\u001b[32m    493\u001b[39m         \u001b[38;5;28mself\u001b[39m.bootstrap,\n\u001b[32m    494\u001b[39m         X,\n\u001b[32m    495\u001b[39m         y,\n\u001b[32m    496\u001b[39m         sample_weight,\n\u001b[32m    497\u001b[39m         i,\n\u001b[32m    498\u001b[39m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[32m    499\u001b[39m         verbose=\u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    500\u001b[39m         class_weight=\u001b[38;5;28mself\u001b[39m.class_weight,\n\u001b[32m    501\u001b[39m         n_samples_bootstrap=n_samples_bootstrap,\n\u001b[32m    502\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    503\u001b[39m     )\n\u001b[32m    504\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[32m    505\u001b[39m )\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(iterable_with_config_and_warning_filters)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = func(*args, **kwargs)\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[39m, in \u001b[36m_parallel_build_trees\u001b[39m\u001b[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m class_weight == \u001b[33m\"\u001b[39m\u001b[33mbalanced_subsample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    186\u001b[39m         curr_sample_weight *= compute_sample_weight(\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, y, indices=indices)\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     tree._fit(\n\u001b[32m    189\u001b[39m         X,\n\u001b[32m    190\u001b[39m         y,\n\u001b[32m    191\u001b[39m         sample_weight=curr_sample_weight,\n\u001b[32m    192\u001b[39m         check_input=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    193\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    194\u001b[39m     )\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    196\u001b[39m     tree._fit(\n\u001b[32m    197\u001b[39m         X,\n\u001b[32m    198\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    202\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Apps/anaconda3/envs/kif/lib/python3.11/site-packages/sklearn/tree/_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m builder.build(\u001b[38;5;28mself\u001b[39m.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ml_model.build_models(save_models=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the models now built, we can see the models seem to be quite equally matched in terms of accuracy for the train and test sets. \n",
    "We can now evaluate the quality of the models on the validation dataset (also sometimes refered to as the hold-out set).\n",
    "\n",
    "For each ML model built, a pandas dataframe can be generated with metrics describing the accuracy of the model on the validation dataset. \n",
    "If you are unfamiliar with any of the terms presented below, [feel free to check out this guide from scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = ml_model.evaluate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports[\"XGBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports[\"CatBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports[\"Random_Forest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular way to evaluate model quality is to generate confusion matrices. \n",
    "\n",
    "Using the command below we can generate confusion matrices (stored as numpy arrays) for each model we generated. \n",
    "\n",
    "You can then easily plot these confusion matrices in whatever graphing program you like. In this case, I will use plotly as before, but you could easily use another graphing package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = ml_model.generate_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices[\"XGBoost\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, you'll need plotly installed (see above) if you want to make this figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "labels = [\"closed\", \"open\"]\n",
    "fig = ff.create_annotated_heatmap(confusion_matrices[\"XGBoost\"], x = labels, y = labels, colorscale=\"reds\")\n",
    "fig.update_layout(yaxis = dict(categoryorder = \"category descending\"))\n",
    "fig.update_layout(title=\"Confusion Matrix Obtained for XGBoost using the Validation/Holdout set\")\n",
    "fig.show() # to make this plot interactive, remove \"svg\" and run the cell block. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2. Work up the ML results with the post_proccessing.py module. \n",
    "\n",
    "In order to perform the analysis we will need to provide the models generated in Part 2.1 Shown below are the two possible ways to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will make an instance of the SupervisedPostProcessor class.\n",
    "ml_post_proc = post_proccessing.SupervisedPostProcessor(\n",
    "    out_dir=ml_out_dir,\n",
    ")\n",
    "\n",
    "# Option 1 - Load models from the instance of the SupervisedModel class. \n",
    "ml_post_proc.load_models_from_instance(supervised_model=ml_model)\n",
    "\n",
    "# Option 2 - Load models from disk. (If you've run the model building, shut down the kernel and now want to post-process).\n",
    "#post_proc.load_models_from_disk(models_to_use=[\"XGBoost\", \"CatBoost\", \"Random_Forest\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After preparing the class we can now determine the per feature scores for each model made.\n",
    "ml_post_proc.get_per_feature_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also project these per feature scores onto the per-residue level. \n",
    "ml_post_proc.get_per_res_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ml_post_proc.__dict__.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the class attributes we can see the per feature and per residue scores were not just saved to disk, but are also stored inside the class.\n",
    "\n",
    "This means you could easily analyse them within Python if you want. I will show one more way to generate a quick figure here. Bear in mind these results can also be analysed in very similar ways to those generated in the statistical analysis section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_per_res_scores = ml_post_proc.all_per_residue_scores\n",
    "all_per_feature_scores = ml_post_proc.all_per_feature_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "df_all_per_res_scores = pd.DataFrame(all_per_res_scores).reset_index()\n",
    "df_all_per_res_scores = df_all_per_res_scores.rename(columns={\"index\": \"Residue Number\"})\n",
    "df_all_per_res_scores = df_all_per_res_scores.sort_values([\"Residue Number\"], ascending=True)\n",
    "df_all_per_res_scores.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_all_per_res_scores, x=\"Residue Number\", y=[\"CatBoost\", \"XGBoost\", \"Random_Forest\"])\n",
    "fig.update_layout(\n",
    "    title=\"Per Residue Scores for All 3 Machine Learning Models\",\n",
    "    xaxis_title=\"Residue Number\",\n",
    "    yaxis_title=\"Per Residue Score\",\n",
    "    legend_title=\"ML Models\",\n",
    "    font=dict(size=16)\n",
    ")\n",
    "\n",
    "fig.show() # remove \"svg\" to make the graph interactive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3. Project the Results onto Protein Structures\n",
    " \n",
    "This section is essentially identical to 1.3, only that now we will output the ml results instead of the stats results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you do not need to specify what model you would like to the output results for, all will be outputted simultaneously.\n",
    "pymol_projections.project_multiple_per_res_scores(\n",
    "    all_per_res_scores=ml_post_proc.all_per_residue_scores,\n",
    "    out_dir=ml_out_dir\n",
    ")\n",
    "\n",
    "pymol_projections.project_multiple_per_feature_scores(\n",
    "    all_per_feature_scores=ml_post_proc.all_per_feature_scores,\n",
    "    numb_features=\"all\",\n",
    "    out_dir=ml_out_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here for ChimeraX\n",
    "chimerax_projections.project_multiple_per_res_scores(\n",
    "    all_per_res_scores=ml_post_proc.all_per_residue_scores,\n",
    "    out_dir=ml_out_dir\n",
    ")\n",
    "\n",
    "chimerax_projections.project_multiple_per_feature_scores(\n",
    "    all_per_feature_scores=ml_post_proc.all_per_feature_scores,\n",
    "    numb_features=\"all\",\n",
    "    out_dir=ml_out_dir,\n",
    "    pdb_file=pdb_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kif",
   "language": "python",
   "name": "kif"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
